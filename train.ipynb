{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a350a6b6-4094-4051-b8bf-dfc6dfd0f179",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c81020-0acc-4fc0-875f-b2cba4e48fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset.dataset import load_data\n",
    "from models import MRnet\n",
    "from config import config\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.utils import _train_model, _evaluate_model, _get_lr\n",
    "import time\n",
    "import torch.utils.data as data\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93ba76-e97f-41c5-a805-4b8f48c14782",
   "metadata": {
    "tags": []
   },
   "source": [
    "Method for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d810f7c-83fb-45ff-9fe2-be3758cd99dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(config : dict):\n",
    "    \"\"\"\n",
    "    Performs training of a specified model.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration to train with\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Starting to Train Model...')\n",
    "\n",
    "    # Load training, validation, and test data\n",
    "    train_loader, val_loader, test_loader, train_wts, val_wts, test_wts = load_data()\n",
    "\n",
    "    print('Initializing Model...')\n",
    "    model = MRnet()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        train_wts = train_wts.cuda()\n",
    "        val_wts = val_wts.cuda()\n",
    "\n",
    "    print('Initializing Loss Method...')\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=train_wts)\n",
    "    val_criterion = torch.nn.BCEWithLogitsLoss(pos_weight=val_wts)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        criterion = criterion.cuda()\n",
    "        val_criterion = val_criterion.cuda()\n",
    "\n",
    "    print('Setup the Optimizer')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, patience=3, factor=.3, threshold=1e-4, verbose=True)\n",
    "    \n",
    "    starting_epoch = config['starting_epoch']\n",
    "    num_epochs = config['max_epoch']\n",
    "    patience = config['patience']\n",
    "    log_train = config['log_train']\n",
    "    log_val = config['log_val']\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = float(0)\n",
    "\n",
    "    print('Starting Training')\n",
    "\n",
    "    writer = SummaryWriter(comment='lr={} task={}'.format(config['lr'], config['task']))\n",
    "    t_start_training = time.time()\n",
    "\n",
    "    for epoch in range(starting_epoch, num_epochs):\n",
    "\n",
    "        current_lr = _get_lr(optimizer)\n",
    "        epoch_start_time = time.time()  # timer for entire epoch\n",
    "\n",
    "        print('Started Training')\n",
    "        train_loss, train_acc = _train_model(\n",
    "            model, train_loader, epoch, num_epochs, optimizer, criterion, writer, current_lr, log_every=log_train)\n",
    "\n",
    "        print('train loop ended, now val')\n",
    "        val_loss, val_acc = _evaluate_model(\n",
    "            model, val_loader, val_criterion,  epoch, num_epochs, writer, current_lr, log_val)\n",
    "\n",
    "        writer.add_scalar('Train/Avg Loss', train_loss, epoch)\n",
    "        writer.add_scalar('Val/Avg Loss', val_loss, epoch)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        t_end = time.time()\n",
    "        delta = t_end - epoch_start_time\n",
    "\n",
    "        print(\"train loss : {0} | train acc {1} | val loss {2} | val acc {3} | elapsed time {4} s\".format(\n",
    "            train_loss, train_acc, val_loss, val_acc, delta))\n",
    "\n",
    "        print('-' * 30)\n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "        if bool(config['save_model']) and (epoch+1) % 10 == 0:\n",
    "            file_name = 'model_{}_{}_val_acc_{:0.4f}_train_acc_{:0.4f}_epoch_{}.pth'.format(\n",
    "                config['exp_name'], config['task'], val_acc, train_acc, epoch+1)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict()\n",
    "            }, './weights/{}/{}'.format(config['task'], file_name))\n",
    "\n",
    "    # ðŸ§ª Final test evaluation\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_acc = _evaluate_model(\n",
    "        model, test_loader, val_criterion, epoch, num_epochs, writer, current_lr=0, log_every=0\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"FINAL TEST PERFORMANCE:\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    writer.add_scalar('Test/Avg Loss', test_loss, num_epochs)\n",
    "    writer.add_scalar('Test/Final Accuracy', test_acc, num_epochs)\n",
    "\n",
    "    # Wrap up\n",
    "    t_end_training = time.time()\n",
    "    print(f'Training took {t_end_training - t_start_training:.2f} seconds')\n",
    "    writer.flush()\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8eecb-4508-415c-a6b3-a507c23b76ff",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19133bc4-876f-4f68-8aa8-83be1e5895d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration\n",
      "{'max_epoch': 50, 'log_train': 100, 'lr': 1e-05, 'starting_epoch': 0, 'batch_size': 1, 'log_val': 10, 'weight_decay': 0.01, 'patience': 5, 'save_model': 1, 'exp_name': 'test'}\n",
      "Starting to Train Model...\n",
      "Loading Train Dataset of ACL task...\n",
      "Class distribution:\n",
      "Class 0: 7 samples\n",
      "Class 1: 3 samples\n",
      "Class 2: 8 samples\n",
      "Class 3: 4 samples\n",
      "Class 4: 1 samples\n",
      "Class weights for loss are: tensor([0.3859, 0.9003, 0.3376, 0.6752, 2.7010])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'neg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Configuration\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(config)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Ended...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting to Train Model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load training, validation, and test data\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m train_loader, val_loader, test_loader, train_wts, val_wts, test_wts \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitializing Model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m MRnet()\n",
      "File \u001b[0;32m/sfs/gpfs/tardis/home/qdy4zt/Coding Projects/MSDS/Deep Learning/alex_net/dataset/dataset.py:176\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading Train Dataset of ACL task...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Load training dataset\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mMRData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m    178\u001b[0m     train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading Validation Dataset of ACL task...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/sfs/gpfs/tardis/home/qdy4zt/Coding Projects/MSDS/Deep Learning/alex_net/dataset/dataset.py:97\u001b[0m, in \u001b[0;36mMRData.__init__\u001b[0;34m(self, stage, transform, weights)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(class_weights\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass weights for loss are:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of -ve samples : \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mneg\u001b[49m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of +ve samples : \u001b[39m\u001b[38;5;124m'\u001b[39m, pos)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeights for loss is : \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neg' is not defined"
     ]
    }
   ],
   "source": [
    "print('Training Configuration')\n",
    "print(config)\n",
    "\n",
    "train(config=config)\n",
    "\n",
    "print('Training Ended...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef1589-8889-470c-8d31-8537b3c3ba03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
