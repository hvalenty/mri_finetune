{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a350a6b6-4094-4051-b8bf-dfc6dfd0f179",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c81020-0acc-4fc0-875f-b2cba4e48fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset.dataset import load_data\n",
    "from models import MRnet\n",
    "from config import config\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.utils import _train_model, _evaluate_model, _get_lr\n",
    "import time\n",
    "import torch.utils.data as data\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93ba76-e97f-41c5-a805-4b8f48c14782",
   "metadata": {
    "tags": []
   },
   "source": [
    "Method for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d810f7c-83fb-45ff-9fe2-be3758cd99dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Performs training of a specified model.\n",
    "    \n",
    "Input params:\n",
    "    config_file: Takes in configurations to train with \n",
    "\"\"\"\n",
    "\n",
    "def train(config : dict):\n",
    "    \"\"\"\n",
    "    Function where actual training takes place\n",
    "\n",
    "    Args:\n",
    "        config (dict) : Configuration to train with\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Starting to Train Model...')\n",
    "\n",
    "    train_loader, val_loader, train_wts, val_wts = load_data(config['task'])\n",
    "\n",
    "    print('Initializing Model...')\n",
    "    model = MRnet()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        train_wts = train_wts.cuda()\n",
    "        val_wts = val_wts.cuda()\n",
    "\n",
    "    print('Initializing Loss Method...')\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=train_wts)\n",
    "    val_criterion = torch.nn.BCEWithLogitsLoss(pos_weight=val_wts)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        criterion = criterion.cuda()\n",
    "        val_criterion = val_criterion.cuda()\n",
    "\n",
    "    print('Setup the Optimizer')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, patience=3, factor=.3, threshold=1e-4, verbose=True)\n",
    "    \n",
    "    starting_epoch = config['starting_epoch']\n",
    "    num_epochs = config['max_epoch']\n",
    "    patience = config['patience']\n",
    "    log_train = config['log_train']\n",
    "    log_val = config['log_val']\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_auc = float(0)\n",
    "\n",
    "    print('Starting Training')\n",
    "\n",
    "    writer = SummaryWriter(comment='lr={} task={}'.format(config['lr'], config['task']))\n",
    "    t_start_training = time.time()\n",
    "\n",
    "    for epoch in range(starting_epoch, num_epochs):\n",
    "\n",
    "        current_lr = _get_lr(optimizer)\n",
    "        epoch_start_time = time.time()  # timer for entire epoch\n",
    "\n",
    "        print('Started Training')\n",
    "        train_loss, train_auc = _train_model(\n",
    "            model, train_loader, epoch, num_epochs, optimizer, criterion, writer, current_lr, log_every=log_train)\n",
    "\n",
    "        print('train loop ended, now val')\n",
    "        val_loss, val_auc = _evaluate_model(\n",
    "            model, val_loader, val_criterion,  epoch, num_epochs, writer, current_lr, log_val)\n",
    "\n",
    "        writer.add_scalar('Train/Avg Loss', train_loss, epoch)\n",
    "        writer.add_scalar('Val/Avg Loss', val_loss, epoch)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        t_end = time.time()\n",
    "        delta = t_end - epoch_start_time\n",
    "\n",
    "        print(\"train loss : {0} | train auc {1} | val loss {2} | val auc {3} | elapsed time {4} s\".format(\n",
    "            train_loss, train_auc, val_loss, val_auc, delta))\n",
    "\n",
    "        print('-' * 30)\n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "\n",
    "        if bool(config['save_model']):\n",
    "            file_name = 'model_{}_{}_val_auc_{:0.4f}_train_auc_{:0.4f}_epoch_{}.pth'.format(config['exp_name'], config['task'], val_auc, train_auc, epoch+1)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict()\n",
    "            }, './weights/{}/{}'.format(config['task'],file_name))\n",
    "\n",
    "    t_end_training = time.time()\n",
    "    print(f'training took {t_end_training - t_start_training} s')\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8eecb-4508-415c-a6b3-a507c23b76ff",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19133bc4-876f-4f68-8aa8-83be1e5895d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration\n",
      "{'max_epoch': 50, 'log_train': 50, 'lr': 1e-05, 'starting_epoch': 0, 'batch_size': 1, 'log_val': 10, 'task': 'combined', 'weight_decay': 0.01, 'patience': 5, 'save_model': 1, 'exp_name': 'test'}\n",
      "Starting to Train Model...\n",
      "Loading Train Dataset of combined task...\n",
      "Weights for loss is :  tensor([0.2377, 4.4327, 1.8463])\n",
      "Loading Validation Dataset of combined task...\n",
      "Weights for loss is :  tensor([0.2632, 1.2222, 1.3077])\n",
      "Initializing Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unc6kr/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/unc6kr/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Loss Method...\n",
      "Setup the Optimizer\n",
      "Starting Training\n",
      "Started Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unc6kr/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.9111 | Train Avg AUC : 0.4751 abnorm:0.3995 acl:0.5591 meni:0.4667 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.8623 | Train Avg AUC : 0.4737 abnorm:0.4356 acl:0.4786 meni:0.5068 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.8197 | Train Avg AUC : 0.4837 abnorm:0.4115 acl:0.4907 meni:0.5489 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.8014 | Train Avg AUC : 0.5071 abnorm:0.4349 acl:0.5271 meni:0.5593 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.786 | Train Avg AUC : 0.5431 abnorm:0.4833 acl:0.5438 meni:0.6022 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.7822 | Train Avg AUC : 0.5575 abnorm:0.4639 acl:0.5803 meni:0.6284 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.7769 | Train Avg AUC : 0.5642 abnorm:0.4807 acl:0.5745 meni:0.6374 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.7665 | Train Avg AUC : 0.5768 abnorm:0.5043 acl:0.5787 meni:0.6474 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.7642 | Train Avg AUC : 0.5801 abnorm:0.5044 acl:0.5841 meni:0.6518 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.7513 | Train Avg AUC : 0.59 abnorm:0.5047 acl:0.6017 meni:0.6635 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.7567 | Train Avg AUC : 0.6 abnorm:0.5361 acl:0.5976 meni:0.6664 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.757 | Train Avg AUC : 0.598 abnorm:0.5354 acl:0.5921 meni:0.6665 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.7526 | Train Avg AUC : 0.5977 abnorm:0.5278 acl:0.602 meni:0.6635 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.7465 | Train Avg AUC : 0.6056 abnorm:0.5441 acl:0.6044 meni:0.6683 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.7417 | Train Avg AUC : 0.6088 abnorm:0.5408 acl:0.6116 meni:0.6741 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.7409 | Train Avg AUC : 0.6155 abnorm:0.5541 acl:0.6177 meni:0.6747 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.7353 | Train Avg AUC : 0.6267 abnorm:0.5642 acl:0.6302 meni:0.6858 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.7321 | Train Avg AUC : 0.6304 abnorm:0.5745 acl:0.629 meni:0.6876 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.7329 | Train Avg AUC : 0.6369 abnorm:0.5886 acl:0.6335 meni:0.6886 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.7307 | Train Avg AUC : 0.6421 abnorm:0.605 acl:0.6281 meni:0.6931 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.7279 | Train Avg AUC : 0.6464 abnorm:0.614 acl:0.6318 meni:0.6933 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.7266 | Train Avg AUC : 0.6465 abnorm:0.6177 acl:0.6326 meni:0.6892 | lr : 1e-05\n",
      "Epoch 0 End Train Avg AUC : 0.6497 abnorm : 0.6219 acl : 0.6375 meni : 0.6896\n",
      "train loop ended, now val\n",
      "[Epoch: 1 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.4655 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.4676 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.4265 | Val AUC : 0.5933 abnorm:0.7798 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.4212 | Val AUC : 0.5694 abnorm:0.7083 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.4447 | Val AUC : 0.7927 abnorm:0.7377 acl:0.8372 meni:0.8032 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.4499 | Val AUC : 0.8134 abnorm:0.7421 acl:0.8463 meni:0.8519 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4616 | Val AUC : 0.8164 abnorm:0.7429 acl:0.8779 meni:0.8283 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4712 | Val AUC : 0.8091 abnorm:0.7434 acl:0.8962 meni:0.7878 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4826 | Val AUC : 0.7984 abnorm:0.7291 acl:0.8758 meni:0.7903 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4855 | Val AUC : 0.8042 abnorm:0.7363 acl:0.8749 meni:0.8012 | lr : 1e-05\n",
      "[Epoch: 1 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4951 | Val AUC : 0.7972 abnorm:0.7479 acl:0.8657 meni:0.778 | lr : 1e-05\n",
      "Epoch 0 End Val Avg AUC : 0.7779 abnorm : 0.7436 acl : 0.8401 meni : 0.75\n",
      "train loss : 0.7248 | train auc 0.6497 | val loss 0.5129 | val auc 0.7779 | elapsed time 238.65335536003113 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 2 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.7074 | Train Avg AUC : 0.6787 abnorm:0.7667 acl:0.5185 meni:0.7509 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.6685 | Train Avg AUC : 0.7178 abnorm:0.714 acl:0.7094 meni:0.7301 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.6439 | Train Avg AUC : 0.7459 abnorm:0.7456 acl:0.752 meni:0.7403 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.6575 | Train Avg AUC : 0.7473 abnorm:0.7608 acl:0.7275 meni:0.7536 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.6684 | Train Avg AUC : 0.7525 abnorm:0.749 acl:0.7407 meni:0.7677 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.6536 | Train Avg AUC : 0.7563 abnorm:0.7458 acl:0.7584 meni:0.7646 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.6628 | Train Avg AUC : 0.744 abnorm:0.7311 acl:0.7337 meni:0.7671 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.6623 | Train Avg AUC : 0.7373 abnorm:0.7144 acl:0.7383 meni:0.7594 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.6591 | Train Avg AUC : 0.75 abnorm:0.7218 acl:0.7731 meni:0.755 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.6571 | Train Avg AUC : 0.7524 abnorm:0.7306 acl:0.7568 meni:0.7699 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.6642 | Train Avg AUC : 0.7528 abnorm:0.7305 acl:0.7528 meni:0.775 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.6629 | Train Avg AUC : 0.755 abnorm:0.7343 acl:0.7528 meni:0.7779 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.664 | Train Avg AUC : 0.752 abnorm:0.7379 acl:0.752 meni:0.7661 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.6611 | Train Avg AUC : 0.7541 abnorm:0.7411 acl:0.7565 meni:0.7647 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.6571 | Train Avg AUC : 0.7593 abnorm:0.7524 acl:0.7605 meni:0.7648 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.6609 | Train Avg AUC : 0.7608 abnorm:0.7633 acl:0.7577 meni:0.7615 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.6583 | Train Avg AUC : 0.7621 abnorm:0.7649 acl:0.7612 meni:0.7603 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.6571 | Train Avg AUC : 0.7618 abnorm:0.7658 acl:0.7595 meni:0.76 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.6589 | Train Avg AUC : 0.7606 abnorm:0.768 acl:0.7574 meni:0.7563 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.6581 | Train Avg AUC : 0.7585 abnorm:0.7638 acl:0.7575 meni:0.7542 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.6535 | Train Avg AUC : 0.7626 abnorm:0.7729 acl:0.7623 meni:0.7524 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.6488 | Train Avg AUC : 0.7647 abnorm:0.7778 acl:0.7648 meni:0.7516 | lr : 1e-05\n",
      "Epoch 1 End Train Avg AUC : 0.7644 abnorm : 0.7791 acl : 0.7629 meni : 0.7513\n",
      "train loop ended, now val\n",
      "[Epoch: 2 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.2832 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.266 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2577 | Val AUC : 0.5913 abnorm:0.7738 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2845 | Val AUC : 0.5817 abnorm:0.7451 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3397 | Val AUC : 0.8527 abnorm:0.787 acl:0.9041 meni:0.867 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3653 | Val AUC : 0.8561 abnorm:0.7984 acl:0.8757 meni:0.8942 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3956 | Val AUC : 0.8567 abnorm:0.8059 acl:0.9032 meni:0.8609 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4157 | Val AUC : 0.8494 abnorm:0.8107 acl:0.9201 meni:0.8175 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4361 | Val AUC : 0.8422 abnorm:0.8012 acl:0.9005 meni:0.8248 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4479 | Val AUC : 0.8433 abnorm:0.8095 acl:0.8941 meni:0.8262 | lr : 1e-05\n",
      "[Epoch: 2 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4641 | Val AUC : 0.8391 abnorm:0.8242 acl:0.8873 meni:0.8057 | lr : 1e-05\n",
      "Epoch 1 End Val Avg AUC : 0.8186 abnorm : 0.8177 acl : 0.8676 meni : 0.7706\n",
      "train loss : 0.6502 | train auc 0.7644 | val loss 0.4967 | val auc 0.8186 | elapsed time 219.4639241695404 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 3 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.6622 | Train Avg AUC : 0.7718 abnorm:0.7308 acl:0.7705 meni:0.8143 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.6316 | Train Avg AUC : 0.8105 abnorm:0.8295 acl:0.8176 meni:0.7843 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.606 | Train Avg AUC : 0.8147 abnorm:0.8208 acl:0.843 meni:0.7805 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.5862 | Train Avg AUC : 0.8257 abnorm:0.8315 acl:0.8404 meni:0.8053 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.6169 | Train Avg AUC : 0.8081 abnorm:0.8266 acl:0.811 meni:0.7866 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.6265 | Train Avg AUC : 0.7995 abnorm:0.8249 acl:0.8003 meni:0.7733 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.6233 | Train Avg AUC : 0.8056 abnorm:0.8346 acl:0.8084 meni:0.7738 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.6191 | Train Avg AUC : 0.8041 abnorm:0.825 acl:0.8208 meni:0.7664 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.6313 | Train Avg AUC : 0.7946 abnorm:0.8183 acl:0.8064 meni:0.7591 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.6321 | Train Avg AUC : 0.7968 abnorm:0.8194 acl:0.8052 meni:0.7659 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.6161 | Train Avg AUC : 0.8037 abnorm:0.824 acl:0.8138 meni:0.7733 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.6181 | Train Avg AUC : 0.8013 abnorm:0.826 acl:0.8017 meni:0.7761 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.6289 | Train Avg AUC : 0.7948 abnorm:0.8254 acl:0.7821 meni:0.7769 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.6238 | Train Avg AUC : 0.7981 abnorm:0.8239 acl:0.7909 meni:0.7796 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.6246 | Train Avg AUC : 0.7992 abnorm:0.8276 acl:0.7875 meni:0.7825 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.624 | Train Avg AUC : 0.8008 abnorm:0.83 acl:0.7915 meni:0.7809 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.6207 | Train Avg AUC : 0.798 abnorm:0.8231 acl:0.7935 meni:0.7775 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.6202 | Train Avg AUC : 0.7997 abnorm:0.8251 acl:0.7981 meni:0.7759 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.617 | Train Avg AUC : 0.8012 abnorm:0.8308 acl:0.7967 meni:0.7763 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.6186 | Train Avg AUC : 0.8017 abnorm:0.8295 acl:0.7979 meni:0.7777 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.6152 | Train Avg AUC : 0.8033 abnorm:0.8306 acl:0.8002 meni:0.779 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.6172 | Train Avg AUC : 0.8025 abnorm:0.8352 acl:0.7986 meni:0.7737 | lr : 1e-05\n",
      "Epoch 2 End Train Avg AUC : 0.8039 abnorm : 0.836 acl : 0.8004 meni : 0.7754\n",
      "train loop ended, now val\n",
      "[Epoch: 3 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.256 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.2466 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2158 | Val AUC : 0.6071 abnorm:0.8214 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2201 | Val AUC : 0.5948 abnorm:0.7843 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3038 | Val AUC : 0.8798 abnorm:0.8287 acl:0.9331 meni:0.8777 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.351 | Val AUC : 0.8804 abnorm:0.8446 acl:0.8917 meni:0.9048 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4049 | Val AUC : 0.877 abnorm:0.8475 acl:0.915 meni:0.8684 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4317 | Val AUC : 0.8722 abnorm:0.8553 acl:0.9294 meni:0.8319 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4674 | Val AUC : 0.8662 abnorm:0.8473 acl:0.9106 meni:0.8408 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4768 | Val AUC : 0.8689 abnorm:0.8584 acl:0.9051 meni:0.8431 | lr : 1e-05\n",
      "[Epoch: 3 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4904 | Val AUC : 0.8641 abnorm:0.8726 acl:0.8974 meni:0.8225 | lr : 1e-05\n",
      "Epoch 2 End Val Avg AUC : 0.8429 abnorm : 0.8657 acl : 0.8808 meni : 0.7822\n",
      "train loss : 0.613 | train auc 0.8039 | val loss 0.5311 | val auc 0.8429 | elapsed time 218.09757328033447 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 4 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.6441 | Train Avg AUC : 0.7656 abnorm:0.8439 acl:0.7326 meni:0.7204 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.605 | Train Avg AUC : 0.798 abnorm:0.8424 acl:0.7876 meni:0.7641 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.579 | Train Avg AUC : 0.8284 abnorm:0.848 acl:0.8184 meni:0.8188 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.5841 | Train Avg AUC : 0.8288 abnorm:0.8641 acl:0.8076 meni:0.8148 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.5732 | Train Avg AUC : 0.8342 abnorm:0.8524 acl:0.8271 meni:0.8232 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.5745 | Train Avg AUC : 0.833 abnorm:0.8555 acl:0.8145 meni:0.8289 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.5798 | Train Avg AUC : 0.821 abnorm:0.8456 acl:0.7996 meni:0.8177 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.5864 | Train Avg AUC : 0.8197 abnorm:0.8571 acl:0.7924 meni:0.8096 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.5807 | Train Avg AUC : 0.8267 abnorm:0.8649 acl:0.7999 meni:0.8152 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.593 | Train Avg AUC : 0.8236 abnorm:0.8691 acl:0.7978 meni:0.8038 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.5955 | Train Avg AUC : 0.8248 abnorm:0.8674 acl:0.7968 meni:0.8101 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.5894 | Train Avg AUC : 0.8279 abnorm:0.8634 acl:0.8025 meni:0.8178 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.5825 | Train Avg AUC : 0.8274 abnorm:0.8558 acl:0.8073 meni:0.819 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.5791 | Train Avg AUC : 0.8256 abnorm:0.8518 acl:0.8102 meni:0.8149 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.5819 | Train Avg AUC : 0.8239 abnorm:0.8487 acl:0.8098 meni:0.813 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.5844 | Train Avg AUC : 0.8227 abnorm:0.8503 acl:0.8092 meni:0.8086 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.5826 | Train Avg AUC : 0.8237 abnorm:0.8547 acl:0.8124 meni:0.8039 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.5825 | Train Avg AUC : 0.824 abnorm:0.8575 acl:0.8113 meni:0.8033 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.5809 | Train Avg AUC : 0.8243 abnorm:0.8568 acl:0.815 meni:0.801 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.5803 | Train Avg AUC : 0.8262 abnorm:0.8591 acl:0.8189 meni:0.8007 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.5829 | Train Avg AUC : 0.8234 abnorm:0.8566 acl:0.8197 meni:0.7939 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.5887 | Train Avg AUC : 0.8216 abnorm:0.857 acl:0.8132 meni:0.7944 | lr : 1e-05\n",
      "Epoch 3 End Train Avg AUC : 0.8246 abnorm : 0.8604 acl : 0.8195 meni : 0.7938\n",
      "train loop ended, now val\n",
      "[Epoch: 4 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.2859 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.2555 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2362 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2576 | Val AUC : 0.6021 abnorm:0.8064 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3061 | Val AUC : 0.897 abnorm:0.8503 acl:0.9419 meni:0.8989 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3333 | Val AUC : 0.8964 abnorm:0.866 acl:0.9078 meni:0.9153 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3626 | Val AUC : 0.8883 abnorm:0.8679 acl:0.9259 meni:0.8709 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3764 | Val AUC : 0.8838 abnorm:0.8808 acl:0.9386 meni:0.8319 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.3947 | Val AUC : 0.8806 abnorm:0.8752 acl:0.9266 meni:0.8402 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.3977 | Val AUC : 0.8854 abnorm:0.8858 acl:0.9161 meni:0.8543 | lr : 1e-05\n",
      "[Epoch: 4 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4102 | Val AUC : 0.8794 abnorm:0.8949 acl:0.9088 meni:0.8345 | lr : 1e-05\n",
      "Epoch 3 End Val Avg AUC : 0.8603 abnorm : 0.8901 acl : 0.8967 meni : 0.7941\n",
      "train loss : 0.5864 | train auc 0.8246 | val loss 0.4433 | val auc 0.8603 | elapsed time 217.6092085838318 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 5 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.6486 | Train Avg AUC : 0.811 abnorm:0.8571 acl:0.8243 meni:0.7516 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.6058 | Train Avg AUC : 0.8454 abnorm:0.8915 acl:0.8374 meni:0.8074 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.6128 | Train Avg AUC : 0.8259 abnorm:0.8448 acl:0.862 meni:0.7709 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.5814 | Train Avg AUC : 0.8434 abnorm:0.8658 acl:0.883 meni:0.7813 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.5807 | Train Avg AUC : 0.842 abnorm:0.8712 acl:0.8824 meni:0.7724 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.5821 | Train Avg AUC : 0.8368 abnorm:0.8665 acl:0.8589 meni:0.7849 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.5746 | Train Avg AUC : 0.8438 abnorm:0.8773 acl:0.868 meni:0.7861 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.569 | Train Avg AUC : 0.8409 abnorm:0.8728 acl:0.867 meni:0.7828 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.5634 | Train Avg AUC : 0.8396 abnorm:0.8596 acl:0.8663 meni:0.7928 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.5569 | Train Avg AUC : 0.844 abnorm:0.8662 acl:0.8661 meni:0.7997 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.5514 | Train Avg AUC : 0.8477 abnorm:0.8733 acl:0.8682 meni:0.8017 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.5512 | Train Avg AUC : 0.8468 abnorm:0.8784 acl:0.8615 meni:0.8006 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.5485 | Train Avg AUC : 0.845 abnorm:0.8709 acl:0.8634 meni:0.8008 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.5506 | Train Avg AUC : 0.8441 abnorm:0.8785 acl:0.8515 meni:0.8024 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.5546 | Train Avg AUC : 0.8428 abnorm:0.883 acl:0.848 meni:0.7975 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.5566 | Train Avg AUC : 0.8417 abnorm:0.8792 acl:0.8458 meni:0.8001 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.5622 | Train Avg AUC : 0.8405 abnorm:0.8834 acl:0.8417 meni:0.7965 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.5606 | Train Avg AUC : 0.8428 abnorm:0.8788 acl:0.847 meni:0.8027 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.5643 | Train Avg AUC : 0.8414 abnorm:0.8791 acl:0.8441 meni:0.8009 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.5641 | Train Avg AUC : 0.8395 abnorm:0.8759 acl:0.8415 meni:0.801 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.5594 | Train Avg AUC : 0.8403 abnorm:0.8756 acl:0.8432 meni:0.8022 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.5605 | Train Avg AUC : 0.8398 abnorm:0.876 acl:0.8424 meni:0.801 | lr : 1e-05\n",
      "Epoch 4 End Train Avg AUC : 0.8394 abnorm : 0.8749 acl : 0.8452 meni : 0.798\n",
      "train loop ended, now val\n",
      "[Epoch: 5 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.453 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.4064 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.3712 | Val AUC : 0.6151 abnorm:0.8452 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.3958 | Val AUC : 0.607 abnorm:0.8211 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.4053 | Val AUC : 0.9045 abnorm:0.8704 acl:0.939 meni:0.9043 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.4122 | Val AUC : 0.9059 abnorm:0.8908 acl:0.9037 meni:0.9233 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4112 | Val AUC : 0.8955 abnorm:0.8927 acl:0.9192 meni:0.8747 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4135 | Val AUC : 0.8935 abnorm:0.9079 acl:0.9349 meni:0.8379 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.415 | Val AUC : 0.891 abnorm:0.9079 acl:0.9193 meni:0.8459 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4052 | Val AUC : 0.8956 abnorm:0.9168 acl:0.9098 meni:0.8601 | lr : 1e-05\n",
      "[Epoch: 5 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4059 | Val AUC : 0.8885 abnorm:0.9233 acl:0.9046 meni:0.8376 | lr : 1e-05\n",
      "Epoch 4 End Val Avg AUC : 0.8715 abnorm : 0.9187 acl : 0.8923 meni : 0.8035\n",
      "train loss : 0.5619 | train auc 0.8394 | val loss 0.4217 | val auc 0.8715 | elapsed time 214.36633586883545 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 6 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.517 | Train Avg AUC : 0.8383 abnorm:0.8687 acl:0.7442 meni:0.9021 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.5021 | Train Avg AUC : 0.8375 abnorm:0.8087 acl:0.83 meni:0.8738 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4994 | Train Avg AUC : 0.8494 abnorm:0.8395 acl:0.864 meni:0.8446 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4927 | Train Avg AUC : 0.865 abnorm:0.8561 acl:0.8786 meni:0.8604 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4848 | Train Avg AUC : 0.876 abnorm:0.8674 acl:0.9019 meni:0.8587 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.5031 | Train Avg AUC : 0.8695 abnorm:0.8748 acl:0.8881 meni:0.8455 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.504 | Train Avg AUC : 0.8686 abnorm:0.8758 acl:0.8859 meni:0.844 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.5215 | Train Avg AUC : 0.8647 abnorm:0.8779 acl:0.8866 meni:0.8296 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.5146 | Train Avg AUC : 0.8699 abnorm:0.8887 acl:0.8883 meni:0.8327 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.5087 | Train Avg AUC : 0.8666 abnorm:0.8767 acl:0.89 meni:0.8331 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.5067 | Train Avg AUC : 0.8664 abnorm:0.8724 acl:0.8906 meni:0.8361 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.5053 | Train Avg AUC : 0.8648 abnorm:0.874 acl:0.8872 meni:0.8331 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.5142 | Train Avg AUC : 0.8609 abnorm:0.8685 acl:0.8793 meni:0.835 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.5225 | Train Avg AUC : 0.8592 abnorm:0.8736 acl:0.8713 meni:0.8327 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.521 | Train Avg AUC : 0.858 abnorm:0.8705 acl:0.8715 meni:0.832 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.5316 | Train Avg AUC : 0.853 abnorm:0.8695 acl:0.8622 meni:0.8273 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.5328 | Train Avg AUC : 0.8544 abnorm:0.8731 acl:0.8621 meni:0.828 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.5339 | Train Avg AUC : 0.8549 abnorm:0.8719 acl:0.8637 meni:0.8292 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.5421 | Train Avg AUC : 0.848 abnorm:0.8637 acl:0.8527 meni:0.8276 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.5464 | Train Avg AUC : 0.8456 abnorm:0.864 acl:0.8533 meni:0.8196 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.5455 | Train Avg AUC : 0.8461 abnorm:0.8658 acl:0.8551 meni:0.8175 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.5469 | Train Avg AUC : 0.8453 abnorm:0.8671 acl:0.8507 meni:0.8181 | lr : 1e-05\n",
      "Epoch 5 End Train Avg AUC : 0.845 abnorm : 0.8677 acl : 0.8498 meni : 0.8175\n",
      "train loop ended, now val\n",
      "[Epoch: 6 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3443 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3191 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2899 | Val AUC : 0.619 abnorm:0.8571 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.3013 | Val AUC : 0.6103 abnorm:0.8309 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3393 | Val AUC : 0.9024 abnorm:0.8765 acl:0.9477 meni:0.883 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3663 | Val AUC : 0.8979 abnorm:0.8986 acl:0.8957 meni:0.8995 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3924 | Val AUC : 0.8875 abnorm:0.8954 acl:0.915 meni:0.8521 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4016 | Val AUC : 0.8893 abnorm:0.9094 acl:0.9318 meni:0.8268 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4162 | Val AUC : 0.8905 abnorm:0.9085 acl:0.9222 meni:0.8408 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4071 | Val AUC : 0.8967 abnorm:0.9184 acl:0.9129 meni:0.8587 | lr : 1e-05\n",
      "[Epoch: 6 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4043 | Val AUC : 0.8942 abnorm:0.9247 acl:0.9085 meni:0.8495 | lr : 1e-05\n",
      "Epoch 5 End Val Avg AUC : 0.8793 abnorm : 0.9213 acl : 0.8962 meni : 0.8204\n",
      "train loss : 0.5473 | train auc 0.845 | val loss 0.4227 | val auc 0.8793 | elapsed time 214.53016567230225 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 7 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4712 | Train Avg AUC : 0.8957 abnorm:0.8804 acl:0.9114 meni:0.8955 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.5198 | Train Avg AUC : 0.86 abnorm:0.8929 acl:0.8512 meni:0.836 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.5003 | Train Avg AUC : 0.8607 abnorm:0.872 acl:0.8766 meni:0.8333 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.5277 | Train Avg AUC : 0.8622 abnorm:0.8892 acl:0.8451 meni:0.8524 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.537 | Train Avg AUC : 0.8592 abnorm:0.8939 acl:0.8507 meni:0.8332 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.5542 | Train Avg AUC : 0.8505 abnorm:0.8901 acl:0.8436 meni:0.8179 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.5569 | Train Avg AUC : 0.8474 abnorm:0.8773 acl:0.8548 meni:0.8101 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.5521 | Train Avg AUC : 0.85 abnorm:0.8785 acl:0.8546 meni:0.8169 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.5313 | Train Avg AUC : 0.857 abnorm:0.878 acl:0.8718 meni:0.8211 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.5428 | Train Avg AUC : 0.8488 abnorm:0.8781 acl:0.8548 meni:0.8135 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.5476 | Train Avg AUC : 0.8439 abnorm:0.8778 acl:0.8503 meni:0.8036 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.5424 | Train Avg AUC : 0.8482 abnorm:0.8842 acl:0.8554 meni:0.805 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.5444 | Train Avg AUC : 0.8466 abnorm:0.8863 acl:0.8513 meni:0.802 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.5412 | Train Avg AUC : 0.8494 abnorm:0.8843 acl:0.8557 meni:0.8082 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.5392 | Train Avg AUC : 0.8494 abnorm:0.884 acl:0.8509 meni:0.8133 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.541 | Train Avg AUC : 0.8505 abnorm:0.8883 acl:0.8499 meni:0.8134 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.5398 | Train Avg AUC : 0.8521 abnorm:0.8879 acl:0.8546 meni:0.8138 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.5421 | Train Avg AUC : 0.8527 abnorm:0.8909 acl:0.8531 meni:0.8142 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.5397 | Train Avg AUC : 0.8534 abnorm:0.888 acl:0.8548 meni:0.8173 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.5346 | Train Avg AUC : 0.8576 abnorm:0.8889 acl:0.8594 meni:0.8245 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.5363 | Train Avg AUC : 0.856 abnorm:0.8901 acl:0.8623 meni:0.8158 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.5392 | Train Avg AUC : 0.8551 abnorm:0.8902 acl:0.8616 meni:0.8133 | lr : 1e-05\n",
      "Epoch 6 End Train Avg AUC : 0.8551 abnorm : 0.8889 acl : 0.8633 meni : 0.8132\n",
      "train loop ended, now val\n",
      "[Epoch: 7 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.4966 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.4442 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.396 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.4007 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.4216 | Val AUC : 0.8979 abnorm:0.8627 acl:0.9535 meni:0.8777 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.4452 | Val AUC : 0.8976 abnorm:0.8896 acl:0.9091 meni:0.8942 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4445 | Val AUC : 0.8937 abnorm:0.8892 acl:0.9285 meni:0.8634 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.449 | Val AUC : 0.8945 abnorm:0.905 acl:0.9423 meni:0.8362 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4577 | Val AUC : 0.8929 abnorm:0.9061 acl:0.9304 meni:0.8421 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4354 | Val AUC : 0.8984 abnorm:0.9163 acl:0.9192 meni:0.8596 | lr : 1e-05\n",
      "[Epoch: 7 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4219 | Val AUC : 0.8931 abnorm:0.9223 acl:0.9118 meni:0.8451 | lr : 1e-05\n",
      "Epoch 6 End Val Avg AUC : 0.8783 abnorm : 0.9187 acl : 0.9032 meni : 0.8131\n",
      "train loss : 0.538 | train auc 0.8551 | val loss 0.4289 | val auc 0.8783 | elapsed time 218.715434551239 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 8 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.5187 | Train Avg AUC : 0.874 abnorm:0.8818 acl:0.8868 meni:0.8536 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.5006 | Train Avg AUC : 0.8717 abnorm:0.8778 acl:0.8922 meni:0.8453 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.5019 | Train Avg AUC : 0.8717 abnorm:0.8815 acl:0.8911 meni:0.8425 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.5309 | Train Avg AUC : 0.8645 abnorm:0.9015 acl:0.8649 meni:0.8272 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.5269 | Train Avg AUC : 0.8623 abnorm:0.9076 acl:0.8648 meni:0.8145 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.519 | Train Avg AUC : 0.8692 abnorm:0.9108 acl:0.8658 meni:0.8309 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.5167 | Train Avg AUC : 0.8665 abnorm:0.9046 acl:0.8571 meni:0.8376 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.5141 | Train Avg AUC : 0.8687 abnorm:0.9026 acl:0.8659 meni:0.8377 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.511 | Train Avg AUC : 0.8723 abnorm:0.906 acl:0.8702 meni:0.8408 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.5206 | Train Avg AUC : 0.8652 abnorm:0.8996 acl:0.8635 meni:0.8325 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.5234 | Train Avg AUC : 0.8657 abnorm:0.8987 acl:0.8646 meni:0.8338 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.5322 | Train Avg AUC : 0.8614 abnorm:0.8938 acl:0.8605 meni:0.8299 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.5382 | Train Avg AUC : 0.8583 abnorm:0.8949 acl:0.8525 meni:0.8274 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.5453 | Train Avg AUC : 0.8543 abnorm:0.8879 acl:0.8545 meni:0.8206 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.5359 | Train Avg AUC : 0.8574 abnorm:0.887 acl:0.8625 meni:0.8226 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.5296 | Train Avg AUC : 0.8605 abnorm:0.8877 acl:0.8664 meni:0.8274 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.5314 | Train Avg AUC : 0.8608 abnorm:0.8915 acl:0.8661 meni:0.8248 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.5321 | Train Avg AUC : 0.8601 abnorm:0.8928 acl:0.8627 meni:0.8249 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.5337 | Train Avg AUC : 0.8581 abnorm:0.8897 acl:0.8632 meni:0.8214 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.5345 | Train Avg AUC : 0.8579 abnorm:0.8898 acl:0.8641 meni:0.8197 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.5304 | Train Avg AUC : 0.8575 abnorm:0.8858 acl:0.8683 meni:0.8183 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.53 | Train Avg AUC : 0.858 abnorm:0.8864 acl:0.8704 meni:0.8173 | lr : 1e-05\n",
      "Epoch 7 End Train Avg AUC : 0.8591 abnorm : 0.8856 acl : 0.872 meni : 0.8197\n",
      "train loop ended, now val\n",
      "[Epoch: 8 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.2562 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.219 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2049 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2278 | Val AUC : 0.6062 abnorm:0.8186 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.283 | Val AUC : 0.898 abnorm:0.8657 acl:0.9506 meni:0.8777 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3245 | Val AUC : 0.901 abnorm:0.893 acl:0.9051 meni:0.9048 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3623 | Val AUC : 0.8936 abnorm:0.891 acl:0.9251 meni:0.8647 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3768 | Val AUC : 0.8948 abnorm:0.9064 acl:0.9392 meni:0.8387 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4029 | Val AUC : 0.894 abnorm:0.9097 acl:0.929 meni:0.8434 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.3957 | Val AUC : 0.901 abnorm:0.9195 acl:0.918 meni:0.8654 | lr : 1e-05\n",
      "[Epoch: 8 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4011 | Val AUC : 0.8949 abnorm:0.9247 acl:0.9114 meni:0.8485 | lr : 1e-05\n",
      "Epoch 7 End Val Avg AUC : 0.8773 abnorm : 0.9204 acl : 0.9024 meni : 0.8091\n",
      "train loss : 0.5274 | train auc 0.8591 | val loss 0.4322 | val auc 0.8773 | elapsed time 220.06642889976501 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 9 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4805 | Train Avg AUC : 0.906 abnorm:0.9517 acl:0.9471 meni:0.819 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.5034 | Train Avg AUC : 0.8675 abnorm:0.8821 acl:0.8713 meni:0.849 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.5038 | Train Avg AUC : 0.8742 abnorm:0.9063 acl:0.868 meni:0.8483 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.503 | Train Avg AUC : 0.8802 abnorm:0.914 acl:0.8837 meni:0.843 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4941 | Train Avg AUC : 0.8803 abnorm:0.8932 acl:0.8936 meni:0.8541 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.5106 | Train Avg AUC : 0.8676 abnorm:0.8814 acl:0.8867 meni:0.8348 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.5314 | Train Avg AUC : 0.8595 abnorm:0.885 acl:0.8736 meni:0.82 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.5274 | Train Avg AUC : 0.8631 abnorm:0.8908 acl:0.872 meni:0.8264 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.5257 | Train Avg AUC : 0.8643 abnorm:0.8891 acl:0.874 meni:0.8298 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.527 | Train Avg AUC : 0.8644 abnorm:0.8947 acl:0.8704 meni:0.8281 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.5211 | Train Avg AUC : 0.8644 abnorm:0.8956 acl:0.8687 meni:0.829 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.523 | Train Avg AUC : 0.8631 abnorm:0.8917 acl:0.8711 meni:0.8265 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.5287 | Train Avg AUC : 0.8594 abnorm:0.8892 acl:0.8654 meni:0.8237 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.5296 | Train Avg AUC : 0.861 abnorm:0.8921 acl:0.8649 meni:0.826 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.5246 | Train Avg AUC : 0.8634 abnorm:0.8941 acl:0.8699 meni:0.8261 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.5247 | Train Avg AUC : 0.8624 abnorm:0.8885 acl:0.8701 meni:0.8287 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.5185 | Train Avg AUC : 0.8635 abnorm:0.8874 acl:0.8749 meni:0.8283 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.5171 | Train Avg AUC : 0.8633 abnorm:0.8887 acl:0.8755 meni:0.8259 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.5118 | Train Avg AUC : 0.8644 abnorm:0.8891 acl:0.8772 meni:0.8269 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.5086 | Train Avg AUC : 0.8656 abnorm:0.8869 acl:0.8817 meni:0.8282 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.507 | Train Avg AUC : 0.8672 abnorm:0.888 acl:0.8816 meni:0.8318 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.5096 | Train Avg AUC : 0.8661 abnorm:0.8872 acl:0.8798 meni:0.8313 | lr : 1e-05\n",
      "Epoch 8 End Train Avg AUC : 0.8669 abnorm : 0.8889 acl : 0.8809 meni : 0.8308\n",
      "train loop ended, now val\n",
      "[Epoch: 9 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3994 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3419 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.3315 | Val AUC : 0.6032 abnorm:0.8095 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.371 | Val AUC : 0.6013 abnorm:0.8039 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3853 | Val AUC : 0.8986 abnorm:0.8565 acl:0.9564 meni:0.883 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.4016 | Val AUC : 0.9045 abnorm:0.8863 acl:0.9305 meni:0.8968 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3978 | Val AUC : 0.9003 abnorm:0.8892 acl:0.9419 meni:0.8697 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4014 | Val AUC : 0.9011 abnorm:0.9057 acl:0.9545 meni:0.843 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4018 | Val AUC : 0.9028 abnorm:0.9073 acl:0.9488 meni:0.8523 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.3923 | Val AUC : 0.9068 abnorm:0.9168 acl:0.9318 meni:0.8717 | lr : 1e-05\n",
      "[Epoch: 9 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.391 | Val AUC : 0.8979 abnorm:0.9214 acl:0.9235 meni:0.8488 | lr : 1e-05\n",
      "Epoch 8 End Val Avg AUC : 0.8814 abnorm : 0.9179 acl : 0.9153 meni : 0.8111\n",
      "train loss : 0.5104 | train auc 0.8669 | val loss 0.4021 | val auc 0.8814 | elapsed time 218.4039044380188 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 10 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.5118 | Train Avg AUC : 0.8369 abnorm:0.9474 acl:0.6522 meni:0.9111 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.51 | Train Avg AUC : 0.861 abnorm:0.916 acl:0.7677 meni:0.8994 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.5028 | Train Avg AUC : 0.8744 abnorm:0.8989 acl:0.8108 meni:0.9134 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.5273 | Train Avg AUC : 0.8659 abnorm:0.9064 acl:0.827 meni:0.8645 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.5368 | Train Avg AUC : 0.8638 abnorm:0.9016 acl:0.8379 meni:0.852 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.5297 | Train Avg AUC : 0.867 abnorm:0.905 acl:0.8517 meni:0.8444 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.5278 | Train Avg AUC : 0.8702 abnorm:0.9031 acl:0.8693 meni:0.8382 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.5174 | Train Avg AUC : 0.8757 abnorm:0.905 acl:0.8779 meni:0.8443 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.5135 | Train Avg AUC : 0.8782 abnorm:0.912 acl:0.88 meni:0.8426 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.5079 | Train Avg AUC : 0.8784 abnorm:0.9082 acl:0.8905 meni:0.8365 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.502 | Train Avg AUC : 0.8779 abnorm:0.9067 acl:0.8915 meni:0.8354 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.5098 | Train Avg AUC : 0.8729 abnorm:0.9017 acl:0.8889 meni:0.8282 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.505 | Train Avg AUC : 0.8745 abnorm:0.9033 acl:0.8886 meni:0.8315 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.5004 | Train Avg AUC : 0.8759 abnorm:0.9033 acl:0.8946 meni:0.8297 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.503 | Train Avg AUC : 0.8771 abnorm:0.9076 acl:0.8912 meni:0.8325 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4945 | Train Avg AUC : 0.8796 abnorm:0.9054 acl:0.8959 meni:0.8377 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.5019 | Train Avg AUC : 0.8756 abnorm:0.9033 acl:0.8858 meni:0.8376 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.5034 | Train Avg AUC : 0.8748 abnorm:0.9027 acl:0.8841 meni:0.8376 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.5012 | Train Avg AUC : 0.8751 abnorm:0.9018 acl:0.8874 meni:0.8361 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4985 | Train Avg AUC : 0.875 abnorm:0.9018 acl:0.8886 meni:0.8346 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.5037 | Train Avg AUC : 0.8717 abnorm:0.9002 acl:0.8848 meni:0.8302 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.5086 | Train Avg AUC : 0.8689 abnorm:0.8973 acl:0.8836 meni:0.8259 | lr : 1e-05\n",
      "Epoch 9 End Train Avg AUC : 0.87 abnorm : 0.8962 acl : 0.8849 meni : 0.8289\n",
      "train loop ended, now val\n",
      "[Epoch: 10 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3326 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.2849 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2634 | Val AUC : 0.6151 abnorm:0.8452 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2856 | Val AUC : 0.607 abnorm:0.8211 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3121 | Val AUC : 0.8978 abnorm:0.8719 acl:0.9651 meni:0.8564 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3343 | Val AUC : 0.898 abnorm:0.8986 acl:0.9198 meni:0.8757 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3525 | Val AUC : 0.8875 abnorm:0.8989 acl:0.9327 meni:0.8308 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3544 | Val AUC : 0.8913 abnorm:0.913 acl:0.9459 meni:0.8149 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.3617 | Val AUC : 0.895 abnorm:0.9152 acl:0.9411 meni:0.8286 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.3583 | Val AUC : 0.9032 abnorm:0.9242 acl:0.9306 meni:0.8547 | lr : 1e-05\n",
      "[Epoch: 10 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3671 | Val AUC : 0.8983 abnorm:0.9288 acl:0.9235 meni:0.8427 | lr : 1e-05\n",
      "Epoch 9 End Val Avg AUC : 0.8823 abnorm : 0.9251 acl : 0.9153 meni : 0.8066\n",
      "train loss : 0.5074 | train auc 0.87 | val loss 0.3919 | val auc 0.8823 | elapsed time 221.4377658367157 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 11 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4827 | Train Avg AUC : 0.8225 abnorm:0.8841 acl:0.7565 meni:0.8268 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.475 | Train Avg AUC : 0.8574 abnorm:0.8932 acl:0.8131 meni:0.8659 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.478 | Train Avg AUC : 0.8841 abnorm:0.9126 acl:0.8829 meni:0.857 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4931 | Train Avg AUC : 0.8787 abnorm:0.9239 acl:0.8719 meni:0.8401 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4983 | Train Avg AUC : 0.8784 abnorm:0.922 acl:0.874 meni:0.8393 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.5044 | Train Avg AUC : 0.8728 abnorm:0.9045 acl:0.8739 meni:0.8399 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.5137 | Train Avg AUC : 0.8684 abnorm:0.9007 acl:0.8707 meni:0.8337 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.5118 | Train Avg AUC : 0.8692 abnorm:0.9029 acl:0.8723 meni:0.8324 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.5063 | Train Avg AUC : 0.874 abnorm:0.9041 acl:0.8771 meni:0.8409 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.5034 | Train Avg AUC : 0.877 abnorm:0.9036 acl:0.8739 meni:0.8534 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4987 | Train Avg AUC : 0.8772 abnorm:0.8957 acl:0.886 meni:0.8499 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.5032 | Train Avg AUC : 0.8756 abnorm:0.8965 acl:0.8878 meni:0.8425 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.497 | Train Avg AUC : 0.8768 abnorm:0.8948 acl:0.8925 meni:0.8433 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4943 | Train Avg AUC : 0.875 abnorm:0.8894 acl:0.8962 meni:0.8393 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.5 | Train Avg AUC : 0.8739 abnorm:0.8936 acl:0.8913 meni:0.8368 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4956 | Train Avg AUC : 0.8755 abnorm:0.8955 acl:0.8934 meni:0.8377 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.4948 | Train Avg AUC : 0.8767 abnorm:0.8964 acl:0.8924 meni:0.8411 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4951 | Train Avg AUC : 0.8773 abnorm:0.8991 acl:0.8917 meni:0.8412 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4921 | Train Avg AUC : 0.8777 abnorm:0.8971 acl:0.8946 meni:0.8414 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4903 | Train Avg AUC : 0.878 abnorm:0.896 acl:0.8939 meni:0.844 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4978 | Train Avg AUC : 0.8743 abnorm:0.8929 acl:0.888 meni:0.8421 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4959 | Train Avg AUC : 0.8751 abnorm:0.8907 acl:0.8918 meni:0.8427 | lr : 1e-05\n",
      "Epoch 10 End Train Avg AUC : 0.8763 abnorm : 0.8915 acl : 0.8926 meni : 0.8448\n",
      "train loop ended, now val\n",
      "[Epoch: 11 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.5062 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.4681 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.4229 | Val AUC : 0.6032 abnorm:0.8095 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.4218 | Val AUC : 0.6021 abnorm:0.8064 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.4525 | Val AUC : 0.9129 abnorm:0.8611 acl:0.968 meni:0.9096 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.5013 | Val AUC : 0.9034 abnorm:0.8896 acl:0.9184 meni:0.9021 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.5078 | Val AUC : 0.8976 abnorm:0.8901 acl:0.9343 meni:0.8684 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.5161 | Val AUC : 0.8991 abnorm:0.9064 acl:0.9472 meni:0.8438 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.532 | Val AUC : 0.9021 abnorm:0.9097 acl:0.9411 meni:0.8555 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4955 | Val AUC : 0.907 abnorm:0.9195 acl:0.9318 meni:0.8699 | lr : 1e-05\n",
      "[Epoch: 11 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4699 | Val AUC : 0.9035 abnorm:0.9251 acl:0.9255 meni:0.8598 | lr : 1e-05\n",
      "Epoch 10 End Val Avg AUC : 0.8905 abnorm : 0.9225 acl : 0.9209 meni : 0.8281\n",
      "train loss : 0.494 | train auc 0.8763 | val loss 0.4688 | val auc 0.8905 | elapsed time 217.13087034225464 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 12 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.5493 | Train Avg AUC : 0.8609 abnorm:0.8721 acl:0.8707 meni:0.8401 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.5291 | Train Avg AUC : 0.8629 abnorm:0.8833 acl:0.835 meni:0.8705 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.5077 | Train Avg AUC : 0.8696 abnorm:0.8954 acl:0.8532 meni:0.8602 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4803 | Train Avg AUC : 0.875 abnorm:0.8883 acl:0.8699 meni:0.8666 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4738 | Train Avg AUC : 0.8772 abnorm:0.8959 acl:0.8704 meni:0.8655 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4929 | Train Avg AUC : 0.8702 abnorm:0.8921 acl:0.8731 meni:0.8453 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4901 | Train Avg AUC : 0.8737 abnorm:0.8985 acl:0.885 meni:0.8377 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4993 | Train Avg AUC : 0.8688 abnorm:0.8953 acl:0.8867 meni:0.8245 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.5123 | Train Avg AUC : 0.8662 abnorm:0.8974 acl:0.8827 meni:0.8184 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4995 | Train Avg AUC : 0.8691 abnorm:0.8931 acl:0.8873 meni:0.8268 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.5003 | Train Avg AUC : 0.868 abnorm:0.8869 acl:0.8924 meni:0.8249 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.4994 | Train Avg AUC : 0.8697 abnorm:0.8836 acl:0.8929 meni:0.8327 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.4931 | Train Avg AUC : 0.8707 abnorm:0.8871 acl:0.8973 meni:0.8278 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4888 | Train Avg AUC : 0.8745 abnorm:0.8893 acl:0.8991 meni:0.8352 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.4827 | Train Avg AUC : 0.8752 abnorm:0.886 acl:0.8988 meni:0.8409 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4838 | Train Avg AUC : 0.8782 abnorm:0.8893 acl:0.8992 meni:0.8459 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.4842 | Train Avg AUC : 0.8784 abnorm:0.8918 acl:0.8995 meni:0.8439 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4888 | Train Avg AUC : 0.8751 abnorm:0.8871 acl:0.901 meni:0.8371 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4847 | Train Avg AUC : 0.8764 abnorm:0.8888 acl:0.9039 meni:0.8363 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4816 | Train Avg AUC : 0.878 abnorm:0.8898 acl:0.9016 meni:0.8426 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4836 | Train Avg AUC : 0.8771 abnorm:0.8903 acl:0.8996 meni:0.8415 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4834 | Train Avg AUC : 0.8779 abnorm:0.892 acl:0.9003 meni:0.8415 | lr : 1e-05\n",
      "Epoch 11 End Train Avg AUC : 0.8787 abnorm : 0.8938 acl : 0.9022 meni : 0.8401\n",
      "train loop ended, now val\n",
      "[Epoch: 12 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3853 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3302 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2856 | Val AUC : 0.5992 abnorm:0.7976 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2888 | Val AUC : 0.5997 abnorm:0.799 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.317 | Val AUC : 0.8915 abnorm:0.8534 acl:0.9593 meni:0.8617 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3418 | Val AUC : 0.8931 abnorm:0.884 acl:0.9171 meni:0.8783 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.362 | Val AUC : 0.8883 abnorm:0.8892 acl:0.9335 meni:0.8421 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3635 | Val AUC : 0.8924 abnorm:0.905 acl:0.9472 meni:0.8251 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.3715 | Val AUC : 0.8975 abnorm:0.9079 acl:0.9425 meni:0.8421 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.365 | Val AUC : 0.9038 abnorm:0.9168 acl:0.9322 meni:0.8623 | lr : 1e-05\n",
      "[Epoch: 12 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3667 | Val AUC : 0.9014 abnorm:0.9223 acl:0.9271 meni:0.8547 | lr : 1e-05\n",
      "Epoch 11 End Val Avg AUC : 0.8873 abnorm : 0.9196 acl : 0.9223 meni : 0.8201\n",
      "train loss : 0.4846 | train auc 0.8787 | val loss 0.388 | val auc 0.8873 | elapsed time 216.10747265815735 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 13 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3808 | Train Avg AUC : 0.9327 abnorm:0.918 acl:0.9722 meni:0.9079 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4746 | Train Avg AUC : 0.8957 abnorm:0.9178 acl:0.9045 meni:0.8648 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.465 | Train Avg AUC : 0.8982 abnorm:0.9146 acl:0.9089 meni:0.871 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4771 | Train Avg AUC : 0.8793 abnorm:0.8883 acl:0.9019 meni:0.8475 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4757 | Train Avg AUC : 0.8799 abnorm:0.8873 acl:0.8913 meni:0.861 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4747 | Train Avg AUC : 0.8806 abnorm:0.8908 acl:0.8971 meni:0.8538 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4721 | Train Avg AUC : 0.8818 abnorm:0.8857 acl:0.9 meni:0.8598 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4842 | Train Avg AUC : 0.8783 abnorm:0.8926 acl:0.8962 meni:0.8462 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4867 | Train Avg AUC : 0.8782 abnorm:0.8961 acl:0.8951 meni:0.8436 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4836 | Train Avg AUC : 0.8761 abnorm:0.8863 acl:0.8985 meni:0.8434 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4784 | Train Avg AUC : 0.8794 abnorm:0.8906 acl:0.906 meni:0.8417 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.4709 | Train Avg AUC : 0.8846 abnorm:0.8963 acl:0.9118 meni:0.8457 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.4759 | Train Avg AUC : 0.8814 abnorm:0.8945 acl:0.9084 meni:0.8414 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4711 | Train Avg AUC : 0.8829 abnorm:0.8953 acl:0.9147 meni:0.8387 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.4698 | Train Avg AUC : 0.8837 abnorm:0.8952 acl:0.917 meni:0.8389 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4747 | Train Avg AUC : 0.8828 abnorm:0.8958 acl:0.9126 meni:0.8399 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.4755 | Train Avg AUC : 0.882 abnorm:0.8975 acl:0.9069 meni:0.8417 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4765 | Train Avg AUC : 0.8822 abnorm:0.8946 acl:0.9055 meni:0.8465 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4833 | Train Avg AUC : 0.879 abnorm:0.8904 acl:0.9017 meni:0.845 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.485 | Train Avg AUC : 0.8791 abnorm:0.8934 acl:0.9019 meni:0.8419 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4877 | Train Avg AUC : 0.8787 abnorm:0.8959 acl:0.8993 meni:0.8408 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4888 | Train Avg AUC : 0.8776 abnorm:0.8937 acl:0.8957 meni:0.8433 | lr : 1e-05\n",
      "Epoch 12 End Train Avg AUC : 0.8792 abnorm : 0.8959 acl : 0.8961 meni : 0.8458\n",
      "train loop ended, now val\n",
      "[Epoch: 13 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3791 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3291 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2847 | Val AUC : 0.6091 abnorm:0.8274 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2798 | Val AUC : 0.6054 abnorm:0.8162 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3237 | Val AUC : 0.9062 abnorm:0.8704 acl:0.9651 meni:0.883 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3674 | Val AUC : 0.8968 abnorm:0.8964 acl:0.8971 meni:0.8968 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3957 | Val AUC : 0.8939 abnorm:0.9016 acl:0.9192 meni:0.8609 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3984 | Val AUC : 0.8985 abnorm:0.9152 acl:0.9373 meni:0.843 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4154 | Val AUC : 0.9011 abnorm:0.917 acl:0.9329 meni:0.8536 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4002 | Val AUC : 0.9062 abnorm:0.9253 acl:0.9275 meni:0.8659 | lr : 1e-05\n",
      "[Epoch: 13 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3954 | Val AUC : 0.9012 abnorm:0.9298 acl:0.9232 meni:0.8505 | lr : 1e-05\n",
      "Epoch 12 End Val Avg AUC : 0.8865 abnorm : 0.9272 acl : 0.9206 meni : 0.8117\n",
      "train loss : 0.4867 | train auc 0.8792 | val loss 0.4147 | val auc 0.8865 | elapsed time 216.15816855430603 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 14 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4215 | Train Avg AUC : 0.9319 abnorm:0.9466 acl:0.9432 meni:0.906 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4393 | Train Avg AUC : 0.9057 abnorm:0.9063 acl:0.9463 meni:0.8644 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4621 | Train Avg AUC : 0.9002 abnorm:0.9026 acl:0.942 meni:0.8562 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4604 | Train Avg AUC : 0.8954 abnorm:0.9094 acl:0.939 meni:0.8379 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4572 | Train Avg AUC : 0.8867 abnorm:0.8804 acl:0.9446 meni:0.835 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4691 | Train Avg AUC : 0.8839 abnorm:0.8827 acl:0.9283 meni:0.8408 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4833 | Train Avg AUC : 0.882 abnorm:0.8933 acl:0.9097 meni:0.8428 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4756 | Train Avg AUC : 0.8864 abnorm:0.8982 acl:0.91 meni:0.8511 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4856 | Train Avg AUC : 0.8817 abnorm:0.8973 acl:0.9022 meni:0.8456 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4797 | Train Avg AUC : 0.8823 abnorm:0.8992 acl:0.8985 meni:0.8492 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4837 | Train Avg AUC : 0.8794 abnorm:0.8965 acl:0.8956 meni:0.8462 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.4883 | Train Avg AUC : 0.8781 abnorm:0.8935 acl:0.8944 meni:0.8464 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.487 | Train Avg AUC : 0.88 abnorm:0.8979 acl:0.8973 meni:0.8447 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4852 | Train Avg AUC : 0.8819 abnorm:0.9021 acl:0.8997 meni:0.8438 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.4791 | Train Avg AUC : 0.8848 abnorm:0.9051 acl:0.903 meni:0.8463 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.483 | Train Avg AUC : 0.8833 abnorm:0.9032 acl:0.8981 meni:0.8487 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.4856 | Train Avg AUC : 0.8816 abnorm:0.9024 acl:0.8936 meni:0.8489 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4792 | Train Avg AUC : 0.8848 abnorm:0.9031 acl:0.8995 meni:0.8517 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4826 | Train Avg AUC : 0.8828 abnorm:0.9003 acl:0.8973 meni:0.8508 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4814 | Train Avg AUC : 0.8847 abnorm:0.9033 acl:0.8998 meni:0.851 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4801 | Train Avg AUC : 0.8847 abnorm:0.903 acl:0.8994 meni:0.8516 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4795 | Train Avg AUC : 0.885 abnorm:0.9043 acl:0.904 meni:0.8466 | lr : 1e-05\n",
      "Epoch 13 End Train Avg AUC : 0.8851 abnorm : 0.9042 acl : 0.905 meni : 0.846\n",
      "train loop ended, now val\n",
      "[Epoch: 14 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3545 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3009 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2577 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2511 | Val AUC : 0.6062 abnorm:0.8186 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.306 | Val AUC : 0.9037 abnorm:0.8688 acl:0.9593 meni:0.883 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3562 | Val AUC : 0.8973 abnorm:0.8953 acl:0.9051 meni:0.8915 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3924 | Val AUC : 0.8911 abnorm:0.8945 acl:0.9242 meni:0.8546 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3966 | Val AUC : 0.8953 abnorm:0.9101 acl:0.9404 meni:0.8353 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4219 | Val AUC : 0.8983 abnorm:0.9127 acl:0.9362 meni:0.8459 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4084 | Val AUC : 0.9054 abnorm:0.9216 acl:0.9275 meni:0.8672 | lr : 1e-05\n",
      "[Epoch: 14 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.407 | Val AUC : 0.8999 abnorm:0.927 acl:0.9225 meni:0.8502 | lr : 1e-05\n",
      "Epoch 13 End Val Avg AUC : 0.8862 abnorm : 0.9238 acl : 0.9198 meni : 0.815\n",
      "train loss : 0.4783 | train auc 0.8851 | val loss 0.4292 | val auc 0.8862 | elapsed time 218.08373069763184 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 15 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.5018 | Train Avg AUC : 0.8966 abnorm:0.937 acl:0.8947 meni:0.8581 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4816 | Train Avg AUC : 0.8937 abnorm:0.917 acl:0.9069 meni:0.8571 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4937 | Train Avg AUC : 0.8828 abnorm:0.9232 acl:0.9006 meni:0.8248 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4618 | Train Avg AUC : 0.8988 abnorm:0.9219 acl:0.9227 meni:0.8519 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4547 | Train Avg AUC : 0.9031 abnorm:0.9281 acl:0.9289 meni:0.8523 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4498 | Train Avg AUC : 0.9033 abnorm:0.9354 acl:0.9294 meni:0.8452 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4522 | Train Avg AUC : 0.9014 abnorm:0.9342 acl:0.9229 meni:0.847 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4543 | Train Avg AUC : 0.9 abnorm:0.9253 acl:0.9215 meni:0.8534 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4525 | Train Avg AUC : 0.9011 abnorm:0.9217 acl:0.9178 meni:0.8638 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4584 | Train Avg AUC : 0.8966 abnorm:0.9183 acl:0.911 meni:0.8606 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4544 | Train Avg AUC : 0.8979 abnorm:0.92 acl:0.9158 meni:0.8578 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.4551 | Train Avg AUC : 0.895 abnorm:0.9165 acl:0.9158 meni:0.8528 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.4569 | Train Avg AUC : 0.8945 abnorm:0.9141 acl:0.9143 meni:0.855 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4561 | Train Avg AUC : 0.8953 abnorm:0.9133 acl:0.9187 meni:0.8538 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.4644 | Train Avg AUC : 0.8924 abnorm:0.9146 acl:0.9101 meni:0.8525 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4698 | Train Avg AUC : 0.889 abnorm:0.9129 acl:0.9067 meni:0.8474 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.466 | Train Avg AUC : 0.8882 abnorm:0.9089 acl:0.9101 meni:0.8456 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4698 | Train Avg AUC : 0.887 abnorm:0.9082 acl:0.9064 meni:0.8465 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4712 | Train Avg AUC : 0.8868 abnorm:0.9059 acl:0.9041 meni:0.8505 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4727 | Train Avg AUC : 0.8862 abnorm:0.9053 acl:0.9027 meni:0.8507 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4738 | Train Avg AUC : 0.8861 abnorm:0.9038 acl:0.9046 meni:0.8497 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4774 | Train Avg AUC : 0.8852 abnorm:0.9059 acl:0.906 meni:0.8437 | lr : 1e-05\n",
      "Epoch 14 End Train Avg AUC : 0.8852 abnorm : 0.9038 acl : 0.9077 meni : 0.8441\n",
      "train loop ended, now val\n",
      "[Epoch: 15 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3293 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.2813 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.251 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.248 | Val AUC : 0.6062 abnorm:0.8186 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3215 | Val AUC : 0.9082 abnorm:0.8688 acl:0.9622 meni:0.8936 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3884 | Val AUC : 0.8986 abnorm:0.8953 acl:0.8957 meni:0.9048 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4389 | Val AUC : 0.8905 abnorm:0.9007 acl:0.92 meni:0.8509 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4486 | Val AUC : 0.8951 abnorm:0.9145 acl:0.938 meni:0.8328 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4785 | Val AUC : 0.9017 abnorm:0.9176 acl:0.9391 meni:0.8485 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4582 | Val AUC : 0.9093 abnorm:0.9253 acl:0.9341 meni:0.8685 | lr : 1e-05\n",
      "[Epoch: 15 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4468 | Val AUC : 0.9045 abnorm:0.9293 acl:0.9297 meni:0.8543 | lr : 1e-05\n",
      "Epoch 14 End Val Avg AUC : 0.891 abnorm : 0.9255 acl : 0.9273 meni : 0.8201\n",
      "train loss : 0.4747 | train auc 0.8852 | val loss 0.4628 | val auc 0.891 | elapsed time 218.19205784797668 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 16 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.463 | Train Avg AUC : 0.8993 abnorm:0.9593 acl:0.9402 meni:0.7985 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4515 | Train Avg AUC : 0.9043 abnorm:0.9364 acl:0.9284 meni:0.8482 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.447 | Train Avg AUC : 0.8961 abnorm:0.888 acl:0.9341 meni:0.8664 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4564 | Train Avg AUC : 0.8937 abnorm:0.8872 acl:0.9204 meni:0.8736 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4585 | Train Avg AUC : 0.8945 abnorm:0.8952 acl:0.9195 meni:0.8687 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4628 | Train Avg AUC : 0.8959 abnorm:0.9006 acl:0.9183 meni:0.869 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4615 | Train Avg AUC : 0.8951 abnorm:0.8944 acl:0.9195 meni:0.8714 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4559 | Train Avg AUC : 0.8967 abnorm:0.8923 acl:0.9204 meni:0.8775 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4534 | Train Avg AUC : 0.8989 abnorm:0.8951 acl:0.9185 meni:0.8829 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4609 | Train Avg AUC : 0.8937 abnorm:0.8958 acl:0.9141 meni:0.8712 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4625 | Train Avg AUC : 0.8971 abnorm:0.9041 acl:0.9124 meni:0.8747 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.468 | Train Avg AUC : 0.8939 abnorm:0.9033 acl:0.9137 meni:0.8646 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.4743 | Train Avg AUC : 0.8901 abnorm:0.9027 acl:0.912 meni:0.8556 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4767 | Train Avg AUC : 0.8852 abnorm:0.894 acl:0.912 meni:0.8497 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.4747 | Train Avg AUC : 0.8861 abnorm:0.8952 acl:0.914 meni:0.8491 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4722 | Train Avg AUC : 0.8864 abnorm:0.8939 acl:0.9133 meni:0.8518 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.4703 | Train Avg AUC : 0.8861 abnorm:0.8889 acl:0.9159 meni:0.8536 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4693 | Train Avg AUC : 0.8875 abnorm:0.8927 acl:0.9156 meni:0.8544 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4656 | Train Avg AUC : 0.8886 abnorm:0.8959 acl:0.9153 meni:0.8546 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4644 | Train Avg AUC : 0.8888 abnorm:0.8967 acl:0.9161 meni:0.8537 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4637 | Train Avg AUC : 0.889 abnorm:0.8993 acl:0.916 meni:0.8516 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.461 | Train Avg AUC : 0.8913 abnorm:0.9041 acl:0.9183 meni:0.8514 | lr : 1e-05\n",
      "Epoch 15 End Train Avg AUC : 0.8918 abnorm : 0.9051 acl : 0.9191 meni : 0.8512\n",
      "train loop ended, now val\n",
      "[Epoch: 16 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.738 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.6687 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.5903 | Val AUC : 0.6091 abnorm:0.8274 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.571 | Val AUC : 0.5964 abnorm:0.7892 acl:0.5 meni:0.5 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.5555 | Val AUC : 0.9057 abnorm:0.8534 acl:0.9593 meni:0.9043 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.5805 | Val AUC : 0.9001 abnorm:0.8851 acl:0.9078 meni:0.9074 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.5511 | Val AUC : 0.8946 abnorm:0.8927 acl:0.9276 meni:0.8634 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.5428 | Val AUC : 0.8994 abnorm:0.9079 acl:0.9423 meni:0.848 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.5391 | Val AUC : 0.9045 abnorm:0.9152 acl:0.9415 meni:0.8568 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.5037 | Val AUC : 0.9111 abnorm:0.9237 acl:0.9361 meni:0.8734 | lr : 1e-05\n",
      "[Epoch: 16 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4768 | Val AUC : 0.9063 abnorm:0.9288 acl:0.9324 meni:0.8577 | lr : 1e-05\n",
      "Epoch 15 End Val Avg AUC : 0.8933 abnorm : 0.9255 acl : 0.929 meni : 0.8255\n",
      "train loss : 0.4614 | train auc 0.8918 | val loss 0.4654 | val auc 0.8933 | elapsed time 218.13616371154785 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 17 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.454 | Train Avg AUC : 0.8954 abnorm:0.9167 acl:0.9324 meni:0.837 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4487 | Train Avg AUC : 0.8981 abnorm:0.8708 acl:0.9229 meni:0.9006 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4746 | Train Avg AUC : 0.8924 abnorm:0.8864 acl:0.9133 meni:0.8777 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4534 | Train Avg AUC : 0.8981 abnorm:0.8849 acl:0.9186 meni:0.8908 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4426 | Train Avg AUC : 0.9013 abnorm:0.8965 acl:0.925 meni:0.8825 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4329 | Train Avg AUC : 0.9067 abnorm:0.9054 acl:0.934 meni:0.8806 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4385 | Train Avg AUC : 0.9026 abnorm:0.8973 acl:0.9314 meni:0.8792 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4264 | Train Avg AUC : 0.9055 abnorm:0.8995 acl:0.9399 meni:0.877 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4223 | Train Avg AUC : 0.9071 abnorm:0.9027 acl:0.9392 meni:0.8794 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4184 | Train Avg AUC : 0.9057 abnorm:0.8949 acl:0.9435 meni:0.8788 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4165 | Train Avg AUC : 0.9083 abnorm:0.9001 acl:0.9456 meni:0.8791 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.4117 | Train Avg AUC : 0.9123 abnorm:0.904 acl:0.9476 meni:0.8855 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.414 | Train Avg AUC : 0.9122 abnorm:0.9056 acl:0.9472 meni:0.8838 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4193 | Train Avg AUC : 0.91 abnorm:0.9026 acl:0.9453 meni:0.8822 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.4211 | Train Avg AUC : 0.908 abnorm:0.8986 acl:0.9444 meni:0.881 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4233 | Train Avg AUC : 0.9082 abnorm:0.9001 acl:0.9442 meni:0.8802 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.4247 | Train Avg AUC : 0.907 abnorm:0.8993 acl:0.9423 meni:0.8794 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4235 | Train Avg AUC : 0.9068 abnorm:0.8992 acl:0.943 meni:0.8783 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4307 | Train Avg AUC : 0.9049 abnorm:0.9022 acl:0.9377 meni:0.8748 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4281 | Train Avg AUC : 0.9076 abnorm:0.9077 acl:0.9374 meni:0.8776 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4236 | Train Avg AUC : 0.9094 abnorm:0.9089 acl:0.9396 meni:0.8798 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4233 | Train Avg AUC : 0.9102 abnorm:0.9135 acl:0.9412 meni:0.876 | lr : 3e-06\n",
      "Epoch 16 End Train Avg AUC : 0.9124 abnorm : 0.916 acl : 0.9426 meni : 0.8785\n",
      "train loop ended, now val\n",
      "[Epoch: 17 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.377 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.324 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2934 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2949 | Val AUC : 0.607 abnorm:0.8211 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.348 | Val AUC : 0.9052 abnorm:0.8704 acl:0.9622 meni:0.883 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.4108 | Val AUC : 0.8967 abnorm:0.8975 acl:0.8957 meni:0.8968 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4369 | Val AUC : 0.8909 abnorm:0.8998 acl:0.9209 meni:0.8521 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.442 | Val AUC : 0.897 abnorm:0.9145 acl:0.938 meni:0.8387 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4696 | Val AUC : 0.9038 abnorm:0.9188 acl:0.9391 meni:0.8536 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4434 | Val AUC : 0.9121 abnorm:0.9274 acl:0.9345 meni:0.8743 | lr : 3e-06\n",
      "[Epoch: 17 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4262 | Val AUC : 0.9083 abnorm:0.9326 acl:0.9307 meni:0.8615 | lr : 3e-06\n",
      "Epoch 16 End Val Avg AUC : 0.8939 abnorm : 0.9284 acl : 0.9282 meni : 0.8252\n",
      "train loss : 0.419 | train auc 0.9124 | val loss 0.4386 | val auc 0.8939 | elapsed time 216.19104194641113 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 18 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.5051 | Train Avg AUC : 0.8636 abnorm:0.9091 acl:0.9091 meni:0.7727 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4721 | Train Avg AUC : 0.8529 abnorm:0.8507 acl:0.8788 meni:0.8292 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4401 | Train Avg AUC : 0.8903 abnorm:0.8781 acl:0.9226 meni:0.8704 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.433 | Train Avg AUC : 0.896 abnorm:0.8998 acl:0.9214 meni:0.8669 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4192 | Train Avg AUC : 0.898 abnorm:0.9068 acl:0.9281 meni:0.8592 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4172 | Train Avg AUC : 0.9052 abnorm:0.9214 acl:0.931 meni:0.8632 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4189 | Train Avg AUC : 0.9059 abnorm:0.9109 acl:0.9393 meni:0.8677 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4201 | Train Avg AUC : 0.9096 abnorm:0.9224 acl:0.9322 meni:0.8741 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4189 | Train Avg AUC : 0.9097 abnorm:0.918 acl:0.9353 meni:0.8757 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4231 | Train Avg AUC : 0.9101 abnorm:0.919 acl:0.9339 meni:0.8775 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4225 | Train Avg AUC : 0.9114 abnorm:0.9182 acl:0.9347 meni:0.8814 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.4234 | Train Avg AUC : 0.9118 abnorm:0.9196 acl:0.9357 meni:0.8802 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.4236 | Train Avg AUC : 0.9117 abnorm:0.9174 acl:0.9361 meni:0.8818 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4224 | Train Avg AUC : 0.9126 abnorm:0.9168 acl:0.9344 meni:0.8867 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.4264 | Train Avg AUC : 0.9112 abnorm:0.9171 acl:0.9328 meni:0.8836 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4214 | Train Avg AUC : 0.9126 abnorm:0.9165 acl:0.937 meni:0.8844 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.4241 | Train Avg AUC : 0.9117 abnorm:0.919 acl:0.9374 meni:0.8785 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4228 | Train Avg AUC : 0.912 abnorm:0.9206 acl:0.9377 meni:0.8777 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4181 | Train Avg AUC : 0.9135 abnorm:0.9178 acl:0.9408 meni:0.8818 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4202 | Train Avg AUC : 0.9123 abnorm:0.9167 acl:0.9402 meni:0.8799 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4167 | Train Avg AUC : 0.9127 abnorm:0.9144 acl:0.9443 meni:0.8794 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4164 | Train Avg AUC : 0.914 abnorm:0.9151 acl:0.9408 meni:0.8861 | lr : 3e-06\n",
      "Epoch 17 End Train Avg AUC : 0.9142 abnorm : 0.9158 acl : 0.9416 meni : 0.8852\n",
      "train loop ended, now val\n",
      "[Epoch: 18 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.404 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3295 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2903 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2918 | Val AUC : 0.6046 abnorm:0.8137 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3242 | Val AUC : 0.9051 abnorm:0.8673 acl:0.9651 meni:0.883 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3712 | Val AUC : 0.8955 abnorm:0.8953 acl:0.8997 meni:0.8915 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3862 | Val AUC : 0.8915 abnorm:0.8989 acl:0.9234 meni:0.8521 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3861 | Val AUC : 0.8979 abnorm:0.9137 acl:0.9404 meni:0.8396 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4015 | Val AUC : 0.9034 abnorm:0.92 acl:0.9386 meni:0.8517 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.3839 | Val AUC : 0.9104 abnorm:0.9279 acl:0.9325 meni:0.8708 | lr : 3e-06\n",
      "[Epoch: 18 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.377 | Val AUC : 0.9058 abnorm:0.9326 acl:0.9291 meni:0.8557 | lr : 3e-06\n",
      "Epoch 17 End Val Avg AUC : 0.8908 abnorm : 0.9284 acl : 0.9259 meni : 0.8182\n",
      "train loss : 0.4165 | train auc 0.9142 | val loss 0.3938 | val auc 0.8908 | elapsed time 227.27313041687012 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 19 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3774 | Train Avg AUC : 0.9364 abnorm:0.9578 acl:0.9788 meni:0.8726 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4038 | Train Avg AUC : 0.9234 abnorm:0.9506 acl:0.9454 meni:0.8744 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3878 | Train Avg AUC : 0.926 abnorm:0.9491 acl:0.9549 meni:0.874 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3805 | Train Avg AUC : 0.9271 abnorm:0.9465 acl:0.963 meni:0.8719 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3802 | Train Avg AUC : 0.926 abnorm:0.9439 acl:0.961 meni:0.8732 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3847 | Train Avg AUC : 0.9276 abnorm:0.9386 acl:0.9588 meni:0.8853 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3914 | Train Avg AUC : 0.9238 abnorm:0.9321 acl:0.9566 meni:0.8827 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.39 | Train Avg AUC : 0.9212 abnorm:0.9221 acl:0.9571 meni:0.8846 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3944 | Train Avg AUC : 0.9185 abnorm:0.9236 acl:0.955 meni:0.8769 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3898 | Train Avg AUC : 0.9206 abnorm:0.9273 acl:0.9579 meni:0.8767 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3852 | Train Avg AUC : 0.9222 abnorm:0.9257 acl:0.9627 meni:0.8784 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3898 | Train Avg AUC : 0.9219 abnorm:0.9242 acl:0.9603 meni:0.8811 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3891 | Train Avg AUC : 0.9211 abnorm:0.9248 acl:0.9608 meni:0.8777 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3935 | Train Avg AUC : 0.9194 abnorm:0.9241 acl:0.9575 meni:0.8766 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3949 | Train Avg AUC : 0.9181 abnorm:0.9182 acl:0.9591 meni:0.8769 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3959 | Train Avg AUC : 0.9189 abnorm:0.9204 acl:0.9572 meni:0.8791 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3957 | Train Avg AUC : 0.919 abnorm:0.9208 acl:0.9572 meni:0.8791 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.399 | Train Avg AUC : 0.9185 abnorm:0.9198 acl:0.9575 meni:0.878 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3996 | Train Avg AUC : 0.9193 abnorm:0.9209 acl:0.956 meni:0.8809 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3991 | Train Avg AUC : 0.9194 abnorm:0.9216 acl:0.9556 meni:0.8811 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3997 | Train Avg AUC : 0.9192 abnorm:0.9208 acl:0.9545 meni:0.8822 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4034 | Train Avg AUC : 0.9185 abnorm:0.922 acl:0.9534 meni:0.8802 | lr : 3e-06\n",
      "Epoch 18 End Train Avg AUC : 0.9175 abnorm : 0.9172 acl : 0.9529 meni : 0.8823\n",
      "train loop ended, now val\n",
      "[Epoch: 19 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.2975 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.245 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2296 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2401 | Val AUC : 0.6054 abnorm:0.8162 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.315 | Val AUC : 0.8967 abnorm:0.8673 acl:0.9506 meni:0.8723 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3914 | Val AUC : 0.8898 abnorm:0.8953 acl:0.893 meni:0.881 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4334 | Val AUC : 0.8845 abnorm:0.8989 acl:0.92 meni:0.8346 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4393 | Val AUC : 0.8915 abnorm:0.9137 acl:0.9373 meni:0.8234 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4769 | Val AUC : 0.8981 abnorm:0.917 acl:0.9357 meni:0.8414 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4529 | Val AUC : 0.9068 abnorm:0.9258 acl:0.9286 meni:0.8659 | lr : 3e-06\n",
      "[Epoch: 19 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4386 | Val AUC : 0.9036 abnorm:0.9312 acl:0.9235 meni:0.856 | lr : 3e-06\n",
      "Epoch 18 End Val Avg AUC : 0.8899 abnorm : 0.9272 acl : 0.9212 meni : 0.8213\n",
      "train loss : 0.4026 | train auc 0.9175 | val loss 0.4588 | val auc 0.8899 | elapsed time 226.44072937965393 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 20 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4534 | Train Avg AUC : 0.908 abnorm:0.8677 acl:0.8977 meni:0.9585 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3859 | Train Avg AUC : 0.9241 abnorm:0.8765 acl:0.9511 meni:0.9447 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4225 | Train Avg AUC : 0.9003 abnorm:0.8929 acl:0.9255 meni:0.8824 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4376 | Train Avg AUC : 0.908 abnorm:0.9179 acl:0.9233 meni:0.8827 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4282 | Train Avg AUC : 0.9156 abnorm:0.9298 acl:0.931 meni:0.8859 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4311 | Train Avg AUC : 0.912 abnorm:0.9309 acl:0.9349 meni:0.8701 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4202 | Train Avg AUC : 0.9133 abnorm:0.9216 acl:0.9369 meni:0.8815 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4175 | Train Avg AUC : 0.9137 abnorm:0.9177 acl:0.9422 meni:0.8812 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4148 | Train Avg AUC : 0.9142 abnorm:0.9115 acl:0.9443 meni:0.8868 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4151 | Train Avg AUC : 0.9117 abnorm:0.9091 acl:0.9429 meni:0.8832 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4202 | Train Avg AUC : 0.9082 abnorm:0.9072 acl:0.9422 meni:0.8753 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.4224 | Train Avg AUC : 0.9098 abnorm:0.9105 acl:0.9372 meni:0.8818 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.4171 | Train Avg AUC : 0.9107 abnorm:0.9094 acl:0.9395 meni:0.8832 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.4132 | Train Avg AUC : 0.9135 abnorm:0.9136 acl:0.9437 meni:0.8831 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.4082 | Train Avg AUC : 0.9153 abnorm:0.9153 acl:0.9482 meni:0.8824 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.4076 | Train Avg AUC : 0.9162 abnorm:0.9153 acl:0.9496 meni:0.8837 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.4037 | Train Avg AUC : 0.9174 abnorm:0.9145 acl:0.9499 meni:0.8879 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.4069 | Train Avg AUC : 0.9161 abnorm:0.9133 acl:0.9489 meni:0.8862 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.4097 | Train Avg AUC : 0.9138 abnorm:0.908 acl:0.9485 meni:0.8849 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.4102 | Train Avg AUC : 0.9138 abnorm:0.9091 acl:0.9459 meni:0.8862 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.4097 | Train Avg AUC : 0.9149 abnorm:0.9111 acl:0.946 meni:0.8876 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.4074 | Train Avg AUC : 0.9153 abnorm:0.9139 acl:0.9474 meni:0.8847 | lr : 3e-06\n",
      "Epoch 19 End Train Avg AUC : 0.9152 abnorm : 0.9131 acl : 0.9487 meni : 0.8837\n",
      "train loop ended, now val\n",
      "[Epoch: 20 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.317 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.2607 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2357 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2376 | Val AUC : 0.6054 abnorm:0.8162 acl:0.5 meni:0.5 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.315 | Val AUC : 0.8924 abnorm:0.8673 acl:0.9535 meni:0.8564 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3887 | Val AUC : 0.8898 abnorm:0.8953 acl:0.8984 meni:0.8757 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.431 | Val AUC : 0.8865 abnorm:0.8989 acl:0.9234 meni:0.8371 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4358 | Val AUC : 0.8928 abnorm:0.9137 acl:0.9404 meni:0.8243 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4739 | Val AUC : 0.8986 abnorm:0.917 acl:0.9367 meni:0.8421 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4525 | Val AUC : 0.9061 abnorm:0.9253 acl:0.9298 meni:0.8632 | lr : 3e-06\n",
      "[Epoch: 20 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4401 | Val AUC : 0.9032 abnorm:0.9302 acl:0.9245 meni:0.855 | lr : 3e-06\n",
      "Epoch 19 End Val Avg AUC : 0.8895 abnorm : 0.9263 acl : 0.922 meni : 0.8201\n",
      "train loss : 0.4057 | train auc 0.9152 | val loss 0.4633 | val auc 0.8895 | elapsed time 226.48064422607422 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 21 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3986 | Train Avg AUC : 0.9076 abnorm:0.8663 acl:0.9808 meni:0.8758 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3649 | Train Avg AUC : 0.938 abnorm:0.9076 acl:0.9759 meni:0.9305 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3846 | Train Avg AUC : 0.9266 abnorm:0.8906 acl:0.9599 meni:0.9292 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3776 | Train Avg AUC : 0.9285 abnorm:0.9066 acl:0.9596 meni:0.9192 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3756 | Train Avg AUC : 0.9268 abnorm:0.8967 acl:0.9648 meni:0.9189 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3766 | Train Avg AUC : 0.9266 abnorm:0.9053 acl:0.9641 meni:0.9104 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3781 | Train Avg AUC : 0.9257 abnorm:0.9073 acl:0.9633 meni:0.9064 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3742 | Train Avg AUC : 0.9276 abnorm:0.9065 acl:0.9626 meni:0.9137 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3831 | Train Avg AUC : 0.9233 abnorm:0.9061 acl:0.9622 meni:0.9017 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3764 | Train Avg AUC : 0.9255 abnorm:0.9091 acl:0.9651 meni:0.9023 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3813 | Train Avg AUC : 0.9235 abnorm:0.9099 acl:0.9666 meni:0.8941 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3849 | Train Avg AUC : 0.925 abnorm:0.9099 acl:0.9633 meni:0.9019 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3853 | Train Avg AUC : 0.9248 abnorm:0.9091 acl:0.9606 meni:0.9048 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3842 | Train Avg AUC : 0.9251 abnorm:0.9091 acl:0.9596 meni:0.9067 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3796 | Train Avg AUC : 0.9264 abnorm:0.9084 acl:0.9612 meni:0.9095 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3858 | Train Avg AUC : 0.9218 abnorm:0.9042 acl:0.9611 meni:0.9002 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3849 | Train Avg AUC : 0.9227 abnorm:0.9047 acl:0.9621 meni:0.9014 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3806 | Train Avg AUC : 0.9245 abnorm:0.9059 acl:0.9639 meni:0.9038 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.378 | Train Avg AUC : 0.9245 abnorm:0.9061 acl:0.9647 meni:0.9029 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3829 | Train Avg AUC : 0.9239 abnorm:0.9087 acl:0.9613 meni:0.9017 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3881 | Train Avg AUC : 0.9229 abnorm:0.9111 acl:0.9597 meni:0.898 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3897 | Train Avg AUC : 0.9224 abnorm:0.9129 acl:0.9585 meni:0.8958 | lr : 9e-07\n",
      "Epoch 20 End Train Avg AUC : 0.9239 abnorm : 0.9152 acl : 0.9589 meni : 0.8976\n",
      "train loop ended, now val\n",
      "[Epoch: 21 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3275 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.2632 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2367 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2435 | Val AUC : 0.6054 abnorm:0.8162 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.292 | Val AUC : 0.8924 abnorm:0.8673 acl:0.9535 meni:0.8564 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3429 | Val AUC : 0.8871 abnorm:0.8953 acl:0.8984 meni:0.8677 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3705 | Val AUC : 0.8839 abnorm:0.898 acl:0.9217 meni:0.8321 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3695 | Val AUC : 0.8905 abnorm:0.913 acl:0.9392 meni:0.8192 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.3902 | Val AUC : 0.8978 abnorm:0.9182 acl:0.9377 meni:0.8376 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.3776 | Val AUC : 0.9058 abnorm:0.9263 acl:0.9306 meni:0.8605 | lr : 9e-07\n",
      "[Epoch: 21 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3755 | Val AUC : 0.9035 abnorm:0.9312 acl:0.9258 meni:0.8536 | lr : 9e-07\n",
      "Epoch 20 End Val Avg AUC : 0.8892 abnorm : 0.9267 acl : 0.9231 meni : 0.8179\n",
      "train loss : 0.3864 | train auc 0.9239 | val loss 0.4007 | val auc 0.8892 | elapsed time 225.0207874774933 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 22 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.395 | Train Avg AUC : 0.9239 abnorm:0.8862 acl:0.9709 meni:0.9145 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4002 | Train Avg AUC : 0.9064 abnorm:0.8984 acl:0.9631 meni:0.8578 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3956 | Train Avg AUC : 0.9105 abnorm:0.898 acl:0.9567 meni:0.877 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4037 | Train Avg AUC : 0.9076 abnorm:0.9025 acl:0.9473 meni:0.8729 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.393 | Train Avg AUC : 0.9155 abnorm:0.9132 acl:0.9482 meni:0.8851 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3916 | Train Avg AUC : 0.9177 abnorm:0.9175 acl:0.948 meni:0.8876 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3985 | Train Avg AUC : 0.921 abnorm:0.9271 acl:0.9513 meni:0.8847 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.4047 | Train Avg AUC : 0.916 abnorm:0.9175 acl:0.9483 meni:0.882 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4092 | Train Avg AUC : 0.9145 abnorm:0.9171 acl:0.9509 meni:0.8754 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4057 | Train Avg AUC : 0.9172 abnorm:0.9244 acl:0.9482 meni:0.8791 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.4001 | Train Avg AUC : 0.9192 abnorm:0.9241 acl:0.9516 meni:0.882 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3978 | Train Avg AUC : 0.9211 abnorm:0.9256 acl:0.9512 meni:0.8864 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3971 | Train Avg AUC : 0.9207 abnorm:0.9239 acl:0.9527 meni:0.8855 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3943 | Train Avg AUC : 0.922 abnorm:0.9252 acl:0.9533 meni:0.8874 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3881 | Train Avg AUC : 0.9234 abnorm:0.9207 acl:0.9573 meni:0.8921 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3926 | Train Avg AUC : 0.9223 abnorm:0.9196 acl:0.9547 meni:0.8927 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3945 | Train Avg AUC : 0.9211 abnorm:0.9178 acl:0.9535 meni:0.8921 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.389 | Train Avg AUC : 0.9236 abnorm:0.9205 acl:0.9554 meni:0.895 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3886 | Train Avg AUC : 0.9236 abnorm:0.92 acl:0.9571 meni:0.8936 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3908 | Train Avg AUC : 0.9228 abnorm:0.9183 acl:0.9567 meni:0.8933 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3893 | Train Avg AUC : 0.9227 abnorm:0.9187 acl:0.9567 meni:0.8928 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3901 | Train Avg AUC : 0.9234 abnorm:0.9196 acl:0.9571 meni:0.8935 | lr : 9e-07\n",
      "Epoch 21 End Train Avg AUC : 0.9231 abnorm : 0.9181 acl : 0.9567 meni : 0.8946\n",
      "train loop ended, now val\n",
      "[Epoch: 22 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3832 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3134 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.282 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2862 | Val AUC : 0.6054 abnorm:0.8162 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.323 | Val AUC : 0.8916 abnorm:0.8673 acl:0.9564 meni:0.8511 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3711 | Val AUC : 0.8858 abnorm:0.8953 acl:0.8971 meni:0.8651 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.3878 | Val AUC : 0.8828 abnorm:0.898 acl:0.9209 meni:0.8296 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.385 | Val AUC : 0.89 abnorm:0.913 acl:0.9386 meni:0.8183 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4005 | Val AUC : 0.8974 abnorm:0.9194 acl:0.9372 meni:0.8357 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.3831 | Val AUC : 0.9061 abnorm:0.9274 acl:0.931 meni:0.8601 | lr : 9e-07\n",
      "[Epoch: 22 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3755 | Val AUC : 0.9038 abnorm:0.9326 acl:0.9261 meni:0.8526 | lr : 9e-07\n",
      "Epoch 21 End Val Avg AUC : 0.8896 abnorm : 0.928 acl : 0.9237 meni : 0.817\n",
      "train loss : 0.3892 | train auc 0.9231 | val loss 0.3929 | val auc 0.8896 | elapsed time 224.94140148162842 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 23 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4061 | Train Avg AUC : 0.9164 abnorm:0.9231 acl:0.9351 meni:0.8911 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4041 | Train Avg AUC : 0.9165 abnorm:0.9051 acl:0.9465 meni:0.8979 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3923 | Train Avg AUC : 0.9293 abnorm:0.9238 acl:0.9518 meni:0.9124 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3888 | Train Avg AUC : 0.9273 abnorm:0.9242 acl:0.9495 meni:0.9082 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3919 | Train Avg AUC : 0.929 abnorm:0.9324 acl:0.9493 meni:0.9052 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3757 | Train Avg AUC : 0.9349 abnorm:0.9318 acl:0.9574 meni:0.9156 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3755 | Train Avg AUC : 0.9369 abnorm:0.9379 acl:0.9484 meni:0.9243 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3828 | Train Avg AUC : 0.9344 abnorm:0.936 acl:0.9497 meni:0.9175 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3791 | Train Avg AUC : 0.9343 abnorm:0.9326 acl:0.9551 meni:0.9151 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3871 | Train Avg AUC : 0.9312 abnorm:0.9295 acl:0.9507 meni:0.9133 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3893 | Train Avg AUC : 0.9303 abnorm:0.9317 acl:0.9524 meni:0.9067 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3907 | Train Avg AUC : 0.9307 abnorm:0.9374 acl:0.9522 meni:0.9023 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3936 | Train Avg AUC : 0.9283 abnorm:0.935 acl:0.9519 meni:0.8981 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3913 | Train Avg AUC : 0.9287 abnorm:0.9336 acl:0.9516 meni:0.9008 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3863 | Train Avg AUC : 0.93 abnorm:0.9339 acl:0.955 meni:0.9011 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3892 | Train Avg AUC : 0.9261 abnorm:0.9275 acl:0.9518 meni:0.8988 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3919 | Train Avg AUC : 0.9253 abnorm:0.927 acl:0.9476 meni:0.9012 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3956 | Train Avg AUC : 0.9251 abnorm:0.9283 acl:0.946 meni:0.9009 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3948 | Train Avg AUC : 0.9257 abnorm:0.9299 acl:0.9453 meni:0.902 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3929 | Train Avg AUC : 0.925 abnorm:0.9259 acl:0.9478 meni:0.9013 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3903 | Train Avg AUC : 0.9255 abnorm:0.9262 acl:0.9494 meni:0.9009 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.387 | Train Avg AUC : 0.9267 abnorm:0.9266 acl:0.9512 meni:0.9023 | lr : 9e-07\n",
      "Epoch 22 End Train Avg AUC : 0.9261 abnorm : 0.9239 acl : 0.9521 meni : 0.9023\n",
      "train loop ended, now val\n",
      "[Epoch: 23 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3724 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3086 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2813 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2844 | Val AUC : 0.6062 abnorm:0.8186 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3362 | Val AUC : 0.8902 abnorm:0.8688 acl:0.9506 meni:0.8511 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3961 | Val AUC : 0.8862 abnorm:0.8964 acl:0.8971 meni:0.8651 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4203 | Val AUC : 0.8832 abnorm:0.9007 acl:0.9217 meni:0.8271 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4197 | Val AUC : 0.8906 abnorm:0.9152 acl:0.9392 meni:0.8175 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4442 | Val AUC : 0.8976 abnorm:0.9206 acl:0.9377 meni:0.8344 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4206 | Val AUC : 0.9062 abnorm:0.9284 acl:0.9314 meni:0.8587 | lr : 9e-07\n",
      "[Epoch: 23 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4065 | Val AUC : 0.9043 abnorm:0.9335 acl:0.9268 meni:0.8526 | lr : 9e-07\n",
      "Epoch 22 End Val Avg AUC : 0.89 abnorm : 0.9288 acl : 0.924 meni : 0.8173\n",
      "train loss : 0.3879 | train auc 0.9261 | val loss 0.4218 | val auc 0.89 | elapsed time 223.94665813446045 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 24 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3171 | Train Avg AUC : 0.9132 abnorm:0.8556 acl:1.0 meni:0.8841 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3743 | Train Avg AUC : 0.9081 abnorm:0.8679 acl:0.9699 meni:0.8865 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3912 | Train Avg AUC : 0.9096 abnorm:0.8813 acl:0.9683 meni:0.8792 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.411 | Train Avg AUC : 0.9022 abnorm:0.8761 acl:0.953 meni:0.8774 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3981 | Train Avg AUC : 0.9042 abnorm:0.8767 acl:0.9557 meni:0.8802 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3807 | Train Avg AUC : 0.9121 abnorm:0.8803 acl:0.9588 meni:0.8972 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3842 | Train Avg AUC : 0.915 abnorm:0.8871 acl:0.9614 meni:0.8964 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.378 | Train Avg AUC : 0.9186 abnorm:0.8937 acl:0.9633 meni:0.8987 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3738 | Train Avg AUC : 0.9211 abnorm:0.901 acl:0.964 meni:0.8983 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3712 | Train Avg AUC : 0.9227 abnorm:0.9019 acl:0.9623 meni:0.9037 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3719 | Train Avg AUC : 0.9239 abnorm:0.9033 acl:0.9631 meni:0.9053 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3716 | Train Avg AUC : 0.9232 abnorm:0.9003 acl:0.9631 meni:0.9063 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3736 | Train Avg AUC : 0.9261 abnorm:0.9089 acl:0.9605 meni:0.9087 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3763 | Train Avg AUC : 0.9245 abnorm:0.9073 acl:0.9597 meni:0.9066 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3757 | Train Avg AUC : 0.925 abnorm:0.9108 acl:0.9597 meni:0.9044 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3802 | Train Avg AUC : 0.9233 abnorm:0.9103 acl:0.9571 meni:0.9024 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3794 | Train Avg AUC : 0.9238 abnorm:0.9101 acl:0.9586 meni:0.9027 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3794 | Train Avg AUC : 0.9246 abnorm:0.912 acl:0.9599 meni:0.9021 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3803 | Train Avg AUC : 0.9248 abnorm:0.9149 acl:0.9602 meni:0.8992 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3796 | Train Avg AUC : 0.9262 abnorm:0.9164 acl:0.9587 meni:0.9034 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.378 | Train Avg AUC : 0.9274 abnorm:0.9168 acl:0.9592 meni:0.9063 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3782 | Train Avg AUC : 0.9277 abnorm:0.9189 acl:0.9598 meni:0.9046 | lr : 9e-07\n",
      "Epoch 23 End Train Avg AUC : 0.9281 abnorm : 0.9204 acl : 0.96 meni : 0.9039\n",
      "train loop ended, now val\n",
      "[Epoch: 24 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.4677 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3903 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.3556 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.3593 | Val AUC : 0.6029 abnorm:0.8088 acl:0.5 meni:0.5 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3855 | Val AUC : 0.8891 abnorm:0.8627 acl:0.9535 meni:0.8511 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.4345 | Val AUC : 0.8838 abnorm:0.8919 acl:0.8971 meni:0.8624 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4372 | Val AUC : 0.8804 abnorm:0.8954 acl:0.92 meni:0.8258 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4327 | Val AUC : 0.8885 abnorm:0.9101 acl:0.938 meni:0.8175 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.444 | Val AUC : 0.8967 abnorm:0.917 acl:0.9382 meni:0.835 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4182 | Val AUC : 0.9052 abnorm:0.9253 acl:0.9322 meni:0.8583 | lr : 9e-07\n",
      "[Epoch: 24 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.4012 | Val AUC : 0.9029 abnorm:0.9302 acl:0.9271 meni:0.8512 | lr : 9e-07\n",
      "Epoch 23 End Val Avg AUC : 0.8891 abnorm : 0.9259 acl : 0.9242 meni : 0.8173\n",
      "train loss : 0.3779 | train auc 0.9281 | val loss 0.407 | val auc 0.8891 | elapsed time 220.46648502349854 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 25 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3855 | Train Avg AUC : 0.9162 abnorm:0.9109 acl:0.9519 meni:0.8857 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3503 | Train Avg AUC : 0.9275 abnorm:0.8895 acl:0.9737 meni:0.9193 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3402 | Train Avg AUC : 0.9243 abnorm:0.884 acl:0.9805 meni:0.9086 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3576 | Train Avg AUC : 0.926 abnorm:0.8931 acl:0.9651 meni:0.9197 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3615 | Train Avg AUC : 0.9252 abnorm:0.9004 acl:0.9681 meni:0.9072 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3636 | Train Avg AUC : 0.9287 abnorm:0.9063 acl:0.965 meni:0.9149 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3678 | Train Avg AUC : 0.9273 abnorm:0.9025 acl:0.9649 meni:0.9143 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3617 | Train Avg AUC : 0.9326 abnorm:0.9134 acl:0.9668 meni:0.9177 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3606 | Train Avg AUC : 0.9319 abnorm:0.9093 acl:0.9675 meni:0.9189 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3687 | Train Avg AUC : 0.9294 abnorm:0.9111 acl:0.9639 meni:0.9132 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.366 | Train Avg AUC : 0.9313 abnorm:0.9139 acl:0.9628 meni:0.9174 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3684 | Train Avg AUC : 0.9323 abnorm:0.9201 acl:0.96 meni:0.9167 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3631 | Train Avg AUC : 0.9327 abnorm:0.9146 acl:0.9617 meni:0.9219 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3618 | Train Avg AUC : 0.933 abnorm:0.916 acl:0.9624 meni:0.9205 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3638 | Train Avg AUC : 0.9326 abnorm:0.9177 acl:0.962 meni:0.9182 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3669 | Train Avg AUC : 0.9315 abnorm:0.9183 acl:0.9632 meni:0.9129 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.364 | Train Avg AUC : 0.9331 abnorm:0.9223 acl:0.9634 meni:0.9137 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3694 | Train Avg AUC : 0.9324 abnorm:0.9252 acl:0.961 meni:0.9109 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3726 | Train Avg AUC : 0.9318 abnorm:0.9272 acl:0.961 meni:0.9072 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3753 | Train Avg AUC : 0.9309 abnorm:0.9286 acl:0.9602 meni:0.9038 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3757 | Train Avg AUC : 0.9306 abnorm:0.9272 acl:0.9608 meni:0.9037 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3799 | Train Avg AUC : 0.9291 abnorm:0.927 acl:0.9578 meni:0.9026 | lr : 2.6999999999999996e-07\n",
      "Epoch 24 End Train Avg AUC : 0.9286 abnorm : 0.9253 acl : 0.9581 meni : 0.9023\n",
      "train loop ended, now val\n",
      "[Epoch: 25 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3738 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3019 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2795 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.29 | Val AUC : 0.6046 abnorm:0.8137 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3331 | Val AUC : 0.8883 abnorm:0.8657 acl:0.9535 meni:0.8457 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3885 | Val AUC : 0.8837 abnorm:0.8941 acl:0.8971 meni:0.8598 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4061 | Val AUC : 0.8809 abnorm:0.898 acl:0.92 meni:0.8246 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4043 | Val AUC : 0.8892 abnorm:0.913 acl:0.938 meni:0.8166 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.423 | Val AUC : 0.8968 abnorm:0.9188 acl:0.9372 meni:0.8344 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4012 | Val AUC : 0.9055 abnorm:0.9268 acl:0.9318 meni:0.8578 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 25 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3887 | Val AUC : 0.9035 abnorm:0.9316 acl:0.9265 meni:0.8523 | lr : 2.6999999999999996e-07\n",
      "Epoch 24 End Val Avg AUC : 0.8896 abnorm : 0.9276 acl : 0.9237 meni : 0.8176\n",
      "train loss : 0.38 | train auc 0.9286 | val loss 0.4027 | val auc 0.8896 | elapsed time 221.46684527397156 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 26 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3968 | Train Avg AUC : 0.9118 abnorm:0.8889 acl:0.9861 meni:0.8603 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4264 | Train Avg AUC : 0.9057 abnorm:0.9474 acl:0.896 meni:0.8737 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.413 | Train Avg AUC : 0.9178 abnorm:0.9452 acl:0.9263 meni:0.8819 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4274 | Train Avg AUC : 0.9125 abnorm:0.9412 acl:0.925 meni:0.8713 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4122 | Train Avg AUC : 0.919 abnorm:0.9386 acl:0.9338 meni:0.8848 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4077 | Train Avg AUC : 0.9222 abnorm:0.9413 acl:0.9433 meni:0.8821 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3981 | Train Avg AUC : 0.9255 abnorm:0.9402 acl:0.9496 meni:0.8866 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.398 | Train Avg AUC : 0.9249 abnorm:0.9356 acl:0.9514 meni:0.8876 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3928 | Train Avg AUC : 0.928 abnorm:0.9391 acl:0.9524 meni:0.8924 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3898 | Train Avg AUC : 0.9264 abnorm:0.9297 acl:0.957 meni:0.8926 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3854 | Train Avg AUC : 0.9269 abnorm:0.9233 acl:0.9608 meni:0.8967 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3872 | Train Avg AUC : 0.9251 abnorm:0.9236 acl:0.9582 meni:0.8936 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3861 | Train Avg AUC : 0.9259 abnorm:0.9213 acl:0.9587 meni:0.8977 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3872 | Train Avg AUC : 0.9257 abnorm:0.9203 acl:0.9562 meni:0.9006 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3822 | Train Avg AUC : 0.9275 abnorm:0.923 acl:0.9585 meni:0.901 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3812 | Train Avg AUC : 0.9283 abnorm:0.9247 acl:0.959 meni:0.9012 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3797 | Train Avg AUC : 0.9293 abnorm:0.9252 acl:0.959 meni:0.9036 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.378 | Train Avg AUC : 0.931 abnorm:0.927 acl:0.9593 meni:0.9067 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3821 | Train Avg AUC : 0.9291 abnorm:0.9283 acl:0.9573 meni:0.9018 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3816 | Train Avg AUC : 0.9287 abnorm:0.9255 acl:0.9593 meni:0.9013 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.378 | Train Avg AUC : 0.9292 abnorm:0.9254 acl:0.961 meni:0.9013 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3761 | Train Avg AUC : 0.9288 abnorm:0.9233 acl:0.9616 meni:0.9017 | lr : 2.6999999999999996e-07\n",
      "Epoch 25 End Train Avg AUC : 0.9289 abnorm : 0.924 acl : 0.9613 meni : 0.9014\n",
      "train loop ended, now val\n",
      "[Epoch: 26 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3626 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.2905 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2705 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2826 | Val AUC : 0.6046 abnorm:0.8137 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3267 | Val AUC : 0.8883 abnorm:0.8657 acl:0.9535 meni:0.8457 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3819 | Val AUC : 0.8832 abnorm:0.8941 acl:0.8984 meni:0.8571 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4004 | Val AUC : 0.881 abnorm:0.898 acl:0.9217 meni:0.8233 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.3987 | Val AUC : 0.889 abnorm:0.913 acl:0.9392 meni:0.8149 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4175 | Val AUC : 0.8967 abnorm:0.9188 acl:0.9382 meni:0.8331 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.3967 | Val AUC : 0.9056 abnorm:0.9268 acl:0.9325 meni:0.8574 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 26 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3853 | Val AUC : 0.9036 abnorm:0.9321 acl:0.9271 meni:0.8516 | lr : 2.6999999999999996e-07\n",
      "Epoch 25 End Val Avg AUC : 0.8899 abnorm : 0.928 acl : 0.9242 meni : 0.8173\n",
      "train loss : 0.3768 | train auc 0.9289 | val loss 0.4002 | val auc 0.8899 | elapsed time 217.76629638671875 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 27 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4396 | Train Avg AUC : 0.9025 abnorm:0.9419 acl:0.9513 meni:0.8143 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4675 | Train Avg AUC : 0.8982 abnorm:0.9264 acl:0.9003 meni:0.868 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4625 | Train Avg AUC : 0.902 abnorm:0.9312 acl:0.8995 meni:0.8754 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4324 | Train Avg AUC : 0.9111 abnorm:0.9262 acl:0.9309 meni:0.8761 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4231 | Train Avg AUC : 0.9112 abnorm:0.9163 acl:0.9401 meni:0.8774 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.428 | Train Avg AUC : 0.9142 abnorm:0.9144 acl:0.9407 meni:0.8875 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4279 | Train Avg AUC : 0.9107 abnorm:0.9128 acl:0.9392 meni:0.8799 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.417 | Train Avg AUC : 0.9148 abnorm:0.9196 acl:0.939 meni:0.8857 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4039 | Train Avg AUC : 0.9187 abnorm:0.9191 acl:0.9442 meni:0.8927 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.398 | Train Avg AUC : 0.9215 abnorm:0.9225 acl:0.9452 meni:0.8969 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3955 | Train Avg AUC : 0.923 abnorm:0.921 acl:0.9482 meni:0.8997 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3904 | Train Avg AUC : 0.9244 abnorm:0.9209 acl:0.9501 meni:0.902 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3848 | Train Avg AUC : 0.9257 abnorm:0.9214 acl:0.9515 meni:0.904 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3806 | Train Avg AUC : 0.9266 abnorm:0.9202 acl:0.955 meni:0.9047 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3785 | Train Avg AUC : 0.927 abnorm:0.9207 acl:0.9582 meni:0.9022 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3843 | Train Avg AUC : 0.9247 abnorm:0.9187 acl:0.9567 meni:0.8986 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.385 | Train Avg AUC : 0.9254 abnorm:0.9222 acl:0.9574 meni:0.8966 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3889 | Train Avg AUC : 0.9239 abnorm:0.922 acl:0.9578 meni:0.8919 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3865 | Train Avg AUC : 0.9251 abnorm:0.9243 acl:0.9583 meni:0.8926 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3793 | Train Avg AUC : 0.9276 abnorm:0.9253 acl:0.9597 meni:0.8978 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.375 | Train Avg AUC : 0.929 abnorm:0.9261 acl:0.9615 meni:0.8993 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3727 | Train Avg AUC : 0.9299 abnorm:0.9262 acl:0.9625 meni:0.9012 | lr : 2.6999999999999996e-07\n",
      "Epoch 26 End Train Avg AUC : 0.9287 abnorm : 0.9224 acl : 0.963 meni : 0.9007\n",
      "train loop ended, now val\n",
      "[Epoch: 27 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3856 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3148 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2869 | Val AUC : 0.6131 abnorm:0.8393 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2915 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3369 | Val AUC : 0.8849 abnorm:0.8642 acl:0.9448 meni:0.8457 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3933 | Val AUC : 0.8828 abnorm:0.893 acl:0.893 meni:0.8624 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4127 | Val AUC : 0.8804 abnorm:0.8972 acl:0.9184 meni:0.8258 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4107 | Val AUC : 0.8883 abnorm:0.9115 acl:0.9367 meni:0.8166 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4313 | Val AUC : 0.8961 abnorm:0.9176 acl:0.9362 meni:0.8344 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4087 | Val AUC : 0.9049 abnorm:0.9258 acl:0.931 meni:0.8578 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 27 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3957 | Val AUC : 0.9028 abnorm:0.9307 acl:0.9258 meni:0.8519 | lr : 2.6999999999999996e-07\n",
      "Epoch 26 End Val Avg AUC : 0.889 abnorm : 0.9263 acl : 0.9228 meni : 0.8179\n",
      "train loss : 0.375 | train auc 0.9287 | val loss 0.4103 | val auc 0.889 | elapsed time 218.6565396785736 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 28 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.357 | Train Avg AUC : 0.9357 abnorm:0.9222 acl:0.9727 meni:0.9122 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4203 | Train Avg AUC : 0.919 abnorm:0.9196 acl:0.931 meni:0.9063 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4378 | Train Avg AUC : 0.9083 abnorm:0.9039 acl:0.9223 meni:0.8987 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.436 | Train Avg AUC : 0.9079 abnorm:0.892 acl:0.9398 meni:0.8918 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4245 | Train Avg AUC : 0.9085 abnorm:0.8867 acl:0.9458 meni:0.893 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.4135 | Train Avg AUC : 0.9169 abnorm:0.9018 acl:0.9493 meni:0.8995 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.4071 | Train Avg AUC : 0.9176 abnorm:0.8984 acl:0.9498 meni:0.9046 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3992 | Train Avg AUC : 0.9213 abnorm:0.9075 acl:0.9487 meni:0.9077 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.4022 | Train Avg AUC : 0.9228 abnorm:0.9125 acl:0.9446 meni:0.9111 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.4052 | Train Avg AUC : 0.9213 abnorm:0.9095 acl:0.9465 meni:0.9078 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.396 | Train Avg AUC : 0.9245 abnorm:0.9074 acl:0.9506 meni:0.9154 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3899 | Train Avg AUC : 0.9275 abnorm:0.9107 acl:0.9527 meni:0.9191 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3913 | Train Avg AUC : 0.9273 abnorm:0.9144 acl:0.9509 meni:0.9167 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3899 | Train Avg AUC : 0.9276 abnorm:0.9152 acl:0.9514 meni:0.9161 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3889 | Train Avg AUC : 0.9247 abnorm:0.9091 acl:0.9527 meni:0.9123 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3839 | Train Avg AUC : 0.9255 abnorm:0.9086 acl:0.9557 meni:0.9122 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.382 | Train Avg AUC : 0.926 abnorm:0.9118 acl:0.9585 meni:0.9078 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3813 | Train Avg AUC : 0.9272 abnorm:0.9144 acl:0.9591 meni:0.9081 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3795 | Train Avg AUC : 0.9274 abnorm:0.915 acl:0.9585 meni:0.9086 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.379 | Train Avg AUC : 0.928 abnorm:0.917 acl:0.9583 meni:0.9088 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3757 | Train Avg AUC : 0.9296 abnorm:0.9203 acl:0.959 meni:0.9096 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3773 | Train Avg AUC : 0.929 abnorm:0.9218 acl:0.9608 meni:0.9043 | lr : 2.6999999999999996e-07\n",
      "Epoch 27 End Train Avg AUC : 0.9294 abnorm : 0.9225 acl : 0.9614 meni : 0.9044\n",
      "train loop ended, now val\n",
      "[Epoch: 28 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3801 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3114 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2829 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2855 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.334 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3915 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4137 | Val AUC : 0.8789 abnorm:0.8963 acl:0.9184 meni:0.8221 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4121 | Val AUC : 0.8872 abnorm:0.9108 acl:0.9367 meni:0.8141 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4343 | Val AUC : 0.8954 abnorm:0.917 acl:0.9362 meni:0.8331 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4117 | Val AUC : 0.9045 abnorm:0.9253 acl:0.931 meni:0.8574 | lr : 2.6999999999999996e-07\n",
      "[Epoch: 28 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3989 | Val AUC : 0.9024 abnorm:0.9302 acl:0.9258 meni:0.8512 | lr : 2.6999999999999996e-07\n",
      "Epoch 27 End Val Avg AUC : 0.8887 abnorm : 0.9259 acl : 0.9228 meni : 0.8173\n",
      "train loss : 0.3749 | train auc 0.9294 | val loss 0.4147 | val auc 0.8887 | elapsed time 220.4879584312439 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 29 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3576 | Train Avg AUC : 0.9426 abnorm:0.961 acl:0.9705 meni:0.8964 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3787 | Train Avg AUC : 0.9307 abnorm:0.9249 acl:0.973 meni:0.8943 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4143 | Train Avg AUC : 0.927 abnorm:0.9381 acl:0.9604 meni:0.8824 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4093 | Train Avg AUC : 0.9223 abnorm:0.9172 acl:0.9647 meni:0.8849 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3941 | Train Avg AUC : 0.9235 abnorm:0.9198 acl:0.9683 meni:0.8823 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3836 | Train Avg AUC : 0.9279 abnorm:0.9191 acl:0.9707 meni:0.8939 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3837 | Train Avg AUC : 0.9279 abnorm:0.9199 acl:0.9692 meni:0.8946 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3794 | Train Avg AUC : 0.9302 abnorm:0.9265 acl:0.9706 meni:0.8936 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3705 | Train Avg AUC : 0.9328 abnorm:0.9277 acl:0.9726 meni:0.898 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3725 | Train Avg AUC : 0.931 abnorm:0.9242 acl:0.9711 meni:0.8977 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3794 | Train Avg AUC : 0.9284 abnorm:0.9259 acl:0.9666 meni:0.8926 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3801 | Train Avg AUC : 0.9269 abnorm:0.9186 acl:0.9648 meni:0.8972 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3759 | Train Avg AUC : 0.9286 abnorm:0.9191 acl:0.9668 meni:0.8998 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3706 | Train Avg AUC : 0.9309 abnorm:0.9212 acl:0.969 meni:0.9024 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3699 | Train Avg AUC : 0.9312 abnorm:0.9199 acl:0.9678 meni:0.9058 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3719 | Train Avg AUC : 0.9295 abnorm:0.9191 acl:0.968 meni:0.9014 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3777 | Train Avg AUC : 0.9285 abnorm:0.9194 acl:0.9622 meni:0.9039 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3743 | Train Avg AUC : 0.93 abnorm:0.9227 acl:0.9627 meni:0.9047 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3699 | Train Avg AUC : 0.9313 abnorm:0.9238 acl:0.9645 meni:0.9055 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3691 | Train Avg AUC : 0.932 abnorm:0.9244 acl:0.9653 meni:0.9063 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3672 | Train Avg AUC : 0.9322 abnorm:0.9242 acl:0.9664 meni:0.9062 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3687 | Train Avg AUC : 0.932 abnorm:0.9257 acl:0.9665 meni:0.9039 | lr : 8.099999999999998e-08\n",
      "Epoch 28 End Train Avg AUC : 0.9321 abnorm : 0.9271 acl : 0.9671 meni : 0.9021\n",
      "train loop ended, now val\n",
      "[Epoch: 29 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3841 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.314 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2857 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2893 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3348 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3905 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4107 | Val AUC : 0.8785 abnorm:0.8963 acl:0.9184 meni:0.8208 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4087 | Val AUC : 0.8869 abnorm:0.9108 acl:0.9367 meni:0.8132 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4292 | Val AUC : 0.8954 abnorm:0.917 acl:0.9362 meni:0.8331 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.407 | Val AUC : 0.9045 abnorm:0.9253 acl:0.931 meni:0.8574 | lr : 8.099999999999998e-08\n",
      "[Epoch: 29 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3945 | Val AUC : 0.9024 abnorm:0.9302 acl:0.9258 meni:0.8512 | lr : 8.099999999999998e-08\n",
      "Epoch 28 End Val Avg AUC : 0.8887 abnorm : 0.9259 acl : 0.9228 meni : 0.8173\n",
      "train loss : 0.3688 | train auc 0.9321 | val loss 0.4097 | val auc 0.8887 | elapsed time 218.62665843963623 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 30 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3473 | Train Avg AUC : 0.9377 abnorm:0.9317 acl:0.9841 meni:0.8973 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3592 | Train Avg AUC : 0.9296 abnorm:0.9309 acl:0.9596 meni:0.8984 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3626 | Train Avg AUC : 0.9303 abnorm:0.9312 acl:0.9504 meni:0.9094 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3554 | Train Avg AUC : 0.934 abnorm:0.9289 acl:0.9511 meni:0.9219 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3505 | Train Avg AUC : 0.9327 abnorm:0.9225 acl:0.9591 meni:0.9165 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3548 | Train Avg AUC : 0.9315 abnorm:0.92 acl:0.9535 meni:0.9209 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3609 | Train Avg AUC : 0.9317 abnorm:0.9213 acl:0.9593 meni:0.9146 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3552 | Train Avg AUC : 0.9353 abnorm:0.925 acl:0.9646 meni:0.9164 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3531 | Train Avg AUC : 0.9349 abnorm:0.9198 acl:0.964 meni:0.9208 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3526 | Train Avg AUC : 0.9341 abnorm:0.9187 acl:0.965 meni:0.9186 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3512 | Train Avg AUC : 0.9366 abnorm:0.9274 acl:0.9678 meni:0.9146 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3509 | Train Avg AUC : 0.9376 abnorm:0.9284 acl:0.967 meni:0.9173 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3501 | Train Avg AUC : 0.9385 abnorm:0.9295 acl:0.9675 meni:0.9186 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3512 | Train Avg AUC : 0.9381 abnorm:0.9304 acl:0.9677 meni:0.9163 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.354 | Train Avg AUC : 0.9369 abnorm:0.9312 acl:0.9665 meni:0.9131 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3594 | Train Avg AUC : 0.9341 abnorm:0.9266 acl:0.9652 meni:0.9105 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.361 | Train Avg AUC : 0.9337 abnorm:0.9268 acl:0.9648 meni:0.9095 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3659 | Train Avg AUC : 0.9342 abnorm:0.9292 acl:0.9631 meni:0.9105 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3651 | Train Avg AUC : 0.9341 abnorm:0.9294 acl:0.9639 meni:0.9091 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3687 | Train Avg AUC : 0.9327 abnorm:0.9272 acl:0.9636 meni:0.9072 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3692 | Train Avg AUC : 0.932 abnorm:0.9253 acl:0.9636 meni:0.9072 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3685 | Train Avg AUC : 0.9321 abnorm:0.9264 acl:0.9646 meni:0.9054 | lr : 8.099999999999998e-08\n",
      "Epoch 29 End Train Avg AUC : 0.9322 abnorm : 0.9273 acl : 0.9637 meni : 0.9055\n",
      "train loop ended, now val\n",
      "[Epoch: 30 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3946 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3229 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2942 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2983 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3406 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3951 | Val AUC : 0.8797 abnorm:0.893 acl:0.8917 meni:0.8545 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4125 | Val AUC : 0.8782 abnorm:0.8963 acl:0.9175 meni:0.8208 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4099 | Val AUC : 0.8867 abnorm:0.9108 acl:0.9361 meni:0.8132 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4288 | Val AUC : 0.8953 abnorm:0.917 acl:0.9357 meni:0.8331 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4062 | Val AUC : 0.9044 abnorm:0.9253 acl:0.9306 meni:0.8574 | lr : 8.099999999999998e-08\n",
      "[Epoch: 30 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3932 | Val AUC : 0.9021 abnorm:0.9302 acl:0.9252 meni:0.8509 | lr : 8.099999999999998e-08\n",
      "Epoch 29 End Val Avg AUC : 0.8884 abnorm : 0.9259 acl : 0.9223 meni : 0.817\n",
      "train loss : 0.3696 | train auc 0.9322 | val loss 0.407 | val auc 0.8884 | elapsed time 221.66046929359436 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 31 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.2765 | Train Avg AUC : 0.9582 abnorm:0.9375 acl:1.0 meni:0.9372 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3116 | Train Avg AUC : 0.9507 abnorm:0.9479 acl:0.9625 meni:0.9418 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.346 | Train Avg AUC : 0.9475 abnorm:0.9476 acl:0.9552 meni:0.9397 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3403 | Train Avg AUC : 0.9496 abnorm:0.9571 acl:0.969 meni:0.9227 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3518 | Train Avg AUC : 0.947 abnorm:0.9504 acl:0.9652 meni:0.9254 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3604 | Train Avg AUC : 0.9449 abnorm:0.9567 acl:0.962 meni:0.916 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3602 | Train Avg AUC : 0.9443 abnorm:0.9511 acl:0.9658 meni:0.916 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3607 | Train Avg AUC : 0.9428 abnorm:0.9457 acl:0.966 meni:0.9166 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3585 | Train Avg AUC : 0.9419 abnorm:0.946 acl:0.9687 meni:0.9111 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3593 | Train Avg AUC : 0.9395 abnorm:0.9411 acl:0.9712 meni:0.9062 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3607 | Train Avg AUC : 0.9376 abnorm:0.9376 acl:0.972 meni:0.9033 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3634 | Train Avg AUC : 0.9357 abnorm:0.9331 acl:0.9701 meni:0.9037 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3593 | Train Avg AUC : 0.9368 abnorm:0.9333 acl:0.9709 meni:0.906 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3598 | Train Avg AUC : 0.936 abnorm:0.9294 acl:0.9687 meni:0.9099 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3594 | Train Avg AUC : 0.9365 abnorm:0.9296 acl:0.9692 meni:0.9107 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3648 | Train Avg AUC : 0.9329 abnorm:0.9249 acl:0.9692 meni:0.9047 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3647 | Train Avg AUC : 0.9318 abnorm:0.9249 acl:0.9696 meni:0.901 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3611 | Train Avg AUC : 0.9334 abnorm:0.927 acl:0.9724 meni:0.9007 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3601 | Train Avg AUC : 0.9331 abnorm:0.9248 acl:0.9725 meni:0.9019 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3691 | Train Avg AUC : 0.9305 abnorm:0.9247 acl:0.9677 meni:0.899 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3707 | Train Avg AUC : 0.9298 abnorm:0.924 acl:0.9664 meni:0.899 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3726 | Train Avg AUC : 0.9301 abnorm:0.9236 acl:0.9655 meni:0.901 | lr : 8.099999999999998e-08\n",
      "Epoch 30 End Train Avg AUC : 0.9311 abnorm : 0.9253 acl : 0.9651 meni : 0.9029\n",
      "train loop ended, now val\n",
      "[Epoch: 31 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3901 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3182 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2906 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2957 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3381 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3926 | Val AUC : 0.8797 abnorm:0.893 acl:0.8917 meni:0.8545 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4102 | Val AUC : 0.8782 abnorm:0.8963 acl:0.9175 meni:0.8208 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4076 | Val AUC : 0.8867 abnorm:0.9108 acl:0.9361 meni:0.8132 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4264 | Val AUC : 0.8953 abnorm:0.917 acl:0.9357 meni:0.8331 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4042 | Val AUC : 0.9044 abnorm:0.9253 acl:0.9306 meni:0.8574 | lr : 8.099999999999998e-08\n",
      "[Epoch: 31 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3916 | Val AUC : 0.902 abnorm:0.9302 acl:0.9248 meni:0.8509 | lr : 8.099999999999998e-08\n",
      "Epoch 30 End Val Avg AUC : 0.8883 abnorm : 0.9259 acl : 0.922 meni : 0.817\n",
      "train loss : 0.3718 | train auc 0.9311 | val loss 0.4056 | val auc 0.8883 | elapsed time 220.98478484153748 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 32 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3714 | Train Avg AUC : 0.9404 abnorm:0.9432 acl:0.9707 meni:0.9071 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3285 | Train Avg AUC : 0.9397 abnorm:0.9013 acl:0.9853 meni:0.9325 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.38 | Train Avg AUC : 0.9225 abnorm:0.895 acl:0.9686 meni:0.9037 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3728 | Train Avg AUC : 0.9288 abnorm:0.9011 acl:0.9747 meni:0.9106 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3776 | Train Avg AUC : 0.9291 abnorm:0.9125 acl:0.9766 meni:0.8982 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3756 | Train Avg AUC : 0.9288 abnorm:0.9123 acl:0.974 meni:0.9 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3723 | Train Avg AUC : 0.9297 abnorm:0.9148 acl:0.9706 meni:0.9036 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3809 | Train Avg AUC : 0.9243 abnorm:0.9111 acl:0.9673 meni:0.8947 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3794 | Train Avg AUC : 0.9249 abnorm:0.913 acl:0.9623 meni:0.8994 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3824 | Train Avg AUC : 0.9251 abnorm:0.9167 acl:0.9622 meni:0.8962 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3805 | Train Avg AUC : 0.9283 abnorm:0.9214 acl:0.9593 meni:0.9042 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3808 | Train Avg AUC : 0.928 abnorm:0.9211 acl:0.9602 meni:0.9028 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3785 | Train Avg AUC : 0.9284 abnorm:0.9181 acl:0.9629 meni:0.9043 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3771 | Train Avg AUC : 0.9271 abnorm:0.9163 acl:0.9627 meni:0.9023 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3781 | Train Avg AUC : 0.9273 abnorm:0.9188 acl:0.9631 meni:0.9001 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3752 | Train Avg AUC : 0.929 abnorm:0.9191 acl:0.9635 meni:0.9044 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3729 | Train Avg AUC : 0.9296 abnorm:0.9157 acl:0.9628 meni:0.9104 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3704 | Train Avg AUC : 0.9311 abnorm:0.9188 acl:0.9628 meni:0.9118 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3689 | Train Avg AUC : 0.9313 abnorm:0.9199 acl:0.9641 meni:0.9099 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3681 | Train Avg AUC : 0.9312 abnorm:0.9183 acl:0.9642 meni:0.9112 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3696 | Train Avg AUC : 0.93 abnorm:0.9189 acl:0.9649 meni:0.9061 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3711 | Train Avg AUC : 0.9294 abnorm:0.9191 acl:0.9644 meni:0.9046 | lr : 8.099999999999998e-08\n",
      "Epoch 31 End Train Avg AUC : 0.9305 abnorm : 0.9208 acl : 0.9641 meni : 0.9066\n",
      "train loop ended, now val\n",
      "[Epoch: 32 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3731 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3034 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2772 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2823 | Val AUC : 0.6046 abnorm:0.8137 acl:0.5 meni:0.5 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.33 | Val AUC : 0.8844 abnorm:0.8657 acl:0.9419 meni:0.8457 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3871 | Val AUC : 0.8806 abnorm:0.8941 acl:0.893 meni:0.8545 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4089 | Val AUC : 0.8791 abnorm:0.898 acl:0.9184 meni:0.8208 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4072 | Val AUC : 0.8874 abnorm:0.9123 acl:0.9367 meni:0.8132 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4287 | Val AUC : 0.8958 abnorm:0.9182 acl:0.9362 meni:0.8331 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4068 | Val AUC : 0.905 abnorm:0.9263 acl:0.931 meni:0.8578 | lr : 8.099999999999998e-08\n",
      "[Epoch: 32 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3947 | Val AUC : 0.9026 abnorm:0.9312 acl:0.9252 meni:0.8516 | lr : 8.099999999999998e-08\n",
      "Epoch 31 End Val Avg AUC : 0.8889 abnorm : 0.9267 acl : 0.9223 meni : 0.8176\n",
      "train loss : 0.3711 | train auc 0.9305 | val loss 0.4106 | val auc 0.8889 | elapsed time 219.53567910194397 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 33 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4298 | Train Avg AUC : 0.8996 abnorm:0.8512 acl:0.9233 meni:0.9242 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4046 | Train Avg AUC : 0.9131 abnorm:0.8673 acl:0.9378 meni:0.9341 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3987 | Train Avg AUC : 0.9073 abnorm:0.8725 acl:0.9616 meni:0.888 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3767 | Train Avg AUC : 0.9162 abnorm:0.8865 acl:0.9639 meni:0.8982 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3766 | Train Avg AUC : 0.9239 abnorm:0.9058 acl:0.9603 meni:0.9054 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3769 | Train Avg AUC : 0.9247 abnorm:0.9011 acl:0.959 meni:0.914 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3841 | Train Avg AUC : 0.9246 abnorm:0.9132 acl:0.9566 meni:0.9039 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3932 | Train Avg AUC : 0.9248 abnorm:0.9203 acl:0.9529 meni:0.9012 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3881 | Train Avg AUC : 0.9276 abnorm:0.9261 acl:0.9504 meni:0.9063 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3819 | Train Avg AUC : 0.9313 abnorm:0.9295 acl:0.9531 meni:0.9112 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3878 | Train Avg AUC : 0.9302 abnorm:0.9293 acl:0.9505 meni:0.9109 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3841 | Train Avg AUC : 0.9302 abnorm:0.9278 acl:0.9525 meni:0.9102 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3783 | Train Avg AUC : 0.9322 abnorm:0.9288 acl:0.9538 meni:0.9141 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3765 | Train Avg AUC : 0.9348 abnorm:0.9339 acl:0.9533 meni:0.917 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3755 | Train Avg AUC : 0.9347 abnorm:0.9335 acl:0.9534 meni:0.9172 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.377 | Train Avg AUC : 0.9329 abnorm:0.9291 acl:0.9552 meni:0.9144 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3734 | Train Avg AUC : 0.9343 abnorm:0.9339 acl:0.9575 meni:0.9115 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3773 | Train Avg AUC : 0.9334 abnorm:0.9334 acl:0.9577 meni:0.9089 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3782 | Train Avg AUC : 0.9316 abnorm:0.9306 acl:0.9598 meni:0.9043 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.375 | Train Avg AUC : 0.9326 abnorm:0.929 acl:0.9621 meni:0.9067 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3759 | Train Avg AUC : 0.9317 abnorm:0.9273 acl:0.9623 meni:0.9055 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3749 | Train Avg AUC : 0.9311 abnorm:0.927 acl:0.9617 meni:0.9045 | lr : 2.4299999999999996e-08\n",
      "Epoch 32 End Train Avg AUC : 0.9308 abnorm : 0.9261 acl : 0.9625 meni : 0.9038\n",
      "train loop ended, now val\n",
      "[Epoch: 33 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3769 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3065 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2803 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2858 | Val AUC : 0.6046 abnorm:0.8137 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3319 | Val AUC : 0.8844 abnorm:0.8657 acl:0.9419 meni:0.8457 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3882 | Val AUC : 0.8806 abnorm:0.8941 acl:0.893 meni:0.8545 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4087 | Val AUC : 0.8786 abnorm:0.898 acl:0.9184 meni:0.8195 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4067 | Val AUC : 0.8871 abnorm:0.9123 acl:0.9367 meni:0.8124 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4274 | Val AUC : 0.8956 abnorm:0.9182 acl:0.9362 meni:0.8325 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4054 | Val AUC : 0.9049 abnorm:0.9263 acl:0.931 meni:0.8574 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 33 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3932 | Val AUC : 0.9025 abnorm:0.9312 acl:0.9252 meni:0.8512 | lr : 2.4299999999999996e-08\n",
      "Epoch 32 End Val Avg AUC : 0.8888 abnorm : 0.9267 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3745 | train auc 0.9308 | val loss 0.4086 | val auc 0.8888 | elapsed time 220.207453250885 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 34 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3586 | Train Avg AUC : 0.9623 abnorm:0.9593 acl:0.9477 meni:0.9798 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3445 | Train Avg AUC : 0.9506 abnorm:0.9199 acl:0.9654 meni:0.9664 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3569 | Train Avg AUC : 0.9354 abnorm:0.9008 acl:0.9594 meni:0.9461 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3695 | Train Avg AUC : 0.9292 abnorm:0.8991 acl:0.9642 meni:0.9244 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3751 | Train Avg AUC : 0.9294 abnorm:0.9111 acl:0.9678 meni:0.9092 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3712 | Train Avg AUC : 0.9302 abnorm:0.9167 acl:0.9674 meni:0.9064 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.365 | Train Avg AUC : 0.9324 abnorm:0.9202 acl:0.97 meni:0.907 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3581 | Train Avg AUC : 0.9347 abnorm:0.9273 acl:0.9717 meni:0.9052 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3598 | Train Avg AUC : 0.9338 abnorm:0.9206 acl:0.9685 meni:0.9125 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3629 | Train Avg AUC : 0.9312 abnorm:0.9165 acl:0.9667 meni:0.9105 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3692 | Train Avg AUC : 0.9309 abnorm:0.9177 acl:0.9663 meni:0.9087 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3653 | Train Avg AUC : 0.9331 abnorm:0.9177 acl:0.9679 meni:0.9135 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3689 | Train Avg AUC : 0.9331 abnorm:0.9218 acl:0.9686 meni:0.9088 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.369 | Train Avg AUC : 0.9317 abnorm:0.9209 acl:0.9681 meni:0.9061 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3634 | Train Avg AUC : 0.9336 abnorm:0.922 acl:0.97 meni:0.9087 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3673 | Train Avg AUC : 0.9309 abnorm:0.9164 acl:0.9703 meni:0.9061 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.372 | Train Avg AUC : 0.9311 abnorm:0.9228 acl:0.9671 meni:0.9035 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3719 | Train Avg AUC : 0.9301 abnorm:0.922 acl:0.9659 meni:0.9023 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3681 | Train Avg AUC : 0.9312 abnorm:0.9218 acl:0.9675 meni:0.9043 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3757 | Train Avg AUC : 0.9298 abnorm:0.9224 acl:0.9626 meni:0.9044 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3759 | Train Avg AUC : 0.9292 abnorm:0.9212 acl:0.9621 meni:0.9044 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3759 | Train Avg AUC : 0.9292 abnorm:0.922 acl:0.9625 meni:0.903 | lr : 2.4299999999999996e-08\n",
      "Epoch 33 End Train Avg AUC : 0.9301 abnorm : 0.9234 acl : 0.963 meni : 0.904\n",
      "train loop ended, now val\n",
      "[Epoch: 34 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3774 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3068 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2805 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2859 | Val AUC : 0.6046 abnorm:0.8137 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3315 | Val AUC : 0.8844 abnorm:0.8657 acl:0.9419 meni:0.8457 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3874 | Val AUC : 0.8806 abnorm:0.8941 acl:0.893 meni:0.8545 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4077 | Val AUC : 0.8786 abnorm:0.898 acl:0.9184 meni:0.8195 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4056 | Val AUC : 0.8871 abnorm:0.9123 acl:0.9367 meni:0.8124 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4258 | Val AUC : 0.8956 abnorm:0.9182 acl:0.9362 meni:0.8325 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4041 | Val AUC : 0.9049 abnorm:0.9263 acl:0.931 meni:0.8574 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 34 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3921 | Val AUC : 0.9025 abnorm:0.9312 acl:0.9252 meni:0.8512 | lr : 2.4299999999999996e-08\n",
      "Epoch 33 End Val Avg AUC : 0.8888 abnorm : 0.9267 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.374 | train auc 0.9301 | val loss 0.4076 | val auc 0.8888 | elapsed time 219.79167985916138 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 35 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3551 | Train Avg AUC : 0.952 abnorm:0.9215 acl:0.9805 meni:0.9539 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3434 | Train Avg AUC : 0.9495 abnorm:0.956 acl:0.9799 meni:0.9126 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3609 | Train Avg AUC : 0.9344 abnorm:0.9407 acl:0.9767 meni:0.8859 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3504 | Train Avg AUC : 0.9369 abnorm:0.9266 acl:0.9802 meni:0.9038 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3508 | Train Avg AUC : 0.9363 abnorm:0.9259 acl:0.9769 meni:0.9062 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3493 | Train Avg AUC : 0.9367 abnorm:0.9272 acl:0.977 meni:0.906 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3489 | Train Avg AUC : 0.9369 abnorm:0.9266 acl:0.9755 meni:0.9086 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3484 | Train Avg AUC : 0.934 abnorm:0.9149 acl:0.9791 meni:0.9081 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3527 | Train Avg AUC : 0.9348 abnorm:0.918 acl:0.9767 meni:0.9096 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3623 | Train Avg AUC : 0.9327 abnorm:0.9248 acl:0.9734 meni:0.8999 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3667 | Train Avg AUC : 0.9316 abnorm:0.9264 acl:0.9728 meni:0.8958 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3701 | Train Avg AUC : 0.932 abnorm:0.931 acl:0.9676 meni:0.8975 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3727 | Train Avg AUC : 0.9327 abnorm:0.9346 acl:0.9652 meni:0.8984 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3725 | Train Avg AUC : 0.9337 abnorm:0.935 acl:0.9641 meni:0.9018 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3719 | Train Avg AUC : 0.9335 abnorm:0.932 acl:0.9647 meni:0.9038 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3731 | Train Avg AUC : 0.9329 abnorm:0.9303 acl:0.9627 meni:0.9057 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3753 | Train Avg AUC : 0.9327 abnorm:0.9294 acl:0.9639 meni:0.9049 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3751 | Train Avg AUC : 0.9321 abnorm:0.927 acl:0.9632 meni:0.906 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3741 | Train Avg AUC : 0.9318 abnorm:0.9254 acl:0.9638 meni:0.9061 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3766 | Train Avg AUC : 0.9305 abnorm:0.9246 acl:0.9631 meni:0.9037 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3715 | Train Avg AUC : 0.9323 abnorm:0.9278 acl:0.964 meni:0.905 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3716 | Train Avg AUC : 0.9325 abnorm:0.9284 acl:0.9636 meni:0.9054 | lr : 2.4299999999999996e-08\n",
      "Epoch 34 End Train Avg AUC : 0.9336 abnorm : 0.9282 acl : 0.9645 meni : 0.9081\n",
      "train loop ended, now val\n",
      "[Epoch: 35 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3787 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3079 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2813 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2865 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3318 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3875 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4076 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4054 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4256 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4038 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 35 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3919 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 2.4299999999999996e-08\n",
      "Epoch 34 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3686 | train auc 0.9336 | val loss 0.4073 | val auc 0.8886 | elapsed time 223.34871006011963 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 36 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4095 | Train Avg AUC : 0.9257 abnorm:0.9215 acl:0.955 meni:0.9006 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3878 | Train Avg AUC : 0.9204 abnorm:0.9257 acl:0.9679 meni:0.8675 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3982 | Train Avg AUC : 0.916 abnorm:0.9203 acl:0.9612 meni:0.8666 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4007 | Train Avg AUC : 0.9115 abnorm:0.9167 acl:0.9515 meni:0.8663 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3874 | Train Avg AUC : 0.9201 abnorm:0.9233 acl:0.9582 meni:0.8789 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3704 | Train Avg AUC : 0.9239 abnorm:0.9143 acl:0.9617 meni:0.8957 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3736 | Train Avg AUC : 0.9256 abnorm:0.9144 acl:0.96 meni:0.9023 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3805 | Train Avg AUC : 0.9209 abnorm:0.9086 acl:0.9566 meni:0.8976 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3812 | Train Avg AUC : 0.9218 abnorm:0.9141 acl:0.95 meni:0.9012 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3771 | Train Avg AUC : 0.9263 abnorm:0.9222 acl:0.9539 meni:0.9028 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3702 | Train Avg AUC : 0.9314 abnorm:0.9263 acl:0.9587 meni:0.9092 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3691 | Train Avg AUC : 0.9319 abnorm:0.9262 acl:0.9616 meni:0.9078 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3701 | Train Avg AUC : 0.9295 abnorm:0.9215 acl:0.9615 meni:0.9055 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3702 | Train Avg AUC : 0.9305 abnorm:0.923 acl:0.9627 meni:0.9059 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3718 | Train Avg AUC : 0.93 abnorm:0.9231 acl:0.9618 meni:0.9051 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3732 | Train Avg AUC : 0.9296 abnorm:0.9227 acl:0.9628 meni:0.9033 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3708 | Train Avg AUC : 0.9295 abnorm:0.9205 acl:0.9647 meni:0.9033 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3691 | Train Avg AUC : 0.9298 abnorm:0.9211 acl:0.9668 meni:0.9016 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3692 | Train Avg AUC : 0.9312 abnorm:0.924 acl:0.9671 meni:0.9024 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3702 | Train Avg AUC : 0.9312 abnorm:0.9246 acl:0.9675 meni:0.9015 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3704 | Train Avg AUC : 0.9323 abnorm:0.927 acl:0.9649 meni:0.9051 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3733 | Train Avg AUC : 0.9304 abnorm:0.924 acl:0.9636 meni:0.9037 | lr : 2.4299999999999996e-08\n",
      "Epoch 35 End Train Avg AUC : 0.9308 abnorm : 0.9242 acl : 0.9633 meni : 0.9049\n",
      "train loop ended, now val\n",
      "[Epoch: 36 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3797 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3087 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2821 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2874 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3324 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.388 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4078 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4056 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4255 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4038 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 2.4299999999999996e-08\n",
      "[Epoch: 36 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3917 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 2.4299999999999996e-08\n",
      "Epoch 35 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3723 | train auc 0.9308 | val loss 0.407 | val auc 0.8886 | elapsed time 222.53721022605896 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 37 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3231 | Train Avg AUC : 0.9392 abnorm:0.9045 acl:0.9778 meni:0.9352 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4027 | Train Avg AUC : 0.9162 abnorm:0.9056 acl:0.9467 meni:0.8961 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4061 | Train Avg AUC : 0.9125 abnorm:0.9193 acl:0.9471 meni:0.8712 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3933 | Train Avg AUC : 0.9198 abnorm:0.9225 acl:0.9531 meni:0.8839 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4015 | Train Avg AUC : 0.9203 abnorm:0.9301 acl:0.9516 meni:0.8793 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3959 | Train Avg AUC : 0.9218 abnorm:0.9234 acl:0.9507 meni:0.8913 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3854 | Train Avg AUC : 0.923 abnorm:0.9248 acl:0.9545 meni:0.8899 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3924 | Train Avg AUC : 0.9175 abnorm:0.9161 acl:0.9557 meni:0.8806 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3929 | Train Avg AUC : 0.9149 abnorm:0.9087 acl:0.9612 meni:0.8749 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3896 | Train Avg AUC : 0.9192 abnorm:0.9141 acl:0.9612 meni:0.8823 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3865 | Train Avg AUC : 0.9218 abnorm:0.9198 acl:0.9613 meni:0.8844 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3856 | Train Avg AUC : 0.925 abnorm:0.9246 acl:0.9622 meni:0.8881 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3853 | Train Avg AUC : 0.9222 abnorm:0.915 acl:0.961 meni:0.8905 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3854 | Train Avg AUC : 0.9215 abnorm:0.9127 acl:0.9609 meni:0.8909 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3816 | Train Avg AUC : 0.923 abnorm:0.9157 acl:0.9619 meni:0.8914 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3802 | Train Avg AUC : 0.9251 abnorm:0.917 acl:0.9617 meni:0.8966 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3756 | Train Avg AUC : 0.9267 abnorm:0.9188 acl:0.9628 meni:0.8984 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3769 | Train Avg AUC : 0.9259 abnorm:0.9167 acl:0.9619 meni:0.8992 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3752 | Train Avg AUC : 0.9284 abnorm:0.9199 acl:0.9628 meni:0.9026 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3746 | Train Avg AUC : 0.93 abnorm:0.9222 acl:0.962 meni:0.9057 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3748 | Train Avg AUC : 0.9294 abnorm:0.9209 acl:0.9619 meni:0.9055 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3749 | Train Avg AUC : 0.9292 abnorm:0.9209 acl:0.9627 meni:0.904 | lr : 7.289999999999999e-09\n",
      "Epoch 36 End Train Avg AUC : 0.9299 abnorm : 0.9225 acl : 0.9627 meni : 0.9044\n",
      "train loop ended, now val\n",
      "[Epoch: 37 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3788 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3078 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2813 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2868 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3318 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3874 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4074 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4052 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4252 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4035 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 37 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3916 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 36 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3746 | train auc 0.9299 | val loss 0.407 | val auc 0.8886 | elapsed time 222.25114107131958 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 38 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4025 | Train Avg AUC : 0.9127 abnorm:0.8836 acl:0.9448 meni:0.9097 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4259 | Train Avg AUC : 0.9116 abnorm:0.916 acl:0.9027 meni:0.9163 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4229 | Train Avg AUC : 0.9158 abnorm:0.9229 acl:0.9265 meni:0.898 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4113 | Train Avg AUC : 0.9163 abnorm:0.9109 acl:0.9423 meni:0.8957 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3927 | Train Avg AUC : 0.9207 abnorm:0.9075 acl:0.9539 meni:0.9006 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.384 | Train Avg AUC : 0.9248 abnorm:0.9125 acl:0.9564 meni:0.9054 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3805 | Train Avg AUC : 0.9262 abnorm:0.9145 acl:0.9536 meni:0.9104 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3799 | Train Avg AUC : 0.926 abnorm:0.9113 acl:0.9526 meni:0.914 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.387 | Train Avg AUC : 0.922 abnorm:0.9067 acl:0.951 meni:0.9083 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.381 | Train Avg AUC : 0.9246 abnorm:0.9097 acl:0.9555 meni:0.9085 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3741 | Train Avg AUC : 0.928 abnorm:0.9121 acl:0.9609 meni:0.9108 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3692 | Train Avg AUC : 0.9302 abnorm:0.9151 acl:0.9632 meni:0.9122 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3655 | Train Avg AUC : 0.9311 abnorm:0.9213 acl:0.966 meni:0.906 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3674 | Train Avg AUC : 0.9313 abnorm:0.9216 acl:0.9654 meni:0.9069 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3693 | Train Avg AUC : 0.932 abnorm:0.9243 acl:0.9654 meni:0.9065 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.371 | Train Avg AUC : 0.9308 abnorm:0.9225 acl:0.964 meni:0.9059 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3755 | Train Avg AUC : 0.93 abnorm:0.9235 acl:0.9616 meni:0.9049 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3746 | Train Avg AUC : 0.9308 abnorm:0.9259 acl:0.9637 meni:0.9029 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3715 | Train Avg AUC : 0.932 abnorm:0.9258 acl:0.9652 meni:0.9051 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3706 | Train Avg AUC : 0.9321 abnorm:0.9248 acl:0.9644 meni:0.9071 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3674 | Train Avg AUC : 0.9324 abnorm:0.925 acl:0.9655 meni:0.9069 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3675 | Train Avg AUC : 0.9329 abnorm:0.9253 acl:0.9647 meni:0.9086 | lr : 7.289999999999999e-09\n",
      "Epoch 37 End Train Avg AUC : 0.9335 abnorm : 0.9256 acl : 0.9653 meni : 0.9096\n",
      "train loop ended, now val\n",
      "[Epoch: 38 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3786 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3076 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2812 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2866 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3317 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3873 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4073 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4051 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4251 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4035 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 38 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3915 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 37 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.367 | train auc 0.9335 | val loss 0.4069 | val auc 0.8886 | elapsed time 218.68667149543762 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 39 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3777 | Train Avg AUC : 0.9441 abnorm:0.9614 acl:0.963 meni:0.9079 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3898 | Train Avg AUC : 0.9178 abnorm:0.9012 acl:0.9698 meni:0.8826 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3651 | Train Avg AUC : 0.9267 abnorm:0.9098 acl:0.9698 meni:0.9005 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3631 | Train Avg AUC : 0.9259 abnorm:0.9079 acl:0.9585 meni:0.9112 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.363 | Train Avg AUC : 0.9317 abnorm:0.9195 acl:0.9645 meni:0.911 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3647 | Train Avg AUC : 0.931 abnorm:0.9229 acl:0.9627 meni:0.9075 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3606 | Train Avg AUC : 0.9321 abnorm:0.9128 acl:0.968 meni:0.9156 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3551 | Train Avg AUC : 0.937 abnorm:0.9208 acl:0.9703 meni:0.9198 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3608 | Train Avg AUC : 0.9336 abnorm:0.9171 acl:0.9657 meni:0.9179 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3638 | Train Avg AUC : 0.9322 abnorm:0.9138 acl:0.9645 meni:0.9184 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3718 | Train Avg AUC : 0.9319 abnorm:0.9224 acl:0.9607 meni:0.9128 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3731 | Train Avg AUC : 0.9331 abnorm:0.9247 acl:0.9606 meni:0.9142 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3661 | Train Avg AUC : 0.9345 abnorm:0.9202 acl:0.9641 meni:0.9192 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3644 | Train Avg AUC : 0.9354 abnorm:0.9227 acl:0.9652 meni:0.9182 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3702 | Train Avg AUC : 0.933 abnorm:0.9216 acl:0.9616 meni:0.9159 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3689 | Train Avg AUC : 0.9334 abnorm:0.9212 acl:0.9612 meni:0.9176 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3712 | Train Avg AUC : 0.9329 abnorm:0.9222 acl:0.9598 meni:0.9166 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3711 | Train Avg AUC : 0.9326 abnorm:0.9224 acl:0.9599 meni:0.9154 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3688 | Train Avg AUC : 0.9342 abnorm:0.9273 acl:0.9626 meni:0.9128 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3682 | Train Avg AUC : 0.9342 abnorm:0.9263 acl:0.9639 meni:0.9124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.369 | Train Avg AUC : 0.9342 abnorm:0.9288 acl:0.9638 meni:0.91 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3689 | Train Avg AUC : 0.934 abnorm:0.928 acl:0.9638 meni:0.91 | lr : 7.289999999999999e-09\n",
      "Epoch 38 End Train Avg AUC : 0.933 abnorm : 0.9278 acl : 0.9646 meni : 0.9066\n",
      "train loop ended, now val\n",
      "[Epoch: 39 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3786 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3077 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2812 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2866 | Val AUC : 0.6046 abnorm:0.8137 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3317 | Val AUC : 0.8844 abnorm:0.8657 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3873 | Val AUC : 0.8806 abnorm:0.8941 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4073 | Val AUC : 0.8786 abnorm:0.898 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4051 | Val AUC : 0.8871 abnorm:0.9123 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4252 | Val AUC : 0.8956 abnorm:0.9182 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4035 | Val AUC : 0.9049 abnorm:0.9263 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 39 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3915 | Val AUC : 0.9025 abnorm:0.9312 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 38 End Val Avg AUC : 0.8888 abnorm : 0.9267 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3694 | train auc 0.933 | val loss 0.407 | val auc 0.8888 | elapsed time 221.4626853466034 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 40 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3407 | Train Avg AUC : 0.9523 abnorm:0.9444 acl:0.9951 meni:0.9175 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3533 | Train Avg AUC : 0.9386 abnorm:0.935 acl:0.9816 meni:0.8991 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3624 | Train Avg AUC : 0.9322 abnorm:0.9351 acl:0.9775 meni:0.8839 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3461 | Train Avg AUC : 0.9338 abnorm:0.9266 acl:0.981 meni:0.8938 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3538 | Train Avg AUC : 0.9339 abnorm:0.9224 acl:0.9776 meni:0.9017 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3552 | Train Avg AUC : 0.9356 abnorm:0.9276 acl:0.9747 meni:0.9044 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3607 | Train Avg AUC : 0.931 abnorm:0.92 acl:0.9753 meni:0.8978 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3601 | Train Avg AUC : 0.9332 abnorm:0.9231 acl:0.9763 meni:0.9002 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3586 | Train Avg AUC : 0.9343 abnorm:0.9228 acl:0.9755 meni:0.9045 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3601 | Train Avg AUC : 0.9325 abnorm:0.9232 acl:0.975 meni:0.8992 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3622 | Train Avg AUC : 0.933 abnorm:0.9249 acl:0.9753 meni:0.8988 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3635 | Train Avg AUC : 0.9333 abnorm:0.9288 acl:0.9735 meni:0.8975 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3642 | Train Avg AUC : 0.9331 abnorm:0.9279 acl:0.9717 meni:0.8996 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3776 | Train Avg AUC : 0.929 abnorm:0.9258 acl:0.9633 meni:0.898 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3792 | Train Avg AUC : 0.9304 abnorm:0.9297 acl:0.9628 meni:0.8986 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3772 | Train Avg AUC : 0.9314 abnorm:0.9296 acl:0.9635 meni:0.9011 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3728 | Train Avg AUC : 0.933 abnorm:0.9311 acl:0.9648 meni:0.9031 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.373 | Train Avg AUC : 0.9322 abnorm:0.9299 acl:0.9651 meni:0.9015 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3737 | Train Avg AUC : 0.9318 abnorm:0.9284 acl:0.9641 meni:0.9029 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3727 | Train Avg AUC : 0.9311 abnorm:0.9263 acl:0.9649 meni:0.9022 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.374 | Train Avg AUC : 0.9304 abnorm:0.9258 acl:0.9634 meni:0.902 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.373 | Train Avg AUC : 0.9306 abnorm:0.925 acl:0.964 meni:0.9028 | lr : 7.289999999999999e-09\n",
      "Epoch 39 End Train Avg AUC : 0.9311 abnorm : 0.9257 acl : 0.9644 meni : 0.9033\n",
      "train loop ended, now val\n",
      "[Epoch: 40 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3785 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3076 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2811 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2865 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3317 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3872 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4072 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.405 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4251 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4034 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 40 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3915 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 39 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3717 | train auc 0.9311 | val loss 0.4069 | val auc 0.8886 | elapsed time 221.62255930900574 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 41 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4102 | Train Avg AUC : 0.9219 abnorm:0.9222 acl:0.9634 meni:0.88 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3667 | Train Avg AUC : 0.9373 abnorm:0.9324 acl:0.973 meni:0.9066 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3534 | Train Avg AUC : 0.9376 abnorm:0.9376 acl:0.9757 meni:0.8994 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3453 | Train Avg AUC : 0.9384 abnorm:0.9383 acl:0.9813 meni:0.8954 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3621 | Train Avg AUC : 0.9339 abnorm:0.9379 acl:0.974 meni:0.8898 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3644 | Train Avg AUC : 0.9328 abnorm:0.9346 acl:0.9704 meni:0.8936 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3691 | Train Avg AUC : 0.9277 abnorm:0.9226 acl:0.9637 meni:0.8967 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3786 | Train Avg AUC : 0.9248 abnorm:0.9198 acl:0.9615 meni:0.8931 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3752 | Train Avg AUC : 0.9284 abnorm:0.9252 acl:0.9634 meni:0.8966 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3864 | Train Avg AUC : 0.9258 abnorm:0.9258 acl:0.9615 meni:0.89 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3909 | Train Avg AUC : 0.9241 abnorm:0.9301 acl:0.9583 meni:0.8839 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3868 | Train Avg AUC : 0.9249 abnorm:0.93 acl:0.9609 meni:0.8837 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3865 | Train Avg AUC : 0.9247 abnorm:0.9279 acl:0.9581 meni:0.8881 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3829 | Train Avg AUC : 0.9251 abnorm:0.9228 acl:0.9598 meni:0.8928 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3814 | Train Avg AUC : 0.9255 abnorm:0.9189 acl:0.9613 meni:0.8963 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3789 | Train Avg AUC : 0.927 abnorm:0.9201 acl:0.9621 meni:0.8989 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3807 | Train Avg AUC : 0.9269 abnorm:0.9205 acl:0.9604 meni:0.8998 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3775 | Train Avg AUC : 0.9286 abnorm:0.9226 acl:0.9597 meni:0.9035 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.379 | Train Avg AUC : 0.9282 abnorm:0.923 acl:0.9593 meni:0.9023 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3776 | Train Avg AUC : 0.9278 abnorm:0.92 acl:0.9613 meni:0.9023 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3767 | Train Avg AUC : 0.9282 abnorm:0.9198 acl:0.9605 meni:0.9041 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3745 | Train Avg AUC : 0.9298 abnorm:0.9222 acl:0.9612 meni:0.9062 | lr : 7.289999999999999e-09\n",
      "Epoch 40 End Train Avg AUC : 0.9303 abnorm : 0.9239 acl : 0.9615 meni : 0.9055\n",
      "train loop ended, now val\n",
      "[Epoch: 41 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3787 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3077 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2813 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2868 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3318 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3873 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4072 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.405 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.425 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4033 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 41 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3914 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 40 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.374 | train auc 0.9303 | val loss 0.4068 | val auc 0.8886 | elapsed time 221.7428810596466 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 42 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3349 | Train Avg AUC : 0.9336 abnorm:0.9365 acl:0.9947 meni:0.8696 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.347 | Train Avg AUC : 0.9436 abnorm:0.9557 acl:0.9746 meni:0.9004 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3386 | Train Avg AUC : 0.9429 abnorm:0.9501 acl:0.9776 meni:0.9009 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3413 | Train Avg AUC : 0.942 abnorm:0.9448 acl:0.9732 meni:0.9082 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3584 | Train Avg AUC : 0.9344 abnorm:0.9412 acl:0.9722 meni:0.8899 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3657 | Train Avg AUC : 0.9329 abnorm:0.937 acl:0.9628 meni:0.8988 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3571 | Train Avg AUC : 0.9384 abnorm:0.9391 acl:0.9681 meni:0.9079 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3514 | Train Avg AUC : 0.9419 abnorm:0.9421 acl:0.9714 meni:0.912 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3535 | Train Avg AUC : 0.9411 abnorm:0.9377 acl:0.9692 meni:0.9163 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.352 | Train Avg AUC : 0.9419 abnorm:0.9383 acl:0.9719 meni:0.9156 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.353 | Train Avg AUC : 0.9422 abnorm:0.9388 acl:0.9728 meni:0.915 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3541 | Train Avg AUC : 0.9408 abnorm:0.9384 acl:0.9717 meni:0.9123 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3522 | Train Avg AUC : 0.9411 abnorm:0.9372 acl:0.9737 meni:0.9126 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3574 | Train Avg AUC : 0.939 abnorm:0.9353 acl:0.9712 meni:0.9104 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3624 | Train Avg AUC : 0.9377 abnorm:0.9359 acl:0.968 meni:0.9091 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3637 | Train Avg AUC : 0.9369 abnorm:0.9311 acl:0.9683 meni:0.9113 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3617 | Train Avg AUC : 0.939 abnorm:0.9354 acl:0.9671 meni:0.9146 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3619 | Train Avg AUC : 0.9373 abnorm:0.9323 acl:0.967 meni:0.9126 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3617 | Train Avg AUC : 0.9383 abnorm:0.9332 acl:0.9673 meni:0.9144 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3679 | Train Avg AUC : 0.9355 abnorm:0.9323 acl:0.9657 meni:0.9084 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3674 | Train Avg AUC : 0.9342 abnorm:0.9298 acl:0.9656 meni:0.9072 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3672 | Train Avg AUC : 0.9343 abnorm:0.9302 acl:0.9652 meni:0.9076 | lr : 7.289999999999999e-09\n",
      "Epoch 41 End Train Avg AUC : 0.933 abnorm : 0.9283 acl : 0.9652 meni : 0.9054\n",
      "train loop ended, now val\n",
      "[Epoch: 42 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3793 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3082 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2817 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2873 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3321 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3876 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4073 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4051 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.425 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4033 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 42 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3913 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 41 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3693 | train auc 0.933 | val loss 0.4066 | val auc 0.8886 | elapsed time 223.22360754013062 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 43 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.446 | Train Avg AUC : 0.9007 abnorm:0.8864 acl:0.9268 meni:0.8889 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4361 | Train Avg AUC : 0.8985 abnorm:0.876 acl:0.9223 meni:0.8972 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3993 | Train Avg AUC : 0.9224 abnorm:0.9034 acl:0.9493 meni:0.9145 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3978 | Train Avg AUC : 0.9249 abnorm:0.917 acl:0.9467 meni:0.9111 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3888 | Train Avg AUC : 0.9264 abnorm:0.9257 acl:0.9533 meni:0.9001 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3959 | Train Avg AUC : 0.9238 abnorm:0.9233 acl:0.9511 meni:0.8969 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3882 | Train Avg AUC : 0.9278 abnorm:0.9263 acl:0.9527 meni:0.9045 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3871 | Train Avg AUC : 0.9295 abnorm:0.9276 acl:0.9573 meni:0.9036 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3913 | Train Avg AUC : 0.9298 abnorm:0.9309 acl:0.9544 meni:0.904 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3884 | Train Avg AUC : 0.9303 abnorm:0.9308 acl:0.9541 meni:0.9061 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3901 | Train Avg AUC : 0.9274 abnorm:0.9251 acl:0.9532 meni:0.9039 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3883 | Train Avg AUC : 0.9262 abnorm:0.9267 acl:0.9541 meni:0.8978 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3835 | Train Avg AUC : 0.9278 abnorm:0.9272 acl:0.955 meni:0.9011 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.382 | Train Avg AUC : 0.9283 abnorm:0.9244 acl:0.9579 meni:0.9028 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3811 | Train Avg AUC : 0.9288 abnorm:0.9268 acl:0.9581 meni:0.9015 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3816 | Train Avg AUC : 0.9282 abnorm:0.9232 acl:0.9581 meni:0.9033 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3822 | Train Avg AUC : 0.9277 abnorm:0.9237 acl:0.9569 meni:0.9023 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.38 | Train Avg AUC : 0.9284 abnorm:0.9245 acl:0.959 meni:0.9018 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3764 | Train Avg AUC : 0.9303 abnorm:0.9264 acl:0.9613 meni:0.9033 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3748 | Train Avg AUC : 0.9302 abnorm:0.9254 acl:0.9602 meni:0.9049 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3761 | Train Avg AUC : 0.9295 abnorm:0.9247 acl:0.9603 meni:0.9035 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.376 | Train Avg AUC : 0.9302 abnorm:0.9246 acl:0.9617 meni:0.9043 | lr : 7.289999999999999e-09\n",
      "Epoch 42 End Train Avg AUC : 0.9317 abnorm : 0.9262 acl : 0.9628 meni : 0.9061\n",
      "train loop ended, now val\n",
      "[Epoch: 43 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3789 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3078 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2814 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.287 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3319 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3874 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4072 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4049 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4248 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4031 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 43 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3912 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 42 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3724 | train auc 0.9317 | val loss 0.4065 | val auc 0.8886 | elapsed time 220.96858763694763 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 44 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.44 | Train Avg AUC : 0.8829 abnorm:0.8926 acl:0.8704 meni:0.8858 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3803 | Train Avg AUC : 0.9223 abnorm:0.8919 acl:0.9489 meni:0.9262 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3665 | Train Avg AUC : 0.9347 abnorm:0.9191 acl:0.9508 meni:0.9342 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3942 | Train Avg AUC : 0.9287 abnorm:0.9234 acl:0.9497 meni:0.9131 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3804 | Train Avg AUC : 0.934 abnorm:0.9238 acl:0.9559 meni:0.9224 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3825 | Train Avg AUC : 0.9304 abnorm:0.9237 acl:0.9539 meni:0.9135 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3821 | Train Avg AUC : 0.9311 abnorm:0.9226 acl:0.9539 meni:0.9169 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3681 | Train Avg AUC : 0.9355 abnorm:0.9187 acl:0.9604 meni:0.9273 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3639 | Train Avg AUC : 0.9373 abnorm:0.9192 acl:0.9628 meni:0.9298 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3727 | Train Avg AUC : 0.9334 abnorm:0.9201 acl:0.9605 meni:0.9198 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3677 | Train Avg AUC : 0.9324 abnorm:0.9144 acl:0.963 meni:0.92 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3763 | Train Avg AUC : 0.9267 abnorm:0.9109 acl:0.9601 meni:0.9091 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3786 | Train Avg AUC : 0.926 abnorm:0.9136 acl:0.9608 meni:0.9037 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3721 | Train Avg AUC : 0.9288 abnorm:0.9174 acl:0.9637 meni:0.9052 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3715 | Train Avg AUC : 0.9307 abnorm:0.9217 acl:0.9629 meni:0.9075 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3748 | Train Avg AUC : 0.93 abnorm:0.9238 acl:0.9616 meni:0.9047 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3764 | Train Avg AUC : 0.9284 abnorm:0.9165 acl:0.9615 meni:0.9072 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3733 | Train Avg AUC : 0.9295 abnorm:0.9187 acl:0.962 meni:0.9078 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3693 | Train Avg AUC : 0.9319 abnorm:0.9225 acl:0.963 meni:0.9104 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3692 | Train Avg AUC : 0.9317 abnorm:0.9233 acl:0.9611 meni:0.9106 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3725 | Train Avg AUC : 0.9311 abnorm:0.9253 acl:0.96 meni:0.9081 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3718 | Train Avg AUC : 0.9318 abnorm:0.9269 acl:0.9605 meni:0.9079 | lr : 7.289999999999999e-09\n",
      "Epoch 43 End Train Avg AUC : 0.9319 abnorm : 0.9278 acl : 0.9596 meni : 0.9083\n",
      "train loop ended, now val\n",
      "[Epoch: 44 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3785 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3075 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2811 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2868 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3317 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3872 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.407 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4048 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4247 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.403 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 44 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3911 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 43 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3719 | train auc 0.9319 | val loss 0.4065 | val auc 0.8886 | elapsed time 219.87704825401306 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 45 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4249 | Train Avg AUC : 0.91 abnorm:0.9159 acl:0.9872 meni:0.827 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.364 | Train Avg AUC : 0.9376 abnorm:0.9334 acl:0.9846 meni:0.8947 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3787 | Train Avg AUC : 0.9222 abnorm:0.8954 acl:0.9847 meni:0.8865 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.385 | Train Avg AUC : 0.9145 abnorm:0.886 acl:0.9706 meni:0.8869 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3761 | Train Avg AUC : 0.9165 abnorm:0.8923 acl:0.9689 meni:0.8883 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3719 | Train Avg AUC : 0.9196 abnorm:0.8961 acl:0.9664 meni:0.8961 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3712 | Train Avg AUC : 0.9275 abnorm:0.9138 acl:0.9646 meni:0.9041 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3734 | Train Avg AUC : 0.9315 abnorm:0.9244 acl:0.9636 meni:0.9064 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3756 | Train Avg AUC : 0.9334 abnorm:0.9348 acl:0.9624 meni:0.903 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3738 | Train Avg AUC : 0.9326 abnorm:0.9335 acl:0.9648 meni:0.8996 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3724 | Train Avg AUC : 0.9325 abnorm:0.9289 acl:0.9632 meni:0.9055 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3741 | Train Avg AUC : 0.9321 abnorm:0.932 acl:0.9616 meni:0.9028 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3716 | Train Avg AUC : 0.9324 abnorm:0.9343 acl:0.9632 meni:0.8996 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3726 | Train Avg AUC : 0.9336 abnorm:0.936 acl:0.9648 meni:0.9001 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3708 | Train Avg AUC : 0.9332 abnorm:0.9311 acl:0.9656 meni:0.9028 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3666 | Train Avg AUC : 0.9335 abnorm:0.929 acl:0.9654 meni:0.9061 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.371 | Train Avg AUC : 0.9309 abnorm:0.9266 acl:0.9655 meni:0.9007 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3714 | Train Avg AUC : 0.9306 abnorm:0.9273 acl:0.9649 meni:0.8996 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3732 | Train Avg AUC : 0.9295 abnorm:0.9264 acl:0.9657 meni:0.8965 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3728 | Train Avg AUC : 0.9288 abnorm:0.9251 acl:0.9667 meni:0.8946 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3701 | Train Avg AUC : 0.9304 abnorm:0.9252 acl:0.967 meni:0.899 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3693 | Train Avg AUC : 0.9315 abnorm:0.9263 acl:0.9661 meni:0.9019 | lr : 7.289999999999999e-09\n",
      "Epoch 44 End Train Avg AUC : 0.9302 abnorm : 0.9219 acl : 0.9651 meni : 0.9037\n",
      "train loop ended, now val\n",
      "[Epoch: 45 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3787 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3076 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2813 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.287 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3319 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3875 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4072 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.405 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4249 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4032 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 45 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3912 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 44 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3713 | train auc 0.9302 | val loss 0.4065 | val auc 0.8886 | elapsed time 221.6660294532776 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 46 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.4689 | Train Avg AUC : 0.9146 abnorm:0.9468 acl:0.9375 meni:0.8596 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.4516 | Train Avg AUC : 0.9219 abnorm:0.9467 acl:0.9469 meni:0.8721 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.4312 | Train Avg AUC : 0.9262 abnorm:0.9509 acl:0.9447 meni:0.8829 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.4185 | Train Avg AUC : 0.928 abnorm:0.9487 acl:0.9512 meni:0.8841 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.4068 | Train Avg AUC : 0.9291 abnorm:0.9402 acl:0.9573 meni:0.8897 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3998 | Train Avg AUC : 0.9312 abnorm:0.9399 acl:0.9591 meni:0.8945 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3953 | Train Avg AUC : 0.9316 abnorm:0.9408 acl:0.9614 meni:0.8925 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3832 | Train Avg AUC : 0.9296 abnorm:0.9257 acl:0.9644 meni:0.8987 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3786 | Train Avg AUC : 0.9322 abnorm:0.9291 acl:0.9633 meni:0.9041 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3854 | Train Avg AUC : 0.9304 abnorm:0.9302 acl:0.9556 meni:0.9055 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.386 | Train Avg AUC : 0.9279 abnorm:0.9249 acl:0.9552 meni:0.9037 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3771 | Train Avg AUC : 0.93 abnorm:0.9243 acl:0.958 meni:0.9077 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3771 | Train Avg AUC : 0.9282 abnorm:0.9169 acl:0.9593 meni:0.9084 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.38 | Train Avg AUC : 0.9268 abnorm:0.9145 acl:0.9586 meni:0.9075 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3765 | Train Avg AUC : 0.9272 abnorm:0.9153 acl:0.9604 meni:0.9058 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3766 | Train Avg AUC : 0.9276 abnorm:0.9178 acl:0.9608 meni:0.9043 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3738 | Train Avg AUC : 0.9292 abnorm:0.9195 acl:0.9627 meni:0.9054 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3739 | Train Avg AUC : 0.9288 abnorm:0.9172 acl:0.9628 meni:0.9065 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3731 | Train Avg AUC : 0.9299 abnorm:0.921 acl:0.964 meni:0.9046 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.372 | Train Avg AUC : 0.9307 abnorm:0.923 acl:0.9656 meni:0.9035 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3721 | Train Avg AUC : 0.9303 abnorm:0.9223 acl:0.9643 meni:0.9043 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3708 | Train Avg AUC : 0.9308 abnorm:0.9229 acl:0.9649 meni:0.9047 | lr : 7.289999999999999e-09\n",
      "Epoch 45 End Train Avg AUC : 0.9315 abnorm : 0.9229 acl : 0.9654 meni : 0.9063\n",
      "train loop ended, now val\n",
      "[Epoch: 46 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3789 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3078 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2815 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2872 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.332 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3875 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4073 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.405 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4249 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4032 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 46 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3912 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 45 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3701 | train auc 0.9315 | val loss 0.4065 | val auc 0.8886 | elapsed time 221.20649313926697 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 47 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.361 | Train Avg AUC : 0.9337 abnorm:0.9233 acl:1.0 meni:0.8778 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3521 | Train Avg AUC : 0.9313 abnorm:0.9284 acl:0.9779 meni:0.8874 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3389 | Train Avg AUC : 0.9427 abnorm:0.9346 acl:0.977 meni:0.9165 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3546 | Train Avg AUC : 0.9385 abnorm:0.9346 acl:0.9641 meni:0.9169 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3598 | Train Avg AUC : 0.942 abnorm:0.9378 acl:0.9629 meni:0.9254 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.38 | Train Avg AUC : 0.938 abnorm:0.9456 acl:0.9567 meni:0.9116 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3745 | Train Avg AUC : 0.9377 abnorm:0.9461 acl:0.9596 meni:0.9075 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3676 | Train Avg AUC : 0.9385 abnorm:0.9467 acl:0.9637 meni:0.9052 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3637 | Train Avg AUC : 0.938 abnorm:0.9391 acl:0.9684 meni:0.9066 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3708 | Train Avg AUC : 0.9338 abnorm:0.9408 acl:0.9667 meni:0.8938 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3685 | Train Avg AUC : 0.9338 abnorm:0.9367 acl:0.9667 meni:0.8981 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.37 | Train Avg AUC : 0.9325 abnorm:0.9315 acl:0.9649 meni:0.9012 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3712 | Train Avg AUC : 0.9334 abnorm:0.9318 acl:0.9635 meni:0.9048 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3714 | Train Avg AUC : 0.9323 abnorm:0.9291 acl:0.9617 meni:0.9061 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3691 | Train Avg AUC : 0.9327 abnorm:0.9279 acl:0.963 meni:0.9072 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3695 | Train Avg AUC : 0.9334 abnorm:0.9272 acl:0.9632 meni:0.9098 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3726 | Train Avg AUC : 0.9297 abnorm:0.9222 acl:0.9638 meni:0.9029 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3763 | Train Avg AUC : 0.9282 abnorm:0.9187 acl:0.9612 meni:0.9047 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3746 | Train Avg AUC : 0.9286 abnorm:0.9197 acl:0.9623 meni:0.904 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.372 | Train Avg AUC : 0.9306 abnorm:0.9215 acl:0.9627 meni:0.9075 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3741 | Train Avg AUC : 0.9307 abnorm:0.9242 acl:0.9641 meni:0.9037 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3712 | Train Avg AUC : 0.932 abnorm:0.9243 acl:0.9655 meni:0.9063 | lr : 7.289999999999999e-09\n",
      "Epoch 46 End Train Avg AUC : 0.9324 abnorm : 0.924 acl : 0.9665 meni : 0.9069\n",
      "train loop ended, now val\n",
      "[Epoch: 47 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3791 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3079 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2816 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2873 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3321 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3877 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4073 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4051 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4249 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4032 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 47 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3912 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 46 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3684 | train auc 0.9324 | val loss 0.4065 | val auc 0.8886 | elapsed time 220.18562006950378 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 48 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3225 | Train Avg AUC : 0.9509 abnorm:0.9316 acl:0.9884 meni:0.9327 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3236 | Train Avg AUC : 0.9526 abnorm:0.9393 acl:0.9827 meni:0.9357 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3468 | Train Avg AUC : 0.9403 abnorm:0.9436 acl:0.974 meni:0.9031 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3478 | Train Avg AUC : 0.945 abnorm:0.9461 acl:0.9711 meni:0.918 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3599 | Train Avg AUC : 0.9416 abnorm:0.9426 acl:0.9682 meni:0.914 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3554 | Train Avg AUC : 0.9426 abnorm:0.94 acl:0.972 meni:0.9157 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3715 | Train Avg AUC : 0.9341 abnorm:0.9316 acl:0.9673 meni:0.9033 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3704 | Train Avg AUC : 0.9356 abnorm:0.9341 acl:0.9655 meni:0.9072 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3647 | Train Avg AUC : 0.9394 abnorm:0.9406 acl:0.9677 meni:0.9098 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3751 | Train Avg AUC : 0.9374 abnorm:0.9397 acl:0.9608 meni:0.9116 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3847 | Train Avg AUC : 0.9326 abnorm:0.937 acl:0.9585 meni:0.9024 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3819 | Train Avg AUC : 0.9336 abnorm:0.9356 acl:0.9605 meni:0.9046 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3853 | Train Avg AUC : 0.9305 abnorm:0.9296 acl:0.9602 meni:0.9017 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3829 | Train Avg AUC : 0.931 abnorm:0.9337 acl:0.9608 meni:0.8984 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3795 | Train Avg AUC : 0.9313 abnorm:0.9309 acl:0.9626 meni:0.9003 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3781 | Train Avg AUC : 0.9314 abnorm:0.9299 acl:0.962 meni:0.9023 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3732 | Train Avg AUC : 0.9317 abnorm:0.9266 acl:0.964 meni:0.9046 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3738 | Train Avg AUC : 0.9305 abnorm:0.9244 acl:0.9643 meni:0.9027 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3724 | Train Avg AUC : 0.9316 abnorm:0.926 acl:0.9643 meni:0.9046 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3752 | Train Avg AUC : 0.9312 abnorm:0.9284 acl:0.9615 meni:0.9036 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3735 | Train Avg AUC : 0.9303 abnorm:0.9247 acl:0.9625 meni:0.9035 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3714 | Train Avg AUC : 0.9316 abnorm:0.9243 acl:0.9628 meni:0.9076 | lr : 7.289999999999999e-09\n",
      "Epoch 47 End Train Avg AUC : 0.9299 abnorm : 0.9243 acl : 0.9599 meni : 0.9054\n",
      "train loop ended, now val\n",
      "[Epoch: 48 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3793 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3081 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2818 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2875 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3322 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3877 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4073 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4051 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4248 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4031 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 48 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3911 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 47 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3761 | train auc 0.9299 | val loss 0.4064 | val auc 0.8886 | elapsed time 222.90818691253662 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 49 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3383 | Train Avg AUC : 0.9372 abnorm:0.8818 acl:0.9762 meni:0.9536 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3973 | Train Avg AUC : 0.9149 abnorm:0.889 acl:0.9467 meni:0.9091 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3648 | Train Avg AUC : 0.9362 abnorm:0.9114 acl:0.9635 meni:0.9338 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3685 | Train Avg AUC : 0.9386 abnorm:0.9179 acl:0.9617 meni:0.936 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3615 | Train Avg AUC : 0.935 abnorm:0.918 acl:0.9696 meni:0.9174 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3626 | Train Avg AUC : 0.9313 abnorm:0.9098 acl:0.9732 meni:0.9109 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3628 | Train Avg AUC : 0.9328 abnorm:0.9131 acl:0.9719 meni:0.9135 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3651 | Train Avg AUC : 0.9313 abnorm:0.913 acl:0.972 meni:0.9088 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3613 | Train Avg AUC : 0.9327 abnorm:0.9102 acl:0.9727 meni:0.9152 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3711 | Train Avg AUC : 0.9279 abnorm:0.9074 acl:0.9704 meni:0.9061 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3678 | Train Avg AUC : 0.9302 abnorm:0.9131 acl:0.9707 meni:0.9068 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3701 | Train Avg AUC : 0.9286 abnorm:0.9137 acl:0.9726 meni:0.8995 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.373 | Train Avg AUC : 0.928 abnorm:0.9192 acl:0.9714 meni:0.8932 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.373 | Train Avg AUC : 0.9294 abnorm:0.9227 acl:0.9683 meni:0.8972 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3786 | Train Avg AUC : 0.9278 abnorm:0.9253 acl:0.9673 meni:0.8909 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3731 | Train Avg AUC : 0.9285 abnorm:0.9248 acl:0.967 meni:0.8936 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3719 | Train Avg AUC : 0.9281 abnorm:0.9226 acl:0.9677 meni:0.8942 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3733 | Train Avg AUC : 0.9273 abnorm:0.9203 acl:0.9671 meni:0.8946 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3731 | Train Avg AUC : 0.9277 abnorm:0.9195 acl:0.9662 meni:0.8975 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3755 | Train Avg AUC : 0.9274 abnorm:0.9208 acl:0.9645 meni:0.897 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3755 | Train Avg AUC : 0.9282 abnorm:0.924 acl:0.9644 meni:0.8962 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3722 | Train Avg AUC : 0.9294 abnorm:0.9236 acl:0.9645 meni:0.9 | lr : 7.289999999999999e-09\n",
      "Epoch 48 End Train Avg AUC : 0.9296 abnorm : 0.9237 acl : 0.9634 meni : 0.9017\n",
      "train loop ended, now val\n",
      "[Epoch: 49 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3797 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3085 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2822 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2878 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3326 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3881 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.4077 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4055 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4253 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4035 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 49 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3914 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 48 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3729 | train auc 0.9296 | val loss 0.4066 | val auc 0.8886 | elapsed time 220.5128254890442 s\n",
      "------------------------------\n",
      "Started Training\n",
      "[Epoch: 50 / 50 | Batch : 50 / 1130 ]| Avg Train Loss 0.3818 | Train Avg AUC : 0.9219 abnorm:0.9156 acl:0.9593 meni:0.8907 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 100 / 1130 ]| Avg Train Loss 0.3611 | Train Avg AUC : 0.9319 abnorm:0.9277 acl:0.975 meni:0.8929 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 150 / 1130 ]| Avg Train Loss 0.3502 | Train Avg AUC : 0.9425 abnorm:0.9396 acl:0.9718 meni:0.9161 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 200 / 1130 ]| Avg Train Loss 0.3495 | Train Avg AUC : 0.9412 abnorm:0.9384 acl:0.9749 meni:0.9102 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 250 / 1130 ]| Avg Train Loss 0.3502 | Train Avg AUC : 0.9388 abnorm:0.9341 acl:0.9691 meni:0.9132 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 300 / 1130 ]| Avg Train Loss 0.3538 | Train Avg AUC : 0.9377 abnorm:0.9339 acl:0.9697 meni:0.9095 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 350 / 1130 ]| Avg Train Loss 0.3708 | Train Avg AUC : 0.9306 abnorm:0.9395 acl:0.9644 meni:0.8879 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 400 / 1130 ]| Avg Train Loss 0.3631 | Train Avg AUC : 0.9323 abnorm:0.938 acl:0.966 meni:0.8928 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 450 / 1130 ]| Avg Train Loss 0.3693 | Train Avg AUC : 0.9309 abnorm:0.9375 acl:0.9635 meni:0.8918 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 500 / 1130 ]| Avg Train Loss 0.3685 | Train Avg AUC : 0.9312 abnorm:0.9327 acl:0.9658 meni:0.8951 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 550 / 1130 ]| Avg Train Loss 0.3711 | Train Avg AUC : 0.9316 abnorm:0.9329 acl:0.9619 meni:0.8999 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 600 / 1130 ]| Avg Train Loss 0.3712 | Train Avg AUC : 0.9307 abnorm:0.9316 acl:0.9637 meni:0.8968 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 650 / 1130 ]| Avg Train Loss 0.3685 | Train Avg AUC : 0.9305 abnorm:0.9289 acl:0.9666 meni:0.8961 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 700 / 1130 ]| Avg Train Loss 0.3672 | Train Avg AUC : 0.9317 abnorm:0.9296 acl:0.968 meni:0.8973 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 750 / 1130 ]| Avg Train Loss 0.3645 | Train Avg AUC : 0.9328 abnorm:0.9278 acl:0.9681 meni:0.9025 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 800 / 1130 ]| Avg Train Loss 0.3657 | Train Avg AUC : 0.9318 abnorm:0.9266 acl:0.9682 meni:0.9006 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 850 / 1130 ]| Avg Train Loss 0.3647 | Train Avg AUC : 0.9318 abnorm:0.9242 acl:0.9685 meni:0.9026 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 900 / 1130 ]| Avg Train Loss 0.3663 | Train Avg AUC : 0.9317 abnorm:0.9263 acl:0.9675 meni:0.9012 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 950 / 1130 ]| Avg Train Loss 0.3697 | Train Avg AUC : 0.9298 abnorm:0.9242 acl:0.9647 meni:0.9006 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 1000 / 1130 ]| Avg Train Loss 0.3704 | Train Avg AUC : 0.9314 abnorm:0.9269 acl:0.9647 meni:0.9026 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 1050 / 1130 ]| Avg Train Loss 0.3684 | Train Avg AUC : 0.9311 abnorm:0.9252 acl:0.9666 meni:0.9016 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 1100 / 1130 ]| Avg Train Loss 0.3671 | Train Avg AUC : 0.9321 abnorm:0.9255 acl:0.9669 meni:0.9041 | lr : 7.289999999999999e-09\n",
      "Epoch 49 End Train Avg AUC : 0.933 abnorm : 0.927 acl : 0.9673 meni : 0.9045\n",
      "train loop ended, now val\n",
      "[Epoch: 50 / 50 | Batch : 10 / 120 ]| Avg Val Loss 0.3798 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 20 / 120 ]| Avg Val Loss 0.3087 | Val AUC : 0.5 abnorm:0.5 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 30 / 120 ]| Avg Val Loss 0.2823 | Val AUC : 0.6111 abnorm:0.8333 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 40 / 120 ]| Avg Val Loss 0.2879 | Val AUC : 0.6038 abnorm:0.8113 acl:0.5 meni:0.5 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 50 / 120 ]| Avg Val Loss 0.3327 | Val AUC : 0.8839 abnorm:0.8642 acl:0.9419 meni:0.8457 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 60 / 120 ]| Avg Val Loss 0.3883 | Val AUC : 0.8802 abnorm:0.893 acl:0.893 meni:0.8545 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 70 / 120 ]| Avg Val Loss 0.408 | Val AUC : 0.8784 abnorm:0.8972 acl:0.9184 meni:0.8195 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 80 / 120 ]| Avg Val Loss 0.4057 | Val AUC : 0.8869 abnorm:0.9115 acl:0.9367 meni:0.8124 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 90 / 120 ]| Avg Val Loss 0.4256 | Val AUC : 0.8954 abnorm:0.9176 acl:0.9362 meni:0.8325 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 100 / 120 ]| Avg Val Loss 0.4038 | Val AUC : 0.9047 abnorm:0.9258 acl:0.931 meni:0.8574 | lr : 7.289999999999999e-09\n",
      "[Epoch: 50 / 50 | Batch : 110 / 120 ]| Avg Val Loss 0.3917 | Val AUC : 0.9024 abnorm:0.9307 acl:0.9252 meni:0.8512 | lr : 7.289999999999999e-09\n",
      "Epoch 49 End Val Avg AUC : 0.8886 abnorm : 0.9263 acl : 0.9223 meni : 0.8173\n",
      "train loss : 0.3668 | train auc 0.933 | val loss 0.4068 | val auc 0.8886 | elapsed time 221.15631937980652 s\n",
      "------------------------------\n",
      "training took 11040.405569553375 s\n",
      "Training Ended...\n"
     ]
    }
   ],
   "source": [
    "print('Training Configuration')\n",
    "print(config)\n",
    "\n",
    "train(config=config)\n",
    "\n",
    "print('Training Ended...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef1589-8889-470c-8d31-8537b3c3ba03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
