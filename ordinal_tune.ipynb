{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a350a6b6-4094-4051-b8bf-dfc6dfd0f179",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c81020-0acc-4fc0-875f-b2cba4e48fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset.dataset import load_data\n",
    "from models import MRnet\n",
    "from ordinal_config import ordinal_config\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.ordinal_utils import _train_model, _evaluate_model, _get_lr\n",
    "import time\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93ba76-e97f-41c5-a805-4b8f48c14782",
   "metadata": {
    "tags": []
   },
   "source": [
    "Method for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d810f7c-83fb-45ff-9fe2-be3758cd99dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(config: dict):\n",
    "    \"\"\"\n",
    "    Function where actual fine-tuning takes place using MSE loss\n",
    "    for 4-class classification by rounding predictions to closest class.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Starting to Train Model...')\n",
    "\n",
    "    train_loader, val_loader, test_loader, train_wts, val_wts, test_wts = load_data()\n",
    "\n",
    "    print('Initializing Model...')\n",
    "    model = MRnet()\n",
    "\n",
    "    # Load pretrained weights\n",
    "    checkpoint = torch.load(\"weights/acl/model_test_acl_val_auc_0.9677_train_auc_0.9903_epoch_20.pth\")\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    # Freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Fine-tune the last conv block\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in ['axial.10', 'coronal.10', 'saggital.10']):\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Replace the final layer for regression-style output\n",
    "    num_features = model.fc[0].in_features if isinstance(model.fc, torch.nn.Sequential) else model.fc.in_features\n",
    "    model.fc = torch.nn.Sequential(\n",
    "        torch.nn.Linear(num_features, 128),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 1)  # Scalar output for regression-style classification\n",
    "    )\n",
    "\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        train_wts = train_wts.cuda()\n",
    "        val_wts = val_wts.cuda()\n",
    "\n",
    "    print('Initializing Loss Method...')\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    val_criterion = torch.nn.MSELoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        criterion = criterion.cuda()\n",
    "        val_criterion = val_criterion.cuda()\n",
    "\n",
    "    print('Setup the Optimizer')\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, patience=3, factor=0.3, threshold=1e-4, verbose=True\n",
    "    )\n",
    "\n",
    "    starting_epoch = config['starting_epoch']\n",
    "    num_epochs = config['max_epoch']\n",
    "    log_train = config['log_train']\n",
    "    log_val = config['log_val']\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = float(0)\n",
    "\n",
    "    writer = SummaryWriter(comment=f\"lr={config['lr']} task=acl-grading\")\n",
    "    t_start_training = time.time()\n",
    "\n",
    "    print('Starting Training')\n",
    "\n",
    "    for epoch in range(starting_epoch, num_epochs):\n",
    "        current_lr = _get_lr(optimizer)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        print(f'Starting Epoch {epoch + 1}/{num_epochs}')\n",
    "        train_loss, train_acc = _train_model(\n",
    "            model, train_loader, epoch, num_epochs, optimizer, criterion, writer,\n",
    "            current_lr, log_every=log_train, use_regression=True\n",
    "        )\n",
    "\n",
    "        print('Train loop ended, now evaluating on validation set...')\n",
    "        val_loss, val_acc = _evaluate_model(\n",
    "            model, val_loader, val_criterion, epoch, num_epochs, writer,\n",
    "            current_lr, log_val, use_regression=True\n",
    "        )\n",
    "\n",
    "        writer.add_scalar('Train/Avg Loss', train_loss, epoch)\n",
    "        writer.add_scalar('Val/Avg Loss', val_loss, epoch)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n",
    "              f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "        print('-' * 50)\n",
    "        writer.flush()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "        if bool(config['save_model']) and (epoch + 1) % 10 == 0:\n",
    "            file_name = f\"model_{config['exp_name']}_acl_val_acc_{val_acc:.4f}_train_acc_{train_acc:.4f}_epoch_{epoch + 1}.pth\"\n",
    "            save_path = os.path.join('weights', config['task'], file_name)\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            torch.save({'model_state_dict': model.state_dict()}, save_path)\n",
    "\n",
    "    t_end_training = time.time()\n",
    "    print(f'Training completed in {t_end_training - t_start_training:.2f}s')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8eecb-4508-415c-a6b3-a507c23b76ff",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19133bc4-876f-4f68-8aa8-83be1e5895d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration\n",
      "{'max_epoch': 50, 'log_train': 100, 'lr': 0.001, 'starting_epoch': 0, 'batch_size': 1, 'log_val': 10, 'weight_decay': 0.01, 'patience': 5, 'save_model': 1, 'exp_name': 'test'}\n",
      "Starting to Train Model...\n",
      "Loading Train Dataset of ACL task...\n",
      "['001', '008', '015', '016', '084', '098', '101', '107', '109', '124', '129', '145', '150', '164', '172', '183', '201', '209', '225', '230', '245', '251']\n",
      "Unique labels found in dataset: [0, 1, 2, 3]\n",
      "Number of classes: 4\n",
      "Class distribution:\n",
      "Class 0: 7 samples\n",
      "Class 1: 3 samples\n",
      "Class 2: 8 samples\n",
      "Class 3: 4 samples\n",
      "Class weights for loss are: tensor([0.6713, 1.5664, 0.5874, 1.1748])\n",
      "Total samples: 22 | Num classes: 4\n",
      "Loading Validation Dataset of ACL task...\n",
      "['037', '062', '133', '184', '207', '161']\n",
      "Unique labels found in dataset: [0, 1, 2, 3]\n",
      "Number of classes: 4\n",
      "Class distribution:\n",
      "Class 0: 2 samples\n",
      "Class 1: 1 samples\n",
      "Class 2: 1 samples\n",
      "Class 3: 2 samples\n",
      "Class weights for loss are: tensor([0.6667, 1.3333, 1.3333, 0.6667])\n",
      "Total samples: 6 | Num classes: 4\n",
      "Loading Testing Dataset of ACL task...\n",
      "['006', '030', '034', '048', '052', '079', '099', '126', '158', '176', '178', '196', '219', '237', '244']\n",
      "Unique labels found in dataset: [0, 1, 2, 3]\n",
      "Number of classes: 4\n",
      "Class distribution:\n",
      "Class 0: 4 samples\n",
      "Class 1: 1 samples\n",
      "Class 2: 2 samples\n",
      "Class 3: 8 samples\n",
      "Class weights for loss are: tensor([0.5333, 2.1333, 1.0667, 0.2667])\n",
      "Total samples: 15 | Num classes: 4\n",
      "Initializing Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qdy4zt/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/qdy4zt/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Loss Method...\n",
      "Setup the Optimizer\n",
      "Starting Training\n",
      "Starting Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qdy4zt/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1 / 50 | Batch : 0 / 22 ]| Avg Train Loss: 1.2969 | Accuracy: 1.0000 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 2 / 22 ]| Avg Train Loss: 2.4473 | Accuracy: 0.3333 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 4 / 22 ]| Avg Train Loss: 1.8088 | Accuracy: 0.4000 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 6 / 22 ]| Avg Train Loss: 2.0987 | Accuracy: 0.2857 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 8 / 22 ]| Avg Train Loss: 1.9829 | Accuracy: 0.2222 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 10 / 22 ]| Avg Train Loss: 1.8661 | Accuracy: 0.1818 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 12 / 22 ]| Avg Train Loss: 1.7834 | Accuracy: 0.1538 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 14 / 22 ]| Avg Train Loss: 1.8083 | Accuracy: 0.2000 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 16 / 22 ]| Avg Train Loss: 1.8355 | Accuracy: 0.1765 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 18 / 22 ]| Avg Train Loss: 1.7790 | Accuracy: 0.2105 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 20 / 22 ]| Avg Train Loss: 1.7278 | Accuracy: 0.2381 | lr: 0.001\n",
      "Train loop ended, now evaluating on validation set...\n",
      "[Epoch: 1 / 50 | Batch : 0 / 6 ]| Avg Val Loss: 1.0122 | Val Accuracy: 1.0000 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 2 / 6 ]| Avg Val Loss: 1.3020 | Val Accuracy: 0.6667 | lr: 0.001\n",
      "[Epoch: 1 / 50 | Batch : 4 / 6 ]| Avg Val Loss: 1.4214 | Val Accuracy: 0.4000 | lr: 0.001\n",
      "Train Loss: 1.7001 | Train Acc: 0.2727 | Val Loss: 1.4828 | Val Acc: 0.3333 | Epoch Time: 122.75s\n",
      "--------------------------------------------------\n",
      "Starting Epoch 2/50\n",
      "[Epoch: 2 / 50 | Batch : 0 / 22 ]| Avg Train Loss: 1.6970 | Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 2 / 22 ]| Avg Train Loss: 1.3376 | Accuracy: 0.3333 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 4 / 22 ]| Avg Train Loss: 1.2431 | Accuracy: 0.4000 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 6 / 22 ]| Avg Train Loss: 1.3358 | Accuracy: 0.2857 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 8 / 22 ]| Avg Train Loss: 1.4681 | Accuracy: 0.2222 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 10 / 22 ]| Avg Train Loss: 1.4820 | Accuracy: 0.1818 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 12 / 22 ]| Avg Train Loss: 1.4729 | Accuracy: 0.2308 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 14 / 22 ]| Avg Train Loss: 1.4446 | Accuracy: 0.2667 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 16 / 22 ]| Avg Train Loss: 1.4252 | Accuracy: 0.2941 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 18 / 22 ]| Avg Train Loss: 1.4173 | Accuracy: 0.2632 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 20 / 22 ]| Avg Train Loss: 1.4112 | Accuracy: 0.2857 | lr: 0.001\n",
      "Train loop ended, now evaluating on validation set...\n",
      "[Epoch: 2 / 50 | Batch : 0 / 6 ]| Avg Val Loss: 1.1748 | Val Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 2 / 6 ]| Avg Val Loss: 1.3799 | Val Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 2 / 50 | Batch : 4 / 6 ]| Avg Val Loss: 1.4119 | Val Accuracy: 0.2000 | lr: 0.001\n",
      "Train Loss: 1.3957 | Train Acc: 0.3182 | Val Loss: 1.4959 | Val Acc: 0.1667 | Epoch Time: 122.94s\n",
      "--------------------------------------------------\n",
      "Starting Epoch 3/50\n",
      "[Epoch: 3 / 50 | Batch : 0 / 22 ]| Avg Train Loss: 0.9342 | Accuracy: 1.0000 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 2 / 22 ]| Avg Train Loss: 1.2632 | Accuracy: 0.3333 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 4 / 22 ]| Avg Train Loss: 1.5181 | Accuracy: 0.2000 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 6 / 22 ]| Avg Train Loss: 1.5175 | Accuracy: 0.2857 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 8 / 22 ]| Avg Train Loss: 1.4672 | Accuracy: 0.2222 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 10 / 22 ]| Avg Train Loss: 1.4292 | Accuracy: 0.1818 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 12 / 22 ]| Avg Train Loss: 1.4401 | Accuracy: 0.1538 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 14 / 22 ]| Avg Train Loss: 1.4061 | Accuracy: 0.2000 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 16 / 22 ]| Avg Train Loss: 1.4248 | Accuracy: 0.1765 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 18 / 22 ]| Avg Train Loss: 1.3944 | Accuracy: 0.2105 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 20 / 22 ]| Avg Train Loss: 1.3840 | Accuracy: 0.1905 | lr: 0.001\n",
      "Train loop ended, now evaluating on validation set...\n",
      "[Epoch: 3 / 50 | Batch : 0 / 6 ]| Avg Val Loss: 1.0785 | Val Accuracy: 1.0000 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 2 / 6 ]| Avg Val Loss: 1.2788 | Val Accuracy: 0.6667 | lr: 0.001\n",
      "[Epoch: 3 / 50 | Batch : 4 / 6 ]| Avg Val Loss: 1.3958 | Val Accuracy: 0.4000 | lr: 0.001\n",
      "Train Loss: 1.3784 | Train Acc: 0.1818 | Val Loss: 1.4767 | Val Acc: 0.3333 | Epoch Time: 123.38s\n",
      "--------------------------------------------------\n",
      "Starting Epoch 4/50\n",
      "[Epoch: 4 / 50 | Batch : 0 / 22 ]| Avg Train Loss: 1.6060 | Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 2 / 22 ]| Avg Train Loss: 1.4701 | Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 4 / 22 ]| Avg Train Loss: 1.4046 | Accuracy: 0.2000 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 6 / 22 ]| Avg Train Loss: 1.3686 | Accuracy: 0.2857 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 8 / 22 ]| Avg Train Loss: 1.3477 | Accuracy: 0.3333 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 10 / 22 ]| Avg Train Loss: 1.3257 | Accuracy: 0.3636 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 12 / 22 ]| Avg Train Loss: 1.3760 | Accuracy: 0.3077 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 14 / 22 ]| Avg Train Loss: 1.3490 | Accuracy: 0.3333 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 16 / 22 ]| Avg Train Loss: 1.3224 | Accuracy: 0.3529 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 18 / 22 ]| Avg Train Loss: 1.3455 | Accuracy: 0.3158 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 20 / 22 ]| Avg Train Loss: 1.3622 | Accuracy: 0.3333 | lr: 0.001\n",
      "Train loop ended, now evaluating on validation set...\n",
      "[Epoch: 4 / 50 | Batch : 0 / 6 ]| Avg Val Loss: 1.0818 | Val Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 2 / 6 ]| Avg Val Loss: 1.3962 | Val Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 4 / 50 | Batch : 4 / 6 ]| Avg Val Loss: 1.5036 | Val Accuracy: 0.2000 | lr: 0.001\n",
      "Train Loss: 1.3507 | Train Acc: 0.3182 | Val Loss: 1.6239 | Val Acc: 0.1667 | Epoch Time: 122.71s\n",
      "--------------------------------------------------\n",
      "Starting Epoch 5/50\n",
      "[Epoch: 5 / 50 | Batch : 0 / 22 ]| Avg Train Loss: 1.0625 | Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 2 / 22 ]| Avg Train Loss: 1.0142 | Accuracy: 0.6667 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 4 / 22 ]| Avg Train Loss: 0.9781 | Accuracy: 0.6000 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 6 / 22 ]| Avg Train Loss: 1.1102 | Accuracy: 0.5714 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 8 / 22 ]| Avg Train Loss: 1.2462 | Accuracy: 0.5556 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 10 / 22 ]| Avg Train Loss: 1.2025 | Accuracy: 0.4545 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 12 / 22 ]| Avg Train Loss: 1.2565 | Accuracy: 0.3846 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 14 / 22 ]| Avg Train Loss: 1.2882 | Accuracy: 0.3333 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 16 / 22 ]| Avg Train Loss: 1.2561 | Accuracy: 0.4118 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 18 / 22 ]| Avg Train Loss: 1.2665 | Accuracy: 0.4211 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 20 / 22 ]| Avg Train Loss: 1.2856 | Accuracy: 0.3810 | lr: 0.001\n",
      "Train loop ended, now evaluating on validation set...\n",
      "[Epoch: 5 / 50 | Batch : 0 / 6 ]| Avg Val Loss: 1.1797 | Val Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 2 / 6 ]| Avg Val Loss: 1.3931 | Val Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 5 / 50 | Batch : 4 / 6 ]| Avg Val Loss: 1.4769 | Val Accuracy: 0.2000 | lr: 0.001\n",
      "Train Loss: 1.3183 | Train Acc: 0.3636 | Val Loss: 1.5576 | Val Acc: 0.1667 | Epoch Time: 123.15s\n",
      "--------------------------------------------------\n",
      "Starting Epoch 6/50\n",
      "[Epoch: 6 / 50 | Batch : 0 / 22 ]| Avg Train Loss: 1.2223 | Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 2 / 22 ]| Avg Train Loss: 1.3165 | Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 4 / 22 ]| Avg Train Loss: 1.2344 | Accuracy: 0.4000 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 6 / 22 ]| Avg Train Loss: 1.2192 | Accuracy: 0.4286 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 8 / 22 ]| Avg Train Loss: 1.2078 | Accuracy: 0.4444 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 10 / 22 ]| Avg Train Loss: 1.2508 | Accuracy: 0.3636 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 12 / 22 ]| Avg Train Loss: 1.3105 | Accuracy: 0.3077 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 14 / 22 ]| Avg Train Loss: 1.2845 | Accuracy: 0.3333 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 16 / 22 ]| Avg Train Loss: 1.2828 | Accuracy: 0.2941 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 18 / 22 ]| Avg Train Loss: 1.2714 | Accuracy: 0.3684 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 20 / 22 ]| Avg Train Loss: 1.3105 | Accuracy: 0.3333 | lr: 0.001\n",
      "Train loop ended, now evaluating on validation set...\n",
      "[Epoch: 6 / 50 | Batch : 0 / 6 ]| Avg Val Loss: 1.7431 | Val Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 2 / 6 ]| Avg Val Loss: 2.0270 | Val Accuracy: 0.0000 | lr: 0.001\n",
      "[Epoch: 6 / 50 | Batch : 4 / 6 ]| Avg Val Loss: 2.1426 | Val Accuracy: 0.2000 | lr: 0.001\n",
      "Train Loss: 1.2938 | Train Acc: 0.3636 | Val Loss: 2.0087 | Val Acc: 0.1667 | Epoch Time: 123.18s\n",
      "--------------------------------------------------\n",
      "Starting Epoch 7/50\n",
      "[Epoch: 7 / 50 | Batch : 0 / 22 ]| Avg Train Loss: 0.9565 | Accuracy: 1.0000 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 2 / 22 ]| Avg Train Loss: 1.2112 | Accuracy: 0.6667 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 4 / 22 ]| Avg Train Loss: 1.4807 | Accuracy: 0.4000 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 6 / 22 ]| Avg Train Loss: 1.4838 | Accuracy: 0.4286 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 8 / 22 ]| Avg Train Loss: 1.4195 | Accuracy: 0.4444 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 10 / 22 ]| Avg Train Loss: 1.4766 | Accuracy: 0.3636 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 12 / 22 ]| Avg Train Loss: 1.4256 | Accuracy: 0.3846 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 14 / 22 ]| Avg Train Loss: 1.3890 | Accuracy: 0.4667 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 16 / 22 ]| Avg Train Loss: 1.4026 | Accuracy: 0.4706 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 18 / 22 ]| Avg Train Loss: 1.3922 | Accuracy: 0.4211 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 20 / 22 ]| Avg Train Loss: 1.3787 | Accuracy: 0.4286 | lr: 0.001\n",
      "Train loop ended, now evaluating on validation set...\n",
      "[Epoch: 7 / 50 | Batch : 0 / 6 ]| Avg Val Loss: 0.9104 | Val Accuracy: 1.0000 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 2 / 6 ]| Avg Val Loss: 1.1461 | Val Accuracy: 0.6667 | lr: 0.001\n",
      "[Epoch: 7 / 50 | Batch : 4 / 6 ]| Avg Val Loss: 1.3442 | Val Accuracy: 0.4000 | lr: 0.001\n",
      "Train Loss: 1.3967 | Train Acc: 0.4091 | Val Loss: 1.4758 | Val Acc: 0.3333 | Epoch Time: 122.50s\n",
      "--------------------------------------------------\n",
      "Starting Epoch 8/50\n",
      "[Epoch: 8 / 50 | Batch : 0 / 22 ]| Avg Train Loss: 0.8934 | Accuracy: 1.0000 | lr: 0.001\n",
      "[Epoch: 8 / 50 | Batch : 2 / 22 ]| Avg Train Loss: 1.0460 | Accuracy: 0.6667 | lr: 0.001\n",
      "[Epoch: 8 / 50 | Batch : 4 / 22 ]| Avg Train Loss: 1.1414 | Accuracy: 0.4000 | lr: 0.001\n",
      "[Epoch: 8 / 50 | Batch : 6 / 22 ]| Avg Train Loss: 1.1095 | Accuracy: 0.4286 | lr: 0.001\n",
      "[Epoch: 8 / 50 | Batch : 8 / 22 ]| Avg Train Loss: 1.3106 | Accuracy: 0.3333 | lr: 0.001\n",
      "[Epoch: 8 / 50 | Batch : 10 / 22 ]| Avg Train Loss: 1.3899 | Accuracy: 0.2727 | lr: 0.001\n",
      "[Epoch: 8 / 50 | Batch : 12 / 22 ]| Avg Train Loss: 1.3901 | Accuracy: 0.2308 | lr: 0.001\n",
      "[Epoch: 8 / 50 | Batch : 14 / 22 ]| Avg Train Loss: 1.3539 | Accuracy: 0.3333 | lr: 0.001\n"
     ]
    }
   ],
   "source": [
    "print('Training Configuration')\n",
    "print(ordinal_config)\n",
    "\n",
    "train(config=ordinal_config)\n",
    "\n",
    "print('Training Ended...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef1589-8889-470c-8d31-8537b3c3ba03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e83313-fb75-4d31-a07e-85c854af6cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
